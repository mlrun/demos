{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Project\n",
    "  --------------------------------------------------------------------\n",
    "\n",
    "_____________\n",
    "\n",
    "It's easy to make a business case for running customer churn analyses--given some relevant data, if we could only spot those scenarios where some measurable intervention might have a high likelihood of generating value. From the data-scientist's perspective, making that case starts with some questions, data, and some ideas about how to model that data.  \n",
    "\n",
    "The **[Kaggle Telco Churn dataset](https://www.kaggle.com/blastchar/telco-customer-churn)** is a great starting point, enabling us to set up an almost completely generic pipeline with all the core components of a what could eventually become a complex churn prediction and intervention system.  As a bonus, the same setup could be used to develop a **[predictive maintenance system](https://docs.microsoft.com/en-us/archive/msdn-magazine/2019/may/machine-learning-using-survival-analysis-for-predictive-maintenance)**, or provide a key component in a health care and prevention system.\n",
    "\n",
    "Churn can initally be approached as a binary classification problem.  We start with one or more static feature tables and estimate a prediction function.  In a real-time setting we could also join live aggregates to these static tables and then train a very high resolution churn-detection classifier. The churn detector developed in this notebook has one component that performs this type of static churn classification. It's called **current-state** in the pipeline flow chart below.\n",
    "\n",
    "However, we can look to **[survival analysis](https://en.wikipedia.org/wiki/Survival_analysis)** if our data is time stamped in such a way that we can define a duration feature that represents the age of an observation (for data stored in a database, see **[example sql query to get survival data from a table](https://lifelines.readthedocs.io/en/latest/Examples.html#example-sql-query-to-get-survival-data-from-a-table)**). Fortunately, the Telco dataset contains the client's  contract tenure in months.  So a second regressor branch trains a number of survivability models that will enable us to provide estimates of the timing of events leading to churn, and these can be found in **survival-curves** in the pipeline flow chart below.  (Currently, they only provide information as this notebook is currently in development).\n",
    "\n",
    "## mlrun and nuclio\n",
    "\n",
    "in developing this churn model we highlight how we can use **[mlrun projects](https://github.com/mlrun)**,  **[nuclio functions](https://nuclio.io/)** functions, and **[kubeflow pipelines](https://www.kubeflow.org/)** to set up and deploy a realistic churn model in a production environment.  Along the way we will:\n",
    "1. **write custom data encoders**:  raw data often needs to be processed, some features need to be categorized, others binarized.\n",
    "2. **summarize data**: look at things like class balance, variable distributions.\n",
    "3. **define parameters and hyperparameters** for a generic XGBoost training function\n",
    "4. **train and test** a number of models\n",
    "5. **deploy a \"best\" model** into \"production\" as a nuclio serverless functions\n",
    "6. **test the model servers**\n",
    "\n",
    "Additionally, we will demonstrate\n",
    "* how logs and artifacts are collected throughtout the entire process, \n",
    "* how results can be compared\n",
    "* how github can help streamline, and most importantly document and version your entire process\n",
    "\n",
    "![pipeline](assets/pipeline-3.png)\n",
    "\n",
    "## further development\n",
    "### event simulator\n",
    "Since we only have this one dataset, a \"live\" demonstration will require either changing datasets, or generating simulated data based on the existing telco sample.  Generative models are becoming more and more popular in research, training and in outright applications, so we will be looking to add one to our list of functions.  Given a clean and encoded original dataset, etc...\n",
    "\n",
    "### recommendations\n",
    "who needs attention?  how should we schedule interventions?\n",
    "\n",
    "### apply this to your data\n",
    "how can you adapt this project to suit your own needs?\n",
    "\n",
    "## data science tags\n",
    "xgboost<br>\n",
    "cox proprortional hazards regression<br>\n",
    "classifiers<br>\n",
    "survival analysis<br>\n",
    "\n",
    "_note_: This notebook was adapted from a number external sources:\n",
    "* **[Churn Prediction and Prevention in Python](https://towardsdatascience.com/churn-prediction-and-prevention-in-python-2d454e5fd9a5)**\n",
    "\n",
    "#### **notebook how-to's**\n",
    "* Create and test a custom `data_clean` function \n",
    "* Examine data using a serverless (containerized) `describe` function\n",
    "* Train a number of machine learning algorithms\n",
    "* Tune hyperparameters \n",
    "* Create an automated ML pipeline from various library functions\n",
    "* Run and track the pipeline results and artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a custom data cleaning function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting kind to 'job'\n",
      "%nuclio: setting spec.image to 'mlrun/ml-models'\n"
     ]
    }
   ],
   "source": [
    "%nuclio config kind = \"job\"\n",
    "%nuclio config spec.image = \"mlrun/ml-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from cloudpickle import dumps, dump, load\n",
    "\n",
    "from sklearn.preprocessing import (OneHotEncoder,\n",
    "                                   LabelEncoder)\n",
    "\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem\n",
    "\n",
    "def data_clean(\n",
    "    context:MLClientCtx, \n",
    "    src: DataItem,\n",
    "    file_ext: str = \"csv\",\n",
    "    models_dest: str = \"models/encoders\",\n",
    "    cleaned_key: str = \"cleaned-data\",\n",
    "    encoded_key: str = \"encoded-data\"\n",
    "):\n",
    "    \"\"\"process a raw churn data file\n",
    "    \n",
    "    Data has 3 states here: `raw`, `cleaned` and `encoded`\n",
    "    \n",
    "    * `raw` kept by default, the pipeline begins with a raw data artifact\n",
    "    * `cleaned` kept for charts, presentations\n",
    "    * `encoded` is input for a cross validation and training function\n",
    "    \n",
    "    steps (not necessarily in correct order, some parallel)\n",
    "    * column name maps\n",
    "    * deal with nans and other types of missings/junk\n",
    "    * label encode binary and ordinal category columns\n",
    "    * create category ranges from numerical columns\n",
    "    And finally,\n",
    "    * test\n",
    "    \n",
    "    Why we don't one-hot-encode here? One hot encoding isn't a necessary\n",
    "    step for all algorithms. It can also generate a very large feature\n",
    "    matrix that doesn't need to be serialized (even if sparse).\n",
    "    So we leave one-hot-encoding for the training step.\n",
    "    \n",
    "    What about scaling numerical columns? Same as why we don't one hot\n",
    "    encode here. Do we scale before train-test split?  IMHO, no.  Scaling\n",
    "    before splitting introduces a type of data leakage.  In addition,\n",
    "    many estimators are completely immune to the monotonic transformations\n",
    "    implied by scaling, so why waste the cycles?\n",
    "    \n",
    "    TODO: \n",
    "        * parallelize where possible\n",
    "        * more abstraction (more parameters, chain sklearn transformers)\n",
    "        * convert to marketplace function\n",
    "        \n",
    "    :param context:          the function execution context\n",
    "    :param src:              an artifact or file path\n",
    "    :param file_ext:         file type for artifacts\n",
    "    :param models_dest:       label encoders and other preprocessing steps\n",
    "                             should be saved together with other pipeline\n",
    "                             models\n",
    "    :param cleaned_key:      key of cleaned data table in artifact store\n",
    "    :param encoded_key:      key of encoded data table in artifact store\n",
    "    \"\"\"\n",
    "    df = src.as_df()\n",
    "    \n",
    "    # drop columns\n",
    "    drop_cols_list = [\"customerID\", \"TotalCharges\"]\n",
    "    df.drop(drop_cols_list, axis=1, inplace=True)\n",
    "    \n",
    "    # header transformations\n",
    "    old_cols = df.columns\n",
    "    rename_cols_map = {\n",
    "        \"SeniorCitizen\" : \"senior\",\n",
    "        \"Partner\"       : \"partner\",\n",
    "        \"Dependents\"    : \"deps\",\n",
    "        \"Churn\"         : \"labels\"\n",
    "    }\n",
    "    df.rename(rename_cols_map, axis=1, inplace=True)\n",
    "\n",
    "    # add drop column to logs:\n",
    "    for col in drop_cols_list:\n",
    "        rename_cols_map.update({col: \"_DROPPED_\"})\n",
    "    \n",
    "    # log the op\n",
    "    tp = os.path.join(models_dest, \"preproc-column_map.json\")\n",
    "    context.log_artifact(\"preproc-column_map.json\",\n",
    "                         body=json.dumps(rename_cols_map),\n",
    "                         local_path=tp)\n",
    "    \n",
    "    # VALUE transformations\n",
    "\n",
    "    # clean\n",
    "    # truncate reply to \"No\"\n",
    "    df = df.applymap(lambda x: \"No\" if str(x).startswith(\"No \") else x)\n",
    "\n",
    "    # encode numerical type as category bins (ordinal)\n",
    "    bins = [0, 12, 24, 36, 48, 60, np.inf]\n",
    "    labels = [0, 1, 2, 3, 4, 5]\n",
    "    tenure = df.tenure.copy(deep=True)\n",
    "    df[\"tenure_map\"] = pd.cut(df.tenure, bins, labels=False)\n",
    "    tenure_map = dict(zip(bins, labels))\n",
    "    # save this transformation\n",
    "    tp = os.path.join(models_dest, \"preproc-numcat_map.json\")\n",
    "    context.log_artifact(\"preproc-numcat_map.json\", \n",
    "                         body=bytes(json.dumps(tenure_map).encode(\"utf-8\")), \n",
    "                         local_path=tp)\n",
    "    \n",
    "    context.log_dataset(cleaned_key, df=df, format=file_ext, index=False)\n",
    "    \n",
    "    # label encoding - generate model for each column saved in dict\n",
    "    # some of these columns may be hot encoded in the training step\n",
    "    fix_cols = [\"gender\", \"partner\", \"deps\", \"OnlineSecurity\", \n",
    "                \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\",\n",
    "                \"StreamingTV\", \"StreamingMovies\", \"PhoneService\",\n",
    "                \"MultipleLines\", \"PaperlessBilling\", \"InternetService\", \n",
    "                \"Contract\", \"PaymentMethod\", \"labels\"]\n",
    "    \n",
    "    d = defaultdict(LabelEncoder)\n",
    "    df[fix_cols] = df[fix_cols].apply(lambda x: d[x.name].fit_transform(x.astype(str)))\n",
    "    context.log_dataset(encoded_key, df=df, format=file_ext, index=False)\n",
    "\n",
    "    model_bin = dumps(d)\n",
    "    context.log_model(\"model\", \n",
    "                      body=model_bin,\n",
    "                      artifact_path=os.path.join(context.artifact_path, \n",
    "                                                 models_dest),\n",
    "                      model_file=\"model.pkl\")\n",
    "    # would be nice to have a check here on the integrity of all done\n",
    "    # raw->clean->encoded->clean->raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project to host our functions, jobs and artifacts\n",
    "\n",
    "Projects are used to package multiple functions, workflows, and artifacts. We usually store project code and definitions in a Git archive.\n",
    "\n",
    "The following code creates a new project in a local dir and initialize git tracking on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from mlrun import run_local, NewTask, mlconf, import_function, mount_v3io\n",
    "mlconf.dbpath = mlconf.dbpath or \"http://mlrun-api:8080\"\n",
    "\n",
    "# specify artifacts target location\n",
    "artifact_path = mlconf.artifact_path or path.abspath(\"./\")\n",
    "project_name = \"churn-project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_project, code_to_function\n",
    "project_dir = \"./project\"\n",
    "churn_proj = new_project(project_name, project_dir, init_git=True)\n",
    "# churn_proj.artifact_path = \"/User/artifacts/churn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the raw data file is local we'll just log it already as an artifact, ensuring we keep a record of the source data used to generate the cleaned data and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-05-22 14:25:47,093 log artifact raw-data at https://raw.githubusercontent.com/yjb-ds/testdata/master/data/WA_Fn-UseC_-Telco-Customer-Churn.csv, size: None, db: Y\n"
     ]
    }
   ],
   "source": [
    "churn_proj.log_artifact(\n",
    "    \"raw-data\", \n",
    "    target_path=\"https://raw.githubusercontent.com/yjb-ds/testdata/master/data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test-locally\"></a>\n",
    "### Run the data generator function locally\n",
    "\n",
    "The functions above can be tested locally. Parameters, inputs, and outputs can be specified in the API or the `Task` object.<br>\n",
    "when using `run_local()` the function inputs and outputs are automatically recorded by MLRun experiment and data tracking DB.\n",
    "\n",
    "In each run we can specify the function, inputs, parameters/hyper-parameters, etc... For more details, see the [mlrun_basics notebook](mlrun_basics.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-05-22 14:25:51,730 starting run data_clean uid=caed2e71528347ecad61af9161d15a01  -> http://mlrun-api:8080\n",
      "[mlrun] 2020-05-22 14:25:52,066 log artifact preproc-column_map.json at /User/artifacts/churn/models/encoders/preproc-column_map.json, size: 146, db: Y\n",
      "[mlrun] 2020-05-22 14:25:52,147 log artifact preproc-numcat_map.json at /User/artifacts/churn/models/encoders/preproc-numcat_map.json, size: 53, db: Y\n",
      "[mlrun] 2020-05-22 14:25:52,402 log artifact cleaned-data at /User/artifacts/churn/cleaned-data.csv, size: 708244, db: Y\n",
      "[mlrun] 2020-05-22 14:25:52,595 log artifact encoded-data at /User/artifacts/churn/encoded-data.csv, size: 326760, db: Y\n",
      "[mlrun] 2020-05-22 14:25:52,615 log artifact model at /User/artifacts/churn/models/encoders/, size: 1515, db: Y\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>churn-project</td>\n",
       "      <td><div title=\"caed2e71528347ecad61af9161d15a01\"><a href=\"https://mlrun-ui.default-tenant.app.yjb-mlrun-hope.iguazio-cd1.com/projects/churn-project/jobs/caed2e71528347ecad61af9161d15a01/info\" target=\"_blank\" >...61d15a01</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>May 22 14:25:51</td>\n",
       "      <td>completed</td>\n",
       "      <td>data_clean</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=admin</div><div class=\"dictlist\">kind=handler</div><div class=\"dictlist\">owner=admin</div><div class=\"dictlist\">host=jupyter-67c88b95d4-crdhq</div></td>\n",
       "      <td><div title=\"store:///raw-data\">src</div></td>\n",
       "      <td><div class=\"dictlist\">file_ext=csv</div><div class=\"dictlist\">apply_tenure_map=False</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result64e8218d\" title=\"/files/artifacts/churn/models/encoders/preproc-column_map.json\">preproc-column_map.json</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result64e8218d\" title=\"/files/artifacts/churn/models/encoders/preproc-numcat_map.json\">preproc-numcat_map.json</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result64e8218d\" title=\"/files/artifacts/churn/cleaned-data.csv\">cleaned-data</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result64e8218d\" title=\"/files/artifacts/churn/encoded-data.csv\">encoded-data</div><div title=\"/User/artifacts/churn/models/encoders\">model</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result64e8218d-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result64e8218d-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result64e8218d\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result64e8218d-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run caed2e71528347ecad61af9161d15a01 --project churn-project , !mlrun logs caed2e71528347ecad61af9161d15a01 --project churn-project\n",
      "[mlrun] 2020-05-22 14:25:52,703 run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "# run the function locally\n",
    "from mlrun import NewTask\n",
    "cleaner = run_local(\n",
    "    name=\"data_clean\",\n",
    "    handler=data_clean, \n",
    "    project=project_name,\n",
    "    inputs={\"src\": \"store:///raw-data\"},\n",
    "    params={\"file_ext\" : \"csv\",\n",
    "            \"apply_tenure_map\": False},\n",
    "    artifact_path=path.join(mlconf.artifact_path, \"churn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert our local code to a distributed serverless function object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_func = code_to_function(name=\"clean_data\", kind=\"job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Fully Automated ML Pipeline\n",
    "\n",
    "#### Add more functions to our project to be used in our pipeline (from the functions hub/marketplace)\n",
    "\n",
    "AutoML training (classifier), Model validation (test_classifier), Real-time model server, and Model REST API Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f76f71d5358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_proj.set_function(clean_func)\n",
    "churn_proj.set_function(\"hub://describe\", \"describe\")\n",
    "\n",
    "churn_proj.set_function(\"hub://xgb_trainer\", \"classify\")\n",
    "churn_proj.set_function(\"hub://xgb_test\", \"xgbtest\")\n",
    "\n",
    "churn_proj.set_function(\"hub://coxph_trainer\", \"survive\")\n",
    "churn_proj.set_function(\"hub://coxph_test\", \"coxtest\")\n",
    "\n",
    "churn_proj.set_function(\"hub://churn_server\", \"server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and save a pipeline \n",
    "\n",
    "The following workflow definition will be written into a file, it describes a Kubeflow execution graph (DAG)<br>\n",
    "and how functions and data are connected  to form an end to end pipeline. \n",
    "\n",
    "* Build the iris generator (ingest) function container \n",
    "* Ingest the iris data\n",
    "* Analyze the dataset (describe)\n",
    "* Train and test the model\n",
    "* Deploy the model as a real-time serverless function\n",
    "* Test the serverless function REST API with test dataset\n",
    "\n",
    "Check the code below to see how functions objects are initialized and used (by name) inside the workflow.<br>\n",
    "The `workflow.py` file has two parts, initialize the function objects and define pipeline dsl (connect the function inputs and outputs).\n",
    "\n",
    "> Note: the pipeline can include CI steps like building container images and deploying models as illustrated  in the following example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting project/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile project/workflow.py\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "\n",
    "funcs = {}\n",
    "\n",
    "GPUS = False\n",
    "\n",
    "DATA_REPO = \"https://raw.githubusercontent.com/yjb-ds/testdata/master\"\n",
    "DATA_PATH = \"data/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "RAW_CHURN_DATA = f\"{DATA_REPO}/{DATA_PATH}\"\n",
    "\n",
    "# init functions is used to configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        \n",
    "    functions[\"server\"].set_env(\"INFERENCE_STREAM\", \"users/admin/artifacts/churn/model_stream\")\n",
    "\n",
    "    \n",
    "@dsl.pipeline(\n",
    "    name=\"Demo training pipeline\",\n",
    "    description=\"Shows how to use mlrun.\"\n",
    ")\n",
    "def kfpipeline():\n",
    "    \n",
    "    # build our cleaner function (container image)\n",
    "    builder_cleaner = funcs[\"clean-data\"].deploy_step(skip_deployed=True, \n",
    "                                                      with_mlrun=False)\n",
    "    # use mlrun<=0.4.7 only:\n",
    "    builder_xgb = funcs[\"classify\"].deploy_step(skip_deployed=True, \n",
    "                                                with_mlrun=False)\n",
    "    \n",
    "    # run the ingestion function with the new image and params\n",
    "    clean = funcs[\"clean-data\"].as_step(\n",
    "        name=\"clean-data\",\n",
    "        handler=\"data_clean\",\n",
    "        image=builder_cleaner.outputs[\"image\"],\n",
    "        params={\"file_ext\": \"csv\",\n",
    "                \"models_dest\": \"models/encoders\"},\n",
    "        inputs={\"src\": RAW_CHURN_DATA},\n",
    "        outputs=[\"preproc-colum_map\",\n",
    "                 \"preproc-numcat_map\",\n",
    "                 \"preproc-label_encoders\"\n",
    "                 \"cleaned-data\",\n",
    "                 \"encoded-data\",\n",
    "                 \"tenured-data\"])\n",
    "\n",
    "    # analyze our dataset\n",
    "    describe = funcs[\"describe\"].as_step(\n",
    "        name=\"summary\",\n",
    "        params={\"label_column\"  : \"labels\"},\n",
    "        inputs={\"table\": clean.outputs[\"encoded-data\"]},\n",
    "        outputs={\"histograms\", \n",
    "                 \"imbalance\",\n",
    "                 \"correlation\",\n",
    "                 \"correlation-matrix\"})\n",
    "    \n",
    "    # train with hyper-paremeters\n",
    "    xgb = funcs[\"classify\"].as_step(\n",
    "        name=\"current-state\",\n",
    "        handler=\"train_model\",\n",
    "        image=builder_xgb.outputs[\"image\"],\n",
    "        params={\"sample\"                  : -1, \n",
    "                \"label_column\"            : \"labels\",\n",
    "                \"model_type\"              : \"classifier\",\n",
    "                # xgb class initializers (tuning candidates):\n",
    "                \"CLASS_tree_method\"       : \"gpu_hist\" if GPUS else \"hist\",\n",
    "                \"CLASS_objective\"         : \"binary:logistic\",\n",
    "                \"CLASS_n_estimators\"      : 50,\n",
    "                \"CLASS_max_depth\"         : 5,\n",
    "                \"CLASS_learning_rate\"     : 0.15,\n",
    "                \"CLASS_colsample_bylevel\" : 0.7,\n",
    "                \"CLASS_colsample_bytree\"  : 0.8,\n",
    "                \"CLASS_gamma\"             : 1.0,\n",
    "                \"CLASS_max_delta_step\"    : 3,\n",
    "                \"CLASS_min_child_weight\"  : 1.0,\n",
    "                \"CLASS_reg_lambda\"        : 10.0,\n",
    "                \"CLASS_scale_pos_weight\"  : 1,\n",
    "                \"FIT_verbose\"             : 0,\n",
    "                \"CLASS_subsample\"         : 0.9,\n",
    "                \"CLASS_booster\"           : \"gbtree\",\n",
    "                \"CLASS_random_state\"      : 1,\n",
    "                # encoding:\n",
    "                \"encode_cols\"        : {\"InternetService\": \"ISP\",\n",
    "                                        \"Contract\"       : \"Contract\",\n",
    "                                        \"PaymentMethod\"   : \"Payment\"},\n",
    "                # outputs\n",
    "                \"models_dest\"        : \"models\",\n",
    "                \"plots_dest\"         : \"plots\",\n",
    "                \"file_ext\"           : \"csv\"\n",
    "               },\n",
    "        inputs={\"dataset\"   : clean.outputs[\"encoded-data\"]},\n",
    "        outputs=[\"model\", \n",
    "                 \"test-set\"])\n",
    "\n",
    "    cox = funcs[\"survive\"].as_step(\n",
    "        name=\"survival-curves\",\n",
    "        params={\"sample\"                  : -1, \n",
    "                \"event_column\"            : \"labels\",\n",
    "                \"strata_cols\" : ['InternetService', 'StreamingMovies', \n",
    "                                 'StreamingTV', 'PhoneService'],\n",
    "                \"encode_cols\" : {\"Contract\"       : \"Contract\",\n",
    "                                 \"PaymentMethod\"  : \"Payment\"},\n",
    "                # outputs\n",
    "                \"models_dest\"        : \"models/cox\",\n",
    "                \"plots_dest\"         : \"plots\",\n",
    "                \"file_ext\"           : \"csv\"\n",
    "               },\n",
    "        inputs={\"dataset\"   : clean.outputs[\"encoded-data\"]},\n",
    "        outputs=[\"cx-model\",\n",
    "                 \"coxhazard-summary\",\n",
    "                 \"tenured-test-set\"])\n",
    "\n",
    "    test_xgb = funcs[\"xgbtest\"].as_step(\n",
    "        name=\"test classifier\",\n",
    "        params={\"label_column\": \"labels\",\n",
    "                \"plots_dest\"  : \"churn/test/xgb\"},\n",
    "        inputs={\"models_path\"  : xgb.outputs[\"model\"],\n",
    "                \"test_set\"    : xgb.outputs[\"test-set\"]})\n",
    "\n",
    "    test_cox = funcs[\"coxtest\"].as_step(\n",
    "        name=\"test regressor\",\n",
    "        params={\"label_column\": \"labels\",\n",
    "                \"plots_dest\"  : \"churn/test/cox\"},\n",
    "        inputs={\"models_path\"  : cox.outputs[\"cx-model\"],\n",
    "                \"test_set\"    : cox.outputs[\"tenured-test-set\"]})\n",
    "\n",
    "    # deploy our model as a serverless function\n",
    "    deploy_xgb = funcs[\"server\"].deploy_step(\n",
    "        models={\"churn_server_v1\": xgb.outputs[\"model\"]})\n",
    "    deploy_xgb.after(cox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the workflow file as \"main\"\n",
    "churn_proj.set_workflow(\"main\", \"workflow.py\", embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the project definitions to a file (project.yaml), it is recommended to commit all changes to a Git repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_proj.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(churn_proj.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"run-pipeline\"></a>\n",
    "## Run a pipeline workflow\n",
    "use the `run` method to execute a workflow, you can provide alternative arguments and specify the default target for workflow artifacts.<br>\n",
    "The workflow ID is returned and can be used to track the progress or you can use the hyperlinks\n",
    "\n",
    "> Note: The same command can be issued through CLI commands:<br>\n",
    "    `mlrun project my-proj/ -r main -p \"v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/\"`\n",
    "\n",
    "The dirty flag allow us to run a project with uncommited changes (when the notebook is in the same git dir it will always be dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.yjb-mlrun-hope.iguazio-cd1.com/pipelines/#/experiments/details/7d29812f-a779-42ba-836a-e42cad561607\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.yjb-mlrun-hope.iguazio-cd1.com/pipelines/#/runs/details/e2067b83-cf97-4415-ae57-800df70fe327\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-05-22 14:26:01,408 Pipeline run id=e2067b83-cf97-4415-ae57-800df70fe327, check UI or DB for progress\n"
     ]
    }
   ],
   "source": [
    "artifact_path = os.path.join(mlconf.artifact_path, \"churn\")\n",
    "run_id = churn_proj.run(\n",
    "    \"main\",\n",
    "    arguments={},\n",
    "    artifact_path=artifact_path,\n",
    "    dirty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track pipeline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlrun import get_run_db\n",
    "# db = get_run_db().connect()\n",
    "# db.list_runs(project=churn_proj.name).show() #, labels=f\"workflow={run_id}\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[back to top](#top)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
