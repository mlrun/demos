name: churn-project
functions:
- name: clean-data
  spec:
    kind: job
    metadata:
      name: clean-data
      tag: ''
      project: churn-project
      categories: []
    spec:
      command: ''
      args: []
      image: mlrun/ml-models
      env: []
      default_handler: ''
      entry_points:
        data_clean:
          name: data_clean
          doc: "process a raw churn data file\n\nData has 3 states here: `raw`, `cleaned`\
            \ and `encoded`\n\n* `raw` kept by default, the pipeline begins with a\
            \ raw data artifact\n* `cleaned` kept for charts, presentations\n* `encoded`\
            \ is input for a cross validation and training function\n\nsteps (not\
            \ necessarily in correct order, some parallel)\n* column name maps\n*\
            \ deal with nans and other types of missings/junk\n* label encode binary\
            \ and ordinal category columns\n* create category ranges from numerical\
            \ columns\nAnd finally,\n* test\n\nWhy we don't one-hot-encode here? One\
            \ hot encoding isn't a necessary\nstep for all algorithms. It can also\
            \ generate a very large feature\nmatrix that doesn't need to be serialized\
            \ (even if sparse).\nSo we leave one-hot-encoding for the training step.\n\
            \nWhat about scaling numerical columns? Same as why we don't one hot\n\
            encode here. Do we scale before train-test split?  IMHO, no.  Scaling\n\
            before splitting introduces a type of data leakage.  In addition,\nmany\
            \ estimators are completely immune to the monotonic transformations\n\
            implied by scaling, so why waste the cycles?\n\nTODO: \n    * parallelize\
            \ where possible\n    * more abstraction (more parameters, chain sklearn\
            \ transformers)\n    * convert to marketplace function"
          parameters:
          - name: context
            type: MLClientCtx
            doc: the function execution context
          - name: src
            type: DataItem
            doc: an artifact or file path
          - name: file_ext
            type: str
            doc: file type for artifacts
            default: csv
          - name: models_dest
            type: str
            doc: label encoders and other preprocessing steps should be saved together
              with other pipeline models
            default: models/encoders
          - name: cleaned_key
            type: str
            doc: key of cleaned data table in artifact store
            default: cleaned-data
          - name: encoded_key
            type: str
            doc: key of encoded data table in artifact store
            default: encoded-data
          outputs: []
          lineno: 18
      description: ''
      build:
        functionSourceCode: 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
        commands: []
        code_origin: https://github.com/yjb-ds/demos.git#f7b4884f48b9eecb8b2c3e7dfcba0c61dc6e2765:clean_data.ipynb
- url: hub://describe
  name: describe
- url: hub://xgb_trainer
  name: classify
- url: hub://xgb_test
  name: xgbtest
- url: hub://coxph_trainer
  name: survive
- url: hub://coxph_test
  name: coxtest
- url: hub://churn_server
  name: server
workflows:
- name: main
  code: "from kfp import dsl\nfrom mlrun import mount_v3io\n\nfuncs = {}\n\nGPUS =\
    \ False\nRAW_CHURN_DATA = \"/User/repos/demos/churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\
    \n\n# init functions is used to configure function resources and local settings\n\
    def init_functions(functions: dict, project=None, secrets=None):\n    for f in\
    \ functions.values():\n        f.apply(mount_v3io())\n        \n    functions[\"\
    server\"].set_env(\"INFERENCE_STREAM\", \"users/admin/artifacts/churn/model_stream\"\
    )\n\n    \n@dsl.pipeline(\n    name=\"Demo training pipeline\",\n    description=\"\
    Shows how to use mlrun.\"\n)\ndef kfpipeline():\n    \n    # build our cleaner\
    \ function (container image)\n    builder = funcs[\"clean-data\"].deploy_step(skip_deployed=True)\
    \ #False, with_mlrun=False)\n    \n    # run the ingestion function with the new\
    \ image and params\n    clean = funcs[\"clean-data\"].as_step(\n        name=\"\
    clean-data\",\n        handler=\"data_clean\",\n        image=builder.outputs[\"\
    image\"],\n        params={\"file_ext\": \"csv\",\n                \"models_dest\"\
    : \"models/encoders\"},\n        inputs={\"src\": RAW_CHURN_DATA},\n        outputs=[\"\
    preproc-colum_map\",\n                 \"preproc-numcat_map\",\n             \
    \    \"cleaned-data\",\n                 \"encoded-data\"])\n\n    # analyze our\
    \ dataset\n    describe = funcs[\"describe\"].as_step(\n        name=\"summary\"\
    ,\n        params={\"label_column\"  : \"labels\"},\n        inputs={\"table\"\
    : clean.outputs[\"encoded-data\"]},\n        outputs=[\"histograms\", \n     \
    \            \"imbalance\",\n                 \"imbalance-weights-vec\",\n   \
    \              \"correlation\",\n                 \"correlation-matrix\"])\n \
    \   \n    # train with hyper-paremeters\n    xgb = funcs[\"classify\"].as_step(\n\
    \        name=\"current-state\",\n        params={\"sample\"                 \
    \ : -1, \n                \"label_column\"            : \"labels\",\n        \
    \        \"model_type\"              : \"classifier\",\n                # xgb\
    \ class initializers (tuning candidates):\n                \"CLASS_tree_method\"\
    \       : \"gpu_hist\" if GPUS else \"hist\",\n                \"CLASS_objective\"\
    \         : \"binary:logistic\",\n                \"CLASS_n_estimators\"     \
    \ : 50,\n                \"CLASS_max_depth\"         : 5,\n                \"\
    CLASS_learning_rate\"     : 0.15,\n                \"CLASS_colsample_bylevel\"\
    \ : 0.7,\n                \"CLASS_colsample_bytree\"  : 0.8,\n               \
    \ \"CLASS_gamma\"             : 1.0,\n                \"CLASS_max_delta_step\"\
    \    : 3,\n                \"CLASS_min_child_weight\"  : 1.0,\n              \
    \  \"CLASS_reg_lambda\"        : 10.0,\n                \"CLASS_scale_pos_weight\"\
    \  : 1.5,\n                \"FIT_verbose\"             : 0,\n                \"\
    CLASS_subsample\"         : 0.9,\n                \"CLASS_booster\"          \
    \ : \"gbtree\",\n                \"CLASS_random_state\"      : 1,\n          \
    \      # encoding:\n                \"encode_cols\"        : {\"InternetService\"\
    : \"ISP\",\n                                        \"Contract\"       : \"Contract\"\
    ,\n                                        \"PaymentMethod\"   : \"Payment\"},\n\
    \                # outputs\n                \"models_dest\"        : \"models\"\
    ,\n                \"plots_dest\"         : \"plots\",\n                \"file_ext\"\
    \           : \"csv\"\n               },\n        inputs={\"dataset\"   : clean.outputs[\"\
    encoded-data\"]},\n        outputs=[\"model\", \n                 \"test-set\"\
    ])\n\n    cox = funcs[\"survive\"].as_step(\n        name=\"survival-curves\"\
    ,\n        params={\"sample\"                  : -1, \n                \"event_column\"\
    \            : \"labels\",\n                \"strata_cols\" : ['InternetService',\
    \ 'StreamingMovies', \n                                 'StreamingTV', 'PhoneService'],\n\
    \                \"encode_cols\" : {\"Contract\"       : \"Contract\",\n     \
    \                            \"PaymentMethod\"  : \"Payment\"},\n            \
    \    # outputs\n                \"models_dest\"        : \"models/cox\",\n   \
    \             \"plots_dest\"         : \"plots\",\n                \"file_ext\"\
    \           : \"csv\"\n               },\n        inputs={\"dataset\"   : clean.outputs[\"\
    encoded-data\"]},\n        outputs=[\"cx-model\",\n                 \"coxhazard-summary\"\
    ,\n                 \"tenured-test-set\"])\n\n    test_xgb = funcs[\"xgbtest\"\
    ].as_step(\n        name=\"test classifier\",\n        params={\"label_column\"\
    : \"labels\",\n                \"plots_dest\"  : \"churn/test/xgb\"},\n      \
    \  inputs={\"models_path\"  : xgb.outputs[\"model\"],\n                \"test_set\"\
    \    : xgb.outputs[\"test-set\"]})\n\n    test_cox = funcs[\"coxtest\"].as_step(\n\
    \        name=\"test regressor\",\n        params={\"label_column\": \"labels\"\
    ,\n                \"plots_dest\"  : \"churn/test/plots\"},\n        inputs={\"\
    models_path\"  : cox.outputs[\"cx-model\"],\n                \"test_set\"    :\
    \ cox.outputs[\"tenured-test-set\"]})\n\n    # deploy our model as a serverless\
    \ function\n    deploy_xgb = funcs[\"server\"].deploy_step(\n        models={\"\
    churn_server_v1\": xgb.outputs[\"model\"]})\n    deploy_xgb.after(cox)\n"
artifacts:
- key: raw-data
  kind: ''
  iter: 0
  tree: latest
  target_path: /User/repos/demos/churn/WA_Fn-UseC_-Telco-Customer-Churn.csv
  db_key: raw-data
