name: churn-project
functions:
- name: clean-data
  spec:
    kind: job
    metadata:
      name: clean-data
      tag: ''
      project: churn-project
    spec:
      command: ''
      args: []
      image: mlrun/ml-models
      env: []
      default_handler: ''
      entry_points:
        data_clean:
          name: data_clean
          doc: "process a raw churn data file\n\nData has 3 states here: `raw`, `cleaned`\
            \ and `encoded`\n\n* `raw` kept by default, the pipeline begins with a\
            \ raw data artifact\n* `cleaned` kept for charts, presentations\n* `encoded`\
            \ is input for a cross validation and training function\n\nsteps (not\
            \ necessarily in correct order, some parallel)\n* column name maps\n*\
            \ deal with nans and other types of missings/junk\n* label encode binary\
            \ and ordinal category columns\n* create category ranges from numerical\
            \ columns\nAnd finally,\n* test\n\nWhy we don't one-hot-encode here? One\
            \ hot encoding isn't a necessary\nstep for all algorithms. It can also\
            \ generate a very large feature\nmatrix that doesn't need to be serialized\
            \ (even if sparse).\nSo we leave one-hot-encoding for the training step.\n\
            \nWhat about scaling numerical columns? Same as why we don't one hot\n\
            encode here. Do we scale before train-test split?  IMHO, no.  Scaling\n\
            before splitting introduces a type of data leakage.  In addition,\nmany\
            \ estimators are completely immune to the monotonic transformations\n\
            implied by scaling, so why waste the cycles?\n\nTODO: \n    * parallelize\
            \ where possible\n    * more abstraction (more parameters, chain sklearn\
            \ transformers)\n    * convert to marketplace function"
          parameters:
          - name: context
            type: MLClientCtx
            doc: the function execution context
          - name: src
            type: DataItem
            doc: an artifact or file path
          - name: file_ext
            type: str
            doc: file type for artifacts
            default: csv
          - name: models_dest
            type: str
            doc: label encoders and other preprocessing steps should be saved together
              with other pipeline models
            default: models/encoders
          - name: cleaned_key
            type: str
            doc: key of cleaned data table in artifact store
            default: cleaned-data
          - name: encoded_key
            type: str
            doc: key of encoded data table in artifact store
            default: encoded-data
          outputs: []
          lineno: 18
      description: ''
      build:
        functionSourceCode: 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
        commands: []
        code_origin: https://github.com/mlrun/demos.git#e512f22089f6aea0dd0f690462cf5e0b62b9de6b:clean_data.ipynb
- url: hub://describe
  name: describe
- url: hub://xgb_trainer
  name: classify
- url: hub://xgb_test
  name: xgbtest
- url: hub://coxph_trainer
  name: survive
- url: hub://coxph_test
  name: coxtest
- url: hub://churn_server
  name: server
workflows:
- name: main
  code: "from kfp import dsl\nfrom mlrun import mount_v3io\n\nfuncs = {}\n\nGPUS =\
    \ False\n\n# assuming the \nDATA_REPO = \"https://raw.githubusercontent.com/mlrun/demos/master/churn\"\
    \nDATA_PATH = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\nRAW_CHURN_DATA = f\"{DATA_REPO}/{DATA_PATH}\"\
    \n\n# init functions is used to configure function resources and local settings\n\
    def init_functions(functions: dict, project=None, secrets=None):\n    for f in\
    \ functions.values():\n        f.apply(mount_v3io())\n        \n    functions[\"\
    server\"].set_env(\"INFERENCE_STREAM\", \"users/admin/artifacts/churn/model_stream\"\
    )\n\n    \n@dsl.pipeline(\n    name=\"Demo training pipeline\",\n    description=\"\
    Shows how to use mlrun.\"\n)\ndef kfpipeline():\n    \n    # encode the data\n\
    \    clean = funcs[\"clean-data\"].as_step(\n        name=\"clean-data\",\n  \
    \      handler=\"data_clean\",\n        params={\"file_ext\": \"csv\",\n     \
    \           \"models_dest\": \"models/encoders\"},\n        inputs={\"src\": RAW_CHURN_DATA},\n\
    \        outputs=[\"preproc-colum_map\",\n                 \"preproc-numcat_map\"\
    ,\n                 \"preproc-label_encoders\"\n                 \"cleaned-data\"\
    ,\n                 \"encoded-data\"])\n\n    # analyze our dataset\n    describe\
    \ = funcs[\"describe\"].as_step(\n        name=\"summary\",\n        params={\"\
    label_column\"  : \"labels\"},\n        inputs={\"table\": clean.outputs[\"encoded-data\"\
    ]},\n        outputs=[\"histograms\", \n                 \"imbalance\",\n    \
    \             \"correlation\",\n                 \"correlation-matrix\"])\n  \
    \  \n    # train with hyper-paremeters\n    xgb = funcs[\"classify\"].as_step(\n\
    \        name=\"current-state\",\n        handler=\"train_model\",\n        params={\"\
    sample\"                  : -1, \n                \"label_column\"           \
    \ : \"labels\",\n                \"model_type\"              : \"classifier\"\
    ,\n                # xgb class initializers (tuning candidates):\n           \
    \     \"CLASS_tree_method\"       : \"gpu_hist\" if GPUS else \"hist\",\n    \
    \            \"CLASS_objective\"         : \"binary:logistic\",\n            \
    \    \"CLASS_n_estimators\"      : 50,\n                \"CLASS_max_depth\"  \
    \       : 5,\n                \"CLASS_learning_rate\"     : 0.15,\n          \
    \      \"CLASS_colsample_bylevel\" : 0.7,\n                \"CLASS_colsample_bytree\"\
    \  : 0.8,\n                \"CLASS_gamma\"             : 1.0,\n              \
    \  \"CLASS_max_delta_step\"    : 3,\n                \"CLASS_min_child_weight\"\
    \  : 1.0,\n                \"CLASS_reg_lambda\"        : 10.0,\n             \
    \   \"CLASS_scale_pos_weight\"  : 1,\n                \"FIT_verbose\"        \
    \     : 0,\n                \"CLASS_subsample\"         : 0.9,\n             \
    \   \"CLASS_booster\"           : \"gbtree\",\n                \"CLASS_random_state\"\
    \      : 1,\n                # encoding:\n                \"encode_cols\"    \
    \    : {\"InternetService\": \"ISP\",\n                                      \
    \  \"Contract\"       : \"Contract\",\n                                      \
    \  \"PaymentMethod\"   : \"Payment\"},\n                # outputs\n          \
    \      \"models_dest\"        : \"models\",\n                \"plots_dest\"  \
    \       : \"plots\",\n                \"file_ext\"           : \"csv\"\n     \
    \          },\n        inputs={\"dataset\"   : clean.outputs[\"encoded-data\"\
    ]},\n        outputs=[\"model\", \"test_set\"])\n\n    cox = funcs[\"survive\"\
    ].as_step(\n        name=\"survival-curves\",\n        params={\"sample\"    \
    \              : -1, \n                \"event_column\"            : \"labels\"\
    ,\n                \"strata_cols\" : ['InternetService', 'StreamingMovies', \n\
    \                                 'StreamingTV', 'PhoneService'],\n          \
    \      \"encode_cols\" : {\"Contract\"       : \"Contract\",\n               \
    \                  \"PaymentMethod\"  : \"Payment\"},\n                # outputs\n\
    \                \"models_dest\"        : \"models/cox\",\n                \"\
    plots_dest\"         : \"plots\",\n                \"file_ext\"           : \"\
    csv\"\n               },\n        inputs={\"dataset\"   : clean.outputs[\"encoded-data\"\
    ]},\n        outputs=[\"cx-model\", \"coxhazard-summary\", \"tenured-test-set\"\
    ])\n\n    test_xgb = funcs[\"xgbtest\"].as_step(\n        name=\"test classifier\"\
    ,\n        params={\"label_column\": \"labels\",\n                \"plots_dest\"\
    \  : \"churn/test/xgb\"},\n        inputs={\"models_path\" : xgb.outputs[\"model\"\
    ],\n                \"test_set\"    : xgb.outputs[\"test_set\"]})\n\n    test_cox\
    \ = funcs[\"coxtest\"].as_step(\n        name=\"test regressor\",\n        params={\"\
    label_column\": \"labels\",\n                \"plots_dest\"  : \"churn/test/cox\"\
    },\n        inputs={\"models_path\" : cox.outputs[\"cx-model\"],\n           \
    \     \"test_set\"    : cox.outputs[\"tenured-test-set\"]})\n\n    # deploy our\
    \ model as a serverless function\n    deploy_xgb = funcs[\"server\"].deploy_step(\n\
    \        models={\"churn_server_v1\": xgb.outputs[\"model\"]})\n    deploy_xgb.after(cox)\n"
artifacts:
- key: raw-data
  kind: ''
  iter: 0
  tree: latest
  target_path: https://raw.githubusercontent.com/mlrun/demos/master/churn/WA_Fn-UseC_-Telco-Customer-Churn.csv
  db_key: raw-data
