{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88a9647",
   "metadata": {},
   "source": [
    "# Stocks news ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b28bb",
   "metadata": {},
   "source": [
    "Two options to run stocks demo (with kfpipeline and without).\n",
    "1. run notebooks `01_ingest_news.ipynb`, `02_ingest_stocks.ipynb`, `03_model_training.ipynb`, `04_model_serving.ipynb`, `06_grafana_view`\n",
    "2. or `01_ingest_news.ipynb`, `02_ingest_stocks.ipynb`, `05_stocks_pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e381b",
   "metadata": {},
   "source": [
    "> <b> Steps </b>\n",
    "> * [project creation and prerequisits](#project-creation-and-prerequisits)\n",
    "> * [Deploying sentiment analysis serving function from the function marketplace](#Deploying-sentiment-analysis-serving-function-from-the-function-marketplace)\n",
    "> * [Creating a feature set and declaring the graph](#Creating-a-feature-set-and-declaring-the-graph)\n",
    "> * [Dummy ingestion, Deploying ingestion service and getting ingestion endpoint](#Dummy-ingestion,-Deploying-ingestion-service-and-getting-ingestion-endpoint)\n",
    "> * [Testing ingestion service](#Testing-ingestion-service)\n",
    "> * [Creating scheduled mlrun job to invoke our function every time delta](#Creating-scheduled-mlrun-job-to-invoke-our-function-every-time-delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0042bb",
   "metadata": {},
   "source": [
    "## project creation and prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e026f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install prerequisites\n",
    "# prerequisites for the notebook is installing 2 packages yfinance yahoo_fin for uploading stocks data\n",
    "import importlib.util\n",
    "import IPython\n",
    "\n",
    "def install_missing_packages(notebook_packages):\n",
    "    install_flag = False\n",
    "    for package in notebook_packages:\n",
    "        spec = importlib.util.find_spec(package)\n",
    "        if spec is None:\n",
    "            %pip install {package}\n",
    "            install_flag = True\n",
    "        else:     \n",
    "            print(\"package {} installed\".format(package))\n",
    "        if install_flag:            \n",
    "            print (\"restarting kernel due to package install\")\n",
    "            IPython.Application.instance().kernel.do_shutdown(True)\n",
    "# For illustrative purposes.\n",
    "packages  = ['yfinance', 'yahoo_fin']\n",
    "install_missing_packages(packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "project = mlrun.get_or_create_project(name='stocks',user_project=True, context=\"src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a102f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_STOCKS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce9fc3",
   "metadata": {},
   "source": [
    "## Creating a feature set and declaring the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# creating feature set\n",
    "news_set = fstore.FeatureSet(\"news\",\n",
    "                                 entities=[fstore.Entity(\"ticker\")],\n",
    "                                 timestamp_key='Datetime', \n",
    "                                 description=\"stocks news feature set\")\n",
    "\n",
    "# setting up the graph\n",
    "news_set.graph \\\n",
    "    .to(name='get_news', handler='get_news') \\\n",
    "    .to(\"storey.steps.Flatten\", name=\"flatten_news\") \\\n",
    "    .to(name='wrap_event', handler='wrap_event') \\\n",
    "    .to(\"HuggingSentimentAnalysis\",handler= \"get_sentiment\", full_event=True)\n",
    "\n",
    "news_set.set_targets(with_defaults=True) \n",
    "news_set.plot(rankdir=\"LR\", with_targets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68f746",
   "metadata": {},
   "source": [
    "## Dummy ingestion, Deploying ingestion service and getting ingestion endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232bae8b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# ingesting dummy (A MUST) \n",
    "import os\n",
    "import datetime\n",
    "# because were ingesting locally, code must be present !\n",
    "from src.news import *\n",
    "\n",
    "name = os.environ['V3IO_USERNAME']\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "fstore.ingest(news_set,\n",
    "              pd.DataFrame.from_dict({'ticker':[name],\n",
    "                                      'Datetime': now,\n",
    "                                      'n_stocks':NUMBER_OF_STOCKS}),\n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a52db1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Deploying ingestion service\n",
    "# Define the HTTP Source to_dictable the HTTP trigger on our function and expose the endpoint.\n",
    "# There is an option to declare key and timestamp inside the http source (here we dont send data through the http hence not needed)\n",
    "http_source = mlrun.datastore.sources.HttpSource()\n",
    "news_set.spec.source = http_source\n",
    "\n",
    "# code_to_function our mlrun wrapped function to deploy the ingestion pipeline on.\n",
    "# the serving runtimes enables the deployment of our feature set's computational graph\n",
    "function = mlrun.code_to_function(name='get_news',kind='serving',image='mlrun/mlrun', requirements=['yahoo_fin','graphviz'], filename='src/news.py')\n",
    "\n",
    "function.spec.readiness_timeout = 3600\n",
    "\n",
    "run_config = fstore.RunConfig(function=function, local=False).apply(mlrun.mount_v3io())\n",
    "\n",
    "# Deploying\n",
    "news_set_endpoint = fstore.deploy_ingestion_service(featureset=news_set, run_config=run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3453c78",
   "metadata": {},
   "source": [
    "## Testing ingestion service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d417e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "t = requests.post(news_set_endpoint,json={'ticker':['news'],\n",
    "                                                 'Datetime': now,\n",
    "                                                 'n_stocks':NUMBER_OF_STOCKS})\n",
    "t.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4103487c",
   "metadata": {},
   "source": [
    "## Creating scheduled mlrun job to invoke our function every time delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c05a8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "body = {'ticker':['news'],\n",
    "        'Datetime': now,\n",
    "        'n_stocks':4}\n",
    "\n",
    "# specifying '0 8 * * *' as schedule will trigger the function every day at 08:00 AM\n",
    "fn = mlrun.code_to_function(name='ingestion_service_news',kind='job',image='mlrun/mlrun',handler='ingestion_service_invoker', filename='src/invoker.py')\n",
    "fn.run(params={'endpoint':news_set_endpoint, 'body': body}, schedule='0 */1 * * *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e711ac",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Deleting the schedule job\n",
    "mlrun.get_run_db().delete_schedule(project.name,'ingestion-service-news-ingestion_service_invoker')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-base",
   "language": "python",
   "name": "conda-env-mlrun-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
