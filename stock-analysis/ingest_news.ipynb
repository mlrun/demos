{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook handles ingestion of stocks data to feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to align client/server mlrun version\n",
    "# !/User/align_mlrun.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-05-22 11:29:08,201 [info] created and saved project stocks\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "project = mlrun.get_or_create_project(name='stocks',user_project=True, context=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b> Steps </b>\n",
    "> * [Creating mlrun function that reads stocks from yahoo_fin and returning record oriented json](#Creating-mlrun-function-that-reads-stocks-from-yahoo_fin-and-returning-record-oriented-json)\n",
    "> * [Creating a feature set and declaring the graph](#Creating-a-feature-set-and-declaring-the-graph)\n",
    "> * [Dummy ingestion, Deploying ingestion service and getting ingestion endpoint](#Dummy-ingestion,-Deploying-ingestion-service-and-getting-ingestion-endpoint)\n",
    "> * [Testing ingestion service](#Testing-ingestion-service)\n",
    "> * [Creating scheduled mlrun job to invoke our function every time delta](#Creating-scheduled-mlrun-job-to-invoke-our-function-every-time-delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yahoo_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating mlrun function that reads stocks from yahoo_fin and returning record oriented json\n",
    "similar to ingest_stocks, we collect the data from within the feature-set graph. <br>\n",
    "event sent to graph is real-time configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlrun: start-code\n",
    "\n",
    "import yahoo_fin.stock_info as si\n",
    "import yahoo_fin.news as ynews\n",
    "from dateutil import parser\n",
    "import pandas as pd \n",
    "import json\n",
    "import requests\n",
    "from storey import MapClass, Event\n",
    "import string\n",
    "import mlrun\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "def get_news(event):\n",
    "    '''\n",
    "    event: dict with the following keys:\n",
    "    n_stocks - how many stocks to collect\n",
    "    '''\n",
    "    tickers = si.tickers_sp500()[:event['n_stocks']]\n",
    "    tickers_news = []\n",
    "    for ticker in tickers:\n",
    "        news = ynews.get_yf_rss(ticker=ticker)\n",
    "        news_df = pd.DataFrame(news)\n",
    "        df_copy = news_df[['title','summary','link','published']].copy()\n",
    "        df_copy['ticker'] = ticker\n",
    "        df_copy['Datetime'] = df_copy['published'].apply(lambda x: parser.parse(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        df_copy['summary'] = df_copy['summary'].apply(lambda x:remove_punctuation(x))\n",
    "        df_copy['title'] = df_copy['title'].apply(lambda x:remove_punctuation(x))\n",
    "        tickers_news.append(df_copy)\n",
    "    df = pd.concat(tickers_news).reset_index(drop=True)\n",
    "    return json.loads(df.to_json(orient='records'))\n",
    "\n",
    "class sentiment_analysis(MapClass):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        model_location = 'https://iguazio-sample-data.s3.amazonaws.com/models/model.pt'\n",
    "        fn = mlrun.import_function('hub://sentiment_analysis_serving')\n",
    "        fn.add_model('sentiment_analysis_model', model_path=model_location, class_name='SentimentClassifierServing')\n",
    "        self.sentiment_model_endpoint = fn.deploy()\n",
    "        \n",
    "    def do(self,event):\n",
    "        event.body['sentiment'] = json.loads(requests.put(self.sentiment_model_endpoint + \"/v2/models/sentiment_analysis_model/predict\",\n",
    "                                                     json=json.dumps({'inputs':[event.body['summary']]})).text)['outputs'][0]/2 # so it'll be 0 for neg, 0.5 for neutral and 1 for pos\n",
    "        \n",
    "        return Event(event.body,key=event.body['ticker'],time=event.body['Datetime'])\n",
    "    \n",
    "#mlrun: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a feature set and declaring the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"661pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 660.87 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-94 656.8666,-94 656.8666,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"38.5476,-27.0493 40.698,-27.1479 42.8263,-27.2953 44.9236,-27.4913 46.9815,-27.7353 48.9917,-28.0266 50.9463,-28.3645 52.8377,-28.7479 54.6587,-29.1759 56.4025,-29.6472 58.0628,-30.1606 59.634,-30.7147 61.1107,-31.308 62.4882,-31.9388 63.7625,-32.6054 64.9302,-33.3059 65.9882,-34.0385 66.9343,-34.8012 67.7669,-35.5918 68.4849,-36.4082 69.0878,-37.2481 69.5758,-38.1093 69.9496,-38.9894 70.2102,-39.886 70.3595,-40.7965 70.3997,-41.7186 70.3334,-42.6497 70.1636,-43.5873 69.8937,-44.5287 69.5276,-45.4713 69.0691,-46.4127 68.5225,-47.3503 67.8923,-48.2814 67.1831,-49.2035 66.3996,-50.114 65.5464,-51.0106 64.6285,-51.8907 63.6504,-52.7519 62.617,-53.5918 61.5329,-54.4082 60.4024,-55.1988 59.2299,-55.9615 58.0197,-56.6941 56.7755,-57.3946 55.5012,-58.0612 54.2002,-58.692 52.8757,-59.2853 51.5309,-59.8394 50.1684,-60.3528 48.7908,-60.8241 47.4003,-61.2521 45.9989,-61.6355 44.5886,-61.9734 43.1708,-62.2647 41.7472,-62.5087 40.3189,-62.7047 38.8872,-62.8521 37.4531,-62.9507 36.0175,-63 34.5815,-63 33.146,-62.9507 31.7119,-62.8521 30.2801,-62.7047 28.8519,-62.5087 27.4282,-62.2647 26.0105,-61.9734 24.6001,-61.6355 23.1988,-61.2521 21.8083,-60.8241 20.4306,-60.3528 19.0681,-59.8394 17.7233,-59.2853 16.3989,-58.692 15.0979,-58.0612 13.8236,-57.3946 12.5794,-56.6941 11.3691,-55.9615 10.1967,-55.1988 9.0662,-54.4082 7.982,-53.5918 6.9486,-52.7519 5.9706,-51.8907 5.0526,-51.0106 4.1995,-50.114 3.4159,-49.2035 2.7067,-48.2814 2.0765,-47.3503 1.53,-46.4127 1.0715,-45.4713 .7053,-44.5287 .4355,-43.5873 .2657,-42.6497 .1993,-41.7186 .2395,-40.7965 .3888,-39.886 .6495,-38.9894 1.0232,-38.1093 1.5112,-37.2481 2.1141,-36.4082 2.8321,-35.5918 3.6647,-34.8012 4.6109,-34.0385 5.6689,-33.3059 6.8365,-32.6054 8.1108,-31.9388 9.4884,-31.308 10.9651,-30.7147 12.5362,-30.1606 14.1966,-29.6472 15.9404,-29.1759 17.7614,-28.7479 19.6528,-28.3645 21.6074,-28.0266 23.6176,-27.7353 25.6755,-27.4913 27.7728,-27.2953 29.901,-27.1479 32.0515,-27.0493 34.2154,-27 36.3837,-27 38.5476,-27.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.2995\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<!-- get_news -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>get_news</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"161.1942\" cy=\"-45\" rx=\"54.6905\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"161.1942\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">get_news</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;get_news -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;get_news</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M70.0341,-45C78.1776,-45 87.1155,-45 96.1116,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.254,-48.5001 106.254,-45 96.2539,-41.5001 96.254,-48.5001\"/>\n",
       "</g>\n",
       "<!-- flatten_news -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>flatten_news</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"321.9831\" cy=\"-45\" rx=\"70.3881\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"321.9831\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flatten_news</text>\n",
       "</g>\n",
       "<!-- get_news&#45;&gt;flatten_news -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>get_news&#45;&gt;flatten_news</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M216.0789,-45C224.3179,-45 232.9556,-45 241.5932,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"241.7092,-48.5001 251.7091,-45 241.7091,-41.5001 241.7092,-48.5001\"/>\n",
       "</g>\n",
       "<!-- sentiment -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>sentiment</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"486.0218\" cy=\"-45\" rx=\"57.6901\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"486.0218\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sentiment</text>\n",
       "</g>\n",
       "<!-- flatten_news&#45;&gt;sentiment -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>flatten_news&#45;&gt;sentiment</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M392.5023,-45C400.96,-45 409.5841,-45 418.0053,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"418.1519,-48.5001 428.1518,-45 418.1518,-41.5001 418.1519,-48.5001\"/>\n",
       "</g>\n",
       "<!-- parquet -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>parquet</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M652.8666,-86.7273C652.8666,-88.5331 636.5068,-90 616.3666,-90 596.2265,-90 579.8666,-88.5331 579.8666,-86.7273 579.8666,-86.7273 579.8666,-57.2727 579.8666,-57.2727 579.8666,-55.4669 596.2265,-54 616.3666,-54 636.5068,-54 652.8666,-55.4669 652.8666,-57.2727 652.8666,-57.2727 652.8666,-86.7273 652.8666,-86.7273\"/>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M652.8666,-86.7273C652.8666,-84.9214 636.5068,-83.4545 616.3666,-83.4545 596.2265,-83.4545 579.8666,-84.9214 579.8666,-86.7273\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.3666\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">parquet</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;&gt;parquet -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>sentiment&#45;&gt;parquet</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M534.1871,-54.9771C545.8538,-57.3938 558.3023,-59.9724 569.8895,-62.3726\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"569.307,-65.8262 579.8091,-64.4274 570.7269,-58.9717 569.307,-65.8262\"/>\n",
       "</g>\n",
       "<!-- nosql -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>nosql</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M643.8666,-32.7273C643.8666,-34.5331 631.5407,-36 616.3666,-36 601.1926,-36 588.8666,-34.5331 588.8666,-32.7273 588.8666,-32.7273 588.8666,-3.2727 588.8666,-3.2727 588.8666,-1.4669 601.1926,0 616.3666,0 631.5407,0 643.8666,-1.4669 643.8666,-3.2727 643.8666,-3.2727 643.8666,-32.7273 643.8666,-32.7273\"/>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M643.8666,-32.7273C643.8666,-30.9214 631.5407,-29.4545 616.3666,-29.4545 601.1926,-29.4545 588.8666,-30.9214 588.8666,-32.7273\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.3666\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nosql</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;&gt;nosql -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>sentiment&#45;&gt;nosql</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M534.1871,-35.0229C548.8656,-31.9823 564.7817,-28.6854 578.663,-25.81\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"579.745,-29.1603 588.8272,-23.7046 578.3251,-22.3058 579.745,-29.1603\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f165f932490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlrun.feature_store as fstore\n",
    "from mlrun.feature_store.steps import DateExtractor, MapValues\n",
    "import yahoo_fin.stock_info as si\n",
    "\n",
    "# creating feature set\n",
    "news_set = fstore.FeatureSet(\"stocks_news\", \n",
    "                                 entities=[fstore.Entity(\"ticker\")],\n",
    "                                 timestamp_key='Datetime', \n",
    "                                 description=\"stocks news feature set\")\n",
    "\n",
    "# how many tickers data we ingest (make sure same number used for ingesting news)\n",
    "# n_tickers = 4\n",
    "\n",
    "news_set.graph\\\n",
    "    .to(name='get_news',handler='get_news')\\\n",
    "    .to(\"storey.steps.Flatten\", name=\"flatten_news\")\\\n",
    "    .to(\"sentiment_analysis\", \"sentiment\",full_event=True)\\\n",
    "\n",
    "news_set.set_targets(with_defaults=True) \n",
    "news_set.plot(rankdir=\"LR\", with_targets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy ingestion, Deploying ingestion service and getting ingestion endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-05-22 11:29:27,945 [info] Starting remote function deploy\n",
      "2022-05-22 11:29:28  (info) Deploying function\n",
      "2022-05-22 11:29:28  (info) Building\n",
      "2022-05-22 11:29:28  (info) Staging files and preparing base images\n",
      "2022-05-22 11:29:28  (info) Building processor image\n",
      "2022-05-22 11:31:13  (info) Build complete\n"
     ]
    }
   ],
   "source": [
    "# ingesting dummy (A MUST) \n",
    "import os\n",
    "import datetime\n",
    "\n",
    "name = os.environ['V3IO_USERNAME']\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "fstore.ingest(news_set,\n",
    "              pd.DataFrame.from_dict({'ticker':[name],\n",
    "                                      'Datetime': now,\n",
    "                                      'n_stocks':4}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HTTP Source to_dictable the HTTP trigger on our function and expose the endpoint.\n",
    "# There is an option to declare key and timestamp inside the http source (here we dont send data through the http hence not needed)\n",
    "http_source = mlrun.datastore.sources.HttpSource()\n",
    "news_set.spec.source = http_source\n",
    "\n",
    "# code_to_function our mlrun wrapped function to deploy the ingestion pipeline on.\n",
    "# the serving runtimes enables the deployment of our feature set's computational graph\n",
    "function = mlrun.code_to_function(name='get_news',kind='serving',image='mlrun/mlrun', requirements=['yahoo_fin','graphviz'])\n",
    "function.spec.readiness_timeout=100000\n",
    "\n",
    "run_config = fstore.RunConfig(function=function, local=False).apply(mlrun.mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploying\n",
    "news_set_endpoint = fstore.deploy_ingestion_service(featureset=news_set, run_config=run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ingestion service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "t = requests.post(news_set_endpoint,json={'ticker':['news'],\n",
    "                                                 'Datetime': now,\n",
    "                                                 'n_stocks':4})\n",
    "t.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating scheduled mlrun job to invoke our function every time delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('src',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/invoker.py\n",
    "\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "def ingestion_service_invoker(endpoint): \n",
    "    now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    t = requests.post(endpoint,json={'ticker':['news'],\n",
    "                                     'Datetime': now,\n",
    "                                     'n_stocks':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specifying '0 8 * * *' as schedule will trigger the function every day at 08:00 AM\n",
    "# fn = mlrun.code_to_function(name='ingestion_service_news',kind='job',image='mlrun/mlrun',handler='ingestion_service_invoker', filename='src/invoker.py')\n",
    "# fn.run(params={'endpoint':news_set_endpoint}, schedule='0 8 * * *')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
