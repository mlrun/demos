{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datacompy in /User/.pythonlibs/jupyter-dani/lib/python3.7/site-packages (0.7.2)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /User/.pythonlibs/jupyter-dani/lib/python3.7/site-packages (from datacompy) (1.2.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /conda/lib/python3.7/site-packages (from datacompy) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /conda/lib/python3.7/site-packages (from pandas>=0.25.0->datacompy) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /conda/lib/python3.7/site-packages (from pandas>=0.25.0->datacompy) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.25.0->datacompy) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datacompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio\n",
    "import v3io_frames as v3f\n",
    "import os\n",
    "import v3io.dataplane\n",
    "import json\n",
    "import mlrun.feature_store as fs\n",
    "from mlrun.feature_store.steps import *\n",
    "import pandas as pd\n",
    "import mlrun\n",
    "import datacompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio env -c V3IO_ACCESS_KEY=${V3IO_ACCESS_KEY}\n",
    "%nuclio env -c V3IO_USERNAME=${V3IO_USERNAME}\n",
    "%nuclio env -c V3IO_API=${V3IO_API}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    context.logger.info(\"Initializing Data-checkup Context\")\n",
    "    setattr(context, 'PROJECT_NAME', os.getenv('PROJECT_NAME', 'stocks-' + os.getenv('V3IO_USERNAME')))\n",
    "    mlrun.set_environment(project=context.PROJECT_NAME)\n",
    "    setattr(context,\"V3IO_ACCESS_KEY\", os.getenv(\"V3IO_ACCESS_KEY\",None))\n",
    "    setattr(context,\"V3IO_FRAMESD\", os.getenv(\"V3IO_FRAMESD\",'framesd:8081'))\n",
    "    setattr(context,\"V3IO_API\", os.getenv(\"V3IO_API\",None))\n",
    "    setattr(context, 'stocks_kv', os.getenv('STOCKS_KV', os.getenv('V3IO_USERNAME') + '/stocks/stocks_kv'))\n",
    "    setattr(context, 'stocks_stream', os.getenv('STOCKS_STREAM', os.getenv('V3IO_USERNAME') + '/stocks/stocks_stream'))\n",
    "    setattr(context, 'stocks_tsdb', os.getenv('STOCKS_TSDB_TABLE', os.getenv('V3IO_USERNAME') + '/stocks/stocks_tsdb'))\n",
    "    setattr(context, 'container', os.getenv('V3IO_CONTAINER', 'users'))\n",
    "    setattr(context, 'limit', os.getenv('LIMIT', 50))\n",
    "    \n",
    "    sym_to_url = {'GOOGL': 'google-inc', 'MSFT': 'microsoft-corp', 'AMZN': 'amazon-com-inc',\n",
    "                  'AAPL': 'apple-computer-inc', 'INTC' : 'intel-corp'}\n",
    "    setattr(context, 'sym_to_url', os.getenv('sym_to_url', sym_to_url))\n",
    "    \n",
    "    # setting up feature vector\n",
    "    setattr(context, 'stocks_vec', \"stocks-vec\")\n",
    "\n",
    "    # Setting up v3io client\n",
    "    client = v3f.Client(context.V3IO_FRAMESD, container=os.getenv('V3IO_CONTAINER', 'users'), token=context.V3IO_ACCESS_KEY)\n",
    "    setattr(context, 'v3io_client', client) \n",
    "    \n",
    "    # Setting up stream\n",
    "    dataplane_client = v3io.dataplane.Client(endpoint=context.V3IO_API, access_key=context.V3IO_ACCESS_KEY)\n",
    "    setattr(context, 'dataplane_client', dataplane_client) \n",
    "    \n",
    "    # loading shardes from stream, getting respone\n",
    "    resp = context.dataplane_client.seek_shard(container=context.container, path=f'{context.stocks_stream}/0', seek_type='EARLIEST')\n",
    "    setattr(context, 'next_location', resp.output.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_difference(context,df1,df2):\n",
    "    d=datacompy.Compare(df1,df2,join_columns='symbol')\n",
    "    if(d.df1_unq_rows.shape[0] > 0):\n",
    "        context.logger.info('Feature vector is not updated with the latest data')\n",
    "        context.logger.info(f'unmatched row : {d.df1_unq_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context):\n",
    "    # read from KV\n",
    "    kv_df = context.v3io_client.read(\"kv\",table = context.stocks_kv)\n",
    "    kv_df.reset_index(inplace = True, drop = False)\n",
    "    # read from stream\n",
    "    resp = context.dataplane_client.get_records(container=context.container, path=f'{context.stocks_stream}/0', location=context.next_location, limit=context.limit)\n",
    "    \n",
    "    # getting the data from the stream\n",
    "    all_data = []\n",
    "    for rec in resp.output.records:\n",
    "        rec_data = rec.data.decode('utf-8')\n",
    "        all_data.append(rec_data)\n",
    "        \n",
    "    # converting the data into a dict - for convenient \n",
    "    data_as_dict = []\n",
    "    for piece in all_data:\n",
    "        tag_dict = json.loads(str(piece))\n",
    "        data_as_dict.append(tag_dict)\n",
    "        \n",
    "    # converting to a dataframe and finding the most updated tickers timestamp\n",
    "    stream_df = pd.DataFrame(data_as_dict)\n",
    "    tickers = set(stream_df[\"symbol\"])\n",
    "    most_recent = {}\n",
    "    for ticker in tickers:\n",
    "        ticker_df = stream_df[stream_df[\"symbol\"] == ticker]\n",
    "        timestamp = max(ticker_df[\"time\"])\n",
    "        most_recent[ticker] = timestamp\n",
    "    most_recent = pd.DataFrame.from_dict(most_recent,orient = \"index\")\n",
    "    \n",
    "    # reading from feature vector\n",
    "    stock_list = []\n",
    "    service = fs.get_online_feature_service(context.stocks_vec)\n",
    "    for key,value in context.sym_to_url.items():\n",
    "        data = service.get([{\"symbol\": key}])[0]\n",
    "        data[\"symbol\"] = key\n",
    "        stock_list.append(data)\n",
    "    vector_df = pd.DataFrame(stock_list)\n",
    "    \n",
    "    vec_x_kv = vector_df[[col for col in kv_df.columns]]\n",
    "    check_difference(context,vec_x_kv,kv_df)\n",
    "    return check_difference(context,vec_x_kv,kv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python> 2021-04-06 08:06:16,897 [info] Initializing Data-checkup Context\n",
      "(0, 6)\n",
      "(0, 6)\n"
     ]
    }
   ],
   "source": [
    "init_context(context)\n",
    "s = handler(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
