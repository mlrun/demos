{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape news and Analyse sentiments\n",
    "This notebook shows an example of scraping news articles linked to specific traded companies and utilizing our predeployed sentiment analysis model server to predict the sentiment of the author towards said companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the nuclio-jupyter package is not installed run !pip install nuclio-jupyter\n",
    "import nuclio \n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio env -c V3IO_ACCESS_KEY=${V3IO_ACCESS_KEY}\n",
    "%nuclio env -c V3IO_USERNAME=${V3IO_USERNAME}\n",
    "%nuclio env -c V3IO_API=${V3IO_API}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install beautifulsoup4\n",
    "pip install pandas\n",
    "pip install v3io_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting kind to 'nuclio'\n",
      "%nuclio: setting spec.build.baseImage to 'mlrun/ml-models'\n"
     ]
    }
   ],
   "source": [
    "%%nuclio config \n",
    "kind = \"nuclio\"\n",
    "spec.build.baseImage = \"mlrun/ml-models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "import v3io_frames as v3f\n",
    "from unicodedata import normalize\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import mlrun.feature_store as fs\n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_news_page(stock_string):\n",
    "    request = Request('https://www.investing.com/equities/' + stock_string + '-news', headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    content = urlopen(request).read()\n",
    "    return bs(content, 'html.parser')\n",
    "\n",
    "def get_internal_article_links(page):\n",
    "    news = page.find_all('div', attrs={'class': 'mediumTitle1'})[1]\n",
    "    articles = news.find_all('article', attrs={'class': 'js-article-item articleItem'})\n",
    "    return ['https://www.investing.com' + a.find('a').attrs['href'] for a in articles]\n",
    "\n",
    "def get_article_page(article_link):\n",
    "    request = Request(article_link, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    content = urlopen(request).read()\n",
    "    return bs(content, 'html.parser')\n",
    "\n",
    "def clean_paragraph(paragraph):\n",
    "    paragraph = re.sub(r'\\(http\\S+', '', paragraph)\n",
    "    paragraph = re.sub(r'\\([A-Z]+:[A-Z]+\\)', '', paragraph)\n",
    "    paragraph = re.sub(r'[\\n\\t\\s\\']', ' ', paragraph)\n",
    "    return normalize('NFKD', paragraph)    \n",
    "\n",
    "def extract_text(article_page):\n",
    "    text_tag = article_page.find('div', attrs={'class': 'WYSIWYG articlePage'})\n",
    "    paragraphs = text_tag.find_all('p')\n",
    "    text = '\\n'.join([clean_paragraph(p.get_text()) for p in paragraphs[:-1]])\n",
    "    return text\n",
    "\n",
    "import json\n",
    "def get_publish_time(article):\n",
    "    tag = article.find('script',{\"type\" : \"application/ld+json\"}).contents[0]\n",
    "    tag_dict = json.loads(str(tag))\n",
    "    dateModified = tag_dict[\"dateModified\"]\n",
    "    return datetime.strftime(datetime.strptime(dateModified, '%Y-%m-%d %H:%M:%S'), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def get_score(paragraph_scores):\n",
    "    return sum([score - 1 for score in paragraph_scores['outputs']]) / len(paragraph_scores)\n",
    "\n",
    "def get_article_scores(context, articles, endpoint):\n",
    "    scores = [] \n",
    "    for i, article in enumerate(articles):\n",
    "        context.logger.info(f'getting score for article {i + 1}\\\\{len(articles)}')\n",
    "        event_data = {'inputs': article.split('\\n')}\n",
    "        resp = requests.put(endpoint, json=json.dumps(event_data))\n",
    "        scores.append(get_score(json.loads(resp.text)))\n",
    "    return scores\n",
    "\n",
    "def construct_dataframe(sentiments, items,times):\n",
    "    tickers = [x[0] for x in items]\n",
    "    stock_sent = pd.DataFrame({\"symbol\": tickers, \"sentiment\": sentiments, \"last_reaction\": times})\n",
    "    return stock_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    context.logger.info(\"init news reader context\")\n",
    "    setattr(context, 'PROJECT_NAME', os.getenv('PROJECT_NAME', 'stocks-' + os.getenv('V3IO_USERNAME')))\n",
    "    mlrun.set_environment(project = context.PROJECT_NAME)\n",
    "    \n",
    "    # Declaring feature set\n",
    "    stocks_sent_set = fs.FeatureSet(\"news\", entities=[fs.Entity(\"symbol\")])\n",
    "    setattr(context, 'stock_feature_set', stocks_sent_set)\n",
    "    \n",
    "    # Add aggregation \n",
    "    context.stock_feature_set.add_aggregation(\"sentiments\",\"sentiment\",[\"min\",\"max\"],[\"1h\"],\"10m\")\n",
    "    \n",
    "    # Initiazling featureset with dummy data that will be overtwritten later on\n",
    "    news_dummy = pd.DataFrame({\"symbol\":['GOOGL','MSFT','AMZN','AAPL','INTC'],\"sentiment\":[0,0,0,0,0],\"last_reaction\":[0,0,0,0,0]})\n",
    "    fs.ingest(context.stock_feature_set, news_dummy, infer_options=fs.InferOptions.default())\n",
    "    \n",
    "    v3io_framesd = os.getenv('V3IO_FRAMESD', 'framesd:8081')\n",
    "    token = os.getenv('TOKEN', '')\n",
    "    client = v3f.Client(v3io_framesd, container=os.getenv('V3IO_CONTAINER', 'users'), token=token)\n",
    "    setattr(context, 'v3c', client)\n",
    "\n",
    "    setattr(context, 'stocks_stream', os.getenv('STOCKS_STREAM', os.getenv('V3IO_USERNAME') + '/stocks/stocks_stream'))\n",
    "    context.v3c.create(backend='stream', table=context.stocks_stream, if_exists=1)\n",
    "\n",
    "    setattr(context, 'stocks_tsdb', os.getenv('STOCKS_TSDB_TABLE', os.getenv('V3IO_USERNAME') + '/stocks/stocks_tsdb'))\n",
    "    context.v3c.create(backend='tsdb', table=context.stocks_tsdb, rate='1/s', if_exists=1)\n",
    "\n",
    "    setattr(context, 'sentiment_model_endpoint',\n",
    "            os.getenv('SENTIMENT_MODEL_ENDPOINT', '')) # in the '' should be the model endpoint\n",
    "    context.logger.info(f\"set sentiment_model_endpoint {context.sentiment_model_endpoint}\")\n",
    "    sym_to_url = {'GOOGL': 'google-inc', 'MSFT': 'microsoft-corp', 'AMZN': 'amazon-com-inc',\n",
    "                  'AAPL': 'apple-computer-inc', 'INTC' : 'intel-corp'}\n",
    "    setattr(context, 'sym_to_url', sym_to_url)\n",
    "    setattr(context, 'stocks_kv', os.getenv('STOCKS_KV', os.getenv('V3IO_USERNAME') + '/stocks/stocks_kv'))\n",
    "    context.logger.info('end init context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, event):\n",
    "    context.logger.info(f'Getting news about {context.sym_to_url}')\n",
    "    syms = []\n",
    "    contents = []\n",
    "    links = []\n",
    "    times = []\n",
    "    sentiments = []\n",
    "    last_ticker_sentiment = []\n",
    "    last_ticker_time = []\n",
    "    for sym, url_string in context.sym_to_url.items():\n",
    "        context.logger.info(f'Getting news about {sym}')\n",
    "        news_page = get_stock_news_page(url_string)\n",
    "        article_links = get_internal_article_links(news_page)\n",
    "        article_pages = [get_article_page(link) for link in article_links]\n",
    "        articles = [extract_text(article_page) for article_page in article_pages]\n",
    "        curr_sentiments = get_article_scores(context, articles, context.sentiment_model_endpoint)\n",
    "        curr_times = [get_publish_time(article_page) for article_page in article_pages]\n",
    "\n",
    "        sentiments += curr_sentiments\n",
    "        times += curr_times\n",
    "        for article, link, sentiment, time in zip(articles, article_links, curr_sentiments, curr_times):\n",
    "            record = {\n",
    "                'content': article,\n",
    "                'time': time,\n",
    "                'symbol': sym,\n",
    "                'link': link,\n",
    "                'sentiment': sentiment\n",
    "            }\n",
    "            context.v3c.execute('stream', context.stocks_stream, 'put', args={'data': json.dumps(record)})\n",
    "\n",
    "            syms.append(sym)\n",
    "            contents.append(article)\n",
    "            links.append(link)\n",
    "        context.v3c.execute('kv', context.stocks_kv, command='update', args={'key': sym,\n",
    "                                                                             'expression': f\"SET sentiment='{sentiments[-1]}';last_reaction='{times[-1]}'\"})\n",
    "        last_ticker_sentiment.append(sentiments[-1])\n",
    "        last_ticker_time.append(times[-1])\n",
    "        \n",
    "    stock_sent = construct_dataframe(last_ticker_sentiment, context.sym_to_url.items(),last_ticker_time)\n",
    "    context.logger.info(f'Ingesting new information to feature store')\n",
    "    fs.ingest(context.stock_feature_set, stock_sent, infer_options=fs.InferOptions.default())\n",
    "\n",
    "    if len(sentiments) > 0:\n",
    "        df = pd.DataFrame.from_dict({'sentiment': sentiments,\n",
    "                                     'time': times,\n",
    "                                     'symbol': syms})\n",
    "        df = df.set_index(['time', 'symbol'])\n",
    "        df.index = df.index.set_levels([pd.to_datetime(df.index.levels[0]), df.index.levels[1]])\n",
    "        df = df.sort_index(level=0, axis=0)\n",
    "        context.v3c.write(backend='tsdb', table=context.stocks_tsdb, dfs=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def handler(context,event):\n",
    "#     update_news(context,event)\n",
    "#     return 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python> 2021-04-05 15:23:06,750 [info] init news reader context\n",
      "Python> 2021-04-05 15:23:06,757 [info] set sentiment_model_endpoint http://default-tenant.app.dev8.lab.iguazeng.com:32556\n",
      "Python> 2021-04-05 15:23:06,758 [info] end init context\n"
     ]
    }
   ],
   "source": [
    "init_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuclio import Event\n",
    "event = Event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python> 2021-04-05 15:23:07,950 [info] Getting news about {'GOOGL': 'google-inc', 'MSFT': 'microsoft-corp', 'AMZN': 'amazon-com-inc', 'AAPL': 'apple-computer-inc', 'INTC': 'intel-corp'}\n",
      "Python> 2021-04-05 15:23:07,951 [info] Getting news about GOOGL\n",
      "Python> 2021-04-05 15:23:21,318 [info] getting score for article 1\\5\n",
      "Python> 2021-04-05 15:23:21,947 [info] getting score for article 2\\5\n",
      "Python> 2021-04-05 15:23:22,533 [info] getting score for article 3\\5\n",
      "Python> 2021-04-05 15:23:22,738 [info] getting score for article 4\\5\n",
      "Python> 2021-04-05 15:23:23,448 [info] getting score for article 5\\5\n",
      "Python> 2021-04-05 15:23:23,862 [info] Getting news about MSFT\n",
      "Python> 2021-04-05 15:23:40,439 [info] getting score for article 1\\7\n",
      "Python> 2021-04-05 15:23:41,293 [info] getting score for article 2\\7\n",
      "Python> 2021-04-05 15:23:41,642 [info] getting score for article 3\\7\n",
      "Python> 2021-04-05 15:23:42,000 [info] getting score for article 4\\7\n",
      "Python> 2021-04-05 15:23:42,489 [info] getting score for article 5\\7\n",
      "Python> 2021-04-05 15:23:42,712 [info] getting score for article 6\\7\n",
      "Python> 2021-04-05 15:23:43,501 [info] getting score for article 7\\7\n",
      "Python> 2021-04-05 15:23:43,847 [info] Getting news about AMZN\n",
      "Python> 2021-04-05 15:23:53,830 [info] getting score for article 1\\4\n",
      "Python> 2021-04-05 15:23:53,979 [info] getting score for article 2\\4\n",
      "Python> 2021-04-05 15:23:54,256 [info] getting score for article 3\\4\n",
      "Python> 2021-04-05 15:23:55,740 [info] getting score for article 4\\4\n",
      "Python> 2021-04-05 15:23:56,264 [info] Getting news about AAPL\n",
      "Python> 2021-04-05 15:24:13,087 [info] getting score for article 1\\7\n",
      "Python> 2021-04-05 15:24:13,720 [info] getting score for article 2\\7\n",
      "Python> 2021-04-05 15:24:14,186 [info] getting score for article 3\\7\n",
      "Python> 2021-04-05 15:24:14,311 [info] getting score for article 4\\7\n",
      "Python> 2021-04-05 15:24:14,432 [info] getting score for article 5\\7\n",
      "Python> 2021-04-05 15:24:14,788 [info] getting score for article 6\\7\n",
      "Python> 2021-04-05 15:24:14,926 [info] getting score for article 7\\7\n",
      "Python> 2021-04-05 15:24:15,509 [info] Getting news about INTC\n",
      "Python> 2021-04-05 15:24:35,363 [info] getting score for article 1\\8\n",
      "Python> 2021-04-05 15:24:35,609 [info] getting score for article 2\\8\n",
      "Python> 2021-04-05 15:24:36,298 [info] getting score for article 3\\8\n",
      "Python> 2021-04-05 15:24:36,852 [info] getting score for article 4\\8\n",
      "Python> 2021-04-05 15:24:37,045 [info] getting score for article 5\\8\n",
      "Python> 2021-04-05 15:24:37,332 [info] getting score for article 6\\8\n",
      "Python> 2021-04-05 15:24:39,792 [info] getting score for article 7\\8\n",
      "Python> 2021-04-05 15:24:40,590 [info] getting score for article 8\\8\n",
      "Python> 2021-04-05 15:24:41,489 [info] Ingesting new information to feature store\n"
     ]
    }
   ],
   "source": [
    "handler(context, event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-03-25 11:32:58,659 [info] function spec saved to path: 02-read-news.yaml\n"
     ]
    }
   ],
   "source": [
    "from mlrun import code_to_function\n",
    "\n",
    "# Export bare function\n",
    "fn = code_to_function('read-news',\n",
    "                      handler='handler')\n",
    "fn.export('02-read-news.yaml')\n",
    "\n",
    "# Set parameters for current deployment\n",
    "fn.add_trigger('cron', nuclio.triggers.CronTrigger('10s'))\n",
    "fn.set_envs({'V3IO_CONTAINER': 'users',\n",
    "             'STOCKS_STREAM': os.getenv('V3IO_USERNAME') + '/stocks/stocks_stream',\n",
    "             'STOCKS_TSDB_TABLE': os.getenv('V3IO_USERNAME') + '/stocks/stocks_tsdb',\n",
    "             'SENTIMENT_MODEL_ENDPOINT': 'http://default-tenant.app.dev8.lab.iguazeng.com:31772',\n",
    "             'PROJECT_NAME' : \"stocks-test-dani\"})\n",
    "fn.spec.max_replicas = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-03-25 11:32:58,666 [info] Starting remote function deploy\n",
      "2021-03-25 11:32:58  (info) Deploying function\n",
      "2021-03-25 11:32:58  (info) Building\n",
      "2021-03-25 11:32:58  (info) Staging files and preparing base images\n",
      "2021-03-25 11:32:58  (info) Building processor image\n",
      "2021-03-25 11:33:00  (info) Build complete\n",
      "2021-03-25 11:33:06  (info) Function deploy complete\n",
      "> 2021-03-25 11:33:06,437 [info] function deployed, address=default-tenant.app.dev8.lab.iguazeng.com:30566\n"
     ]
    }
   ],
   "source": [
    "addr = fn.deploy(project='stocks-test-dani')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl {addr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
