{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Job with MLRun\n",
    "Run a Spark job which reads a csv file and logs the dataset to MLRun database.<br>\n",
    "This basic example can use as a schema for more complex workloads using MLRun and Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Function Kind and Base Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "# get build base image name by running the following code\n",
    "# copy and paste the output of this cell into config spec.build.baseImage\n",
    "# this will use us to config our spark job docker image\n",
    "import os\n",
    "os.environ[\"IGZ_DATANODE_REGISTRY_URL\"] + '/iguazio/shell:' + os.environ[\"IGZ_VERSION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting kind to 'job'\n",
      "%nuclio: setting spec.build.baseImage to 'datanode-registry.iguazio-platform.app.hsbctesting3.iguazio-cd0.com:80/iguazio/shell:3.0_katyak_debug_b1089_20201214154653'\n"
     ]
    }
   ],
   "source": [
    "# set the function kind and docker image\n",
    "%nuclio config kind = \"job\"\n",
    "%nuclio config spec.build.baseImage = \"datanode-registry.iguazio-platform.app.hsbctesting3.iguazio-cd0.com:80/iguazio/shell:3.0_katyak_debug_b1089_20201214154653\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build MLRun Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python\n",
    "\n",
    "import mlrun\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.execution import MLClientCtx\n",
    "\n",
    "from subprocess import run\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python\n",
    "\n",
    "run([\"/bin/bash\", \"/etc/config/v3io/spark-job-init.sh\"])\n",
    "\n",
    "def read_csv(context: MLClientCtx, \n",
    "             dataset: DataItem, \n",
    "             artifact_path):\n",
    "    \"\"\"\n",
    "    Read csv while using spark job and mlrun - generate serverless function\n",
    "    --------------------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "                context : MLClientCtx\n",
    "                          MLRun introduces a concept of a runtime \"context\", \n",
    "                          the code can be set up to get parameters and inputs from the context, \n",
    "                          as well as log run outputs, artifacts, tags, and time-series metrics in the context.\n",
    "                          \n",
    "                dataset : csv_file\n",
    "                          csv file which needs to be local (on our machine)\n",
    "                          the default location will be \"/v3io/projects/<file_name> \n",
    "                          which can be change by using mlrun.mount_v3io later in the function specs\n",
    "                          \n",
    "                artifact_path : String\n",
    "                          path on which the outout/artifacts of the fucntion will be saved\n",
    "                \n",
    "    Returns:\n",
    "                logged_dataset : mlrun_artifact\n",
    "                          dataset will be logged into mlrun database as dataset artifact\n",
    "    ---------------------------------------------------------------------------------------------\n",
    "    Notes:\n",
    "    ---------------------------------------------------------------------------------------------\n",
    "    Examples:\n",
    "    \"\"\"\n",
    "    \n",
    "    # get csv file location\n",
    "    location = dataset.local()\n",
    "    \n",
    "    # build spark session\n",
    "    spark = SparkSession.builder.appName(\"Spark job\").getOrCreate()\n",
    "    \n",
    "    # read csv\n",
    "    df = spark.read.load(location, \n",
    "                         format=\"csv\", \n",
    "                         sep=\",\", \n",
    "                         header=\"true\")\n",
    "    \n",
    "    # sample for logging\n",
    "    df_to_log = df.toPandas()\n",
    "    \n",
    "    # log final report\n",
    "    context.log_dataset(\"df_sample\", \n",
    "                        df=df_to_log,\n",
    "                        format=\"csv\", index=False,\n",
    "                        artifact_path=artifact_path)\n",
    "    \n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please don't remove the # nuclio: end-code cell above\n",
    "## Set MLRun Function Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save spark service name (based on Iguazio services dashboard)\n",
    "spark_service = \"spark\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun will transform the code above (up to nuclio: end-code cell) into serverless function \n",
    "# which will run in k8s pods\n",
    "fn = mlrun.code_to_function(handler=\"read_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply mount_v3io over our function so that our k8s pod which run our function\n",
    "# will be able to access our data (shared data access)\n",
    "fn.apply(mlrun.mount_v3io_extended())\n",
    "fn.apply(mlrun.platforms.iguazio.mount_v3iod(namespace=\"default-tenant\", v3io_config_configmap=spark_service + \"-submit\"))\n",
    "\n",
    "# skip pulling an image if it already exists. If you would like to always force a pull, \n",
    "# you can set the imagePullPolicy of the container to Always.\n",
    "fn.spec.image_pull_policy = \"IfNotPresent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add build commands to our docker image with required moduls\n",
    "fn.spec.build.commands = ['pip install matplotlib mlrun==0.6.0-rc6 pyspark']\n",
    "\n",
    "# sets environment param in our docker image\n",
    "fn.spec.build.extra = 'ENV PATH $PATH:/igz/.local/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and deploy our docker image\n",
    "fn.deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set MLRun and Run Function\n",
    "Once running the function get be monitored in MLRun UI, here in the notebook<br>\n",
    "And in out functions dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set mlrun api path and arrtifact path for logging\n",
    "artifact_path = mlrun.set_environment(api_path = 'http://mlrun-api:8080',\n",
    "                                      artifact_path = os.path.abspath('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-12-21 07:54:02,198 [info] starting run spark-mlrun-describe_spark uid=bc460cc9dd2b48ecbccee71fcd320204 DB=http://mlrun-api:8080\n",
      "> 2020-12-21 07:54:02,327 [info] Job is running in the background, pod: spark-mlrun-describe-spark-pfg8n\n",
      "20/12/21 07:54:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "+------+-----+-----------+----------+-----+\n",
      "|length|width|petallength|petalwidth|label|\n",
      "+------+-----+-----------+----------+-----+\n",
      "|   5.1|  3.5|        1.4|       0.2|    0|\n",
      "|   4.9|    3|        1.4|       0.2|    0|\n",
      "|   4.7|  3.2|        1.3|       0.2|    0|\n",
      "|   4.6|  3.1|        1.5|       0.2|    0|\n",
      "|     5|  3.6|        1.4|       0.2|    0|\n",
      "+------+-----+-----------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "> 2020-12-21 07:54:37,876 [info] run executed, status=completed\n",
      "final state: completed                                                          \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>default</td>\n",
       "      <td><div title=\"bc460cc9dd2b48ecbccee71fcd320204\"><a href=\"https://mlrun-ui.default-tenant.app.hsbctesting3.iguazio-cd0.com/projects/default/jobs/monitor/bc460cc9dd2b48ecbccee71fcd320204/info\" target=\"_blank\" >...cd320204</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Dec 21 07:54:19</td>\n",
       "      <td>completed</td>\n",
       "      <td>spark-mlrun-describe_spark</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=admin</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div><div class=\"dictlist\">host=spark-mlrun-describe-spark-pfg8n</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result74a7dd6a\" title=\"/files/iris.csv\">dataset</div></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result74a7dd6a\" title=\"/files/df_sample.csv\">df_sample</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result74a7dd6a-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result74a7dd6a-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result74a7dd6a\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result74a7dd6a-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run bc460cc9dd2b48ecbccee71fcd320204 --project default , !mlrun logs bc460cc9dd2b48ecbccee71fcd320204 --project default\n",
      "> 2020-12-21 07:54:40,740 [info] run executed, status=completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.model.RunObject at 0x7f116b4fc5d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run our functions with the relevant params\n",
    "fn.run(inputs={\"dataset\": \"iris.csv\"},\n",
    "       artifact_path=artifact_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}