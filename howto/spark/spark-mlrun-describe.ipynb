{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Job with MLRun\n",
    "Using MLRun to run Spark job.\n",
    "The Spark job will run a describe function, which generates profile report<br>\n",
    "from an Apache Spark DataFrame (Based on pandas_profiling).<br>\n",
    "\n",
    "For each column the following statistics - if relevant for the column type - are presented:\n",
    "\n",
    "**Essentials:** `type`, `unique values`, `missing values`,\n",
    "\n",
    "**Quantile statistics:** `minimum value`, `Q1`, `median`, `Q3`, `maximum`, `range`, `interquartile range`.\n",
    "\n",
    "**Descriptive statistics:** `mean`, `mode`, `standard deviation`, `sum`, `median absolute deviation`,<br> \n",
    "                            `coefficient of variation`, `kurtosis`, `skewness`.<br>\n",
    "                        \n",
    "**Most frequent values:** for categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package mlrun installed\n",
      "package matplotlib installed\n"
     ]
    }
   ],
   "source": [
    "# install prerequisites\n",
    "# prerequisites for the notebook is installing 2 packages yfinance yahoo_fin for uploading stocks data \n",
    "import importlib.util\n",
    "import IPython\n",
    "\n",
    "def install_missing_packages(packages):\n",
    "    install_flag = False\n",
    "    for package in packages:\n",
    "        spec = importlib.util.find_spec(package)\n",
    "        if spec is None:\n",
    "            %pip install {package}\n",
    "            install_flag = True\n",
    "        else:     \n",
    "            print(\"package {} installed\".format(package))\n",
    "        if install_flag:            \n",
    "            print (\"restarting kernerl due to package install\")\n",
    "            IPython.Application.instance().kernel.do_shutdown(True)\n",
    "# For illustrative purposes.\n",
    "packages  = ['mlrun', 'matplotlib']\n",
    "install_missing_packages(packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "from mlrun.platforms.iguazio import mount_v3io, mount_v3iod\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.execution import MLClientCtx\n",
    "\n",
    "import os\n",
    "from subprocess import run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql.types import LongType\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Spark Describe Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import base64 as b64\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from itertools import product\n",
    "import matplotlib\n",
    "\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from pkg_resources import resource_filename\n",
    "import six\n",
    "from pyspark.sql import DataFrame as SparkDataFrame\n",
    "from pyspark.sql.functions import (abs as df_abs, col, count, countDistinct,\n",
    "                                   max as df_max, mean, min as df_min,\n",
    "                                   sum as df_sum, when\n",
    "                                   )\n",
    "from pyspark.sql.functions import variance, stddev, kurtosis, skewness\n",
    "\n",
    "\n",
    "def describe(df, bins, corr_reject, config, **kwargs):\n",
    "    if not isinstance(df, SparkDataFrame):\n",
    "        raise TypeError(\"df must be of type pyspark.sql.DataFrame\")\n",
    "\n",
    "    # Number of rows:\n",
    "    table_stats = {\"n\": df.count()}\n",
    "    if table_stats[\"n\"] == 0:\n",
    "        raise ValueError(\"df cannot be empty\")\n",
    "\n",
    "    try:\n",
    "        # reset matplotlib style before use\n",
    "        matplotlib.style.use(\"default\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Function to \"pretty name\" floats:\n",
    "    def pretty_name(x):\n",
    "        x *= 100\n",
    "        if x == int(x):\n",
    "            return '%.0f%%' % x\n",
    "        else:\n",
    "            return '%.1f%%' % x\n",
    "\n",
    "    # Function to compute the correlation matrix:\n",
    "    def corr_matrix(df, columns=None):\n",
    "        if columns is None:\n",
    "            columns = df.columns\n",
    "        combinations = list(product(columns,columns))\n",
    "\n",
    "        def separate(l, n):\n",
    "            for i in range(0, len(l), n):\n",
    "                yield l[i:i+n]\n",
    "\n",
    "        grouped = list(separate(combinations,len(columns)))\n",
    "        df_cleaned = df.select(*columns).na.drop(how=\"any\")\n",
    "\n",
    "        for i in grouped:\n",
    "            for j in enumerate(i):\n",
    "                i[j[0]] = i[j[0]] + (df_cleaned.corr(str(j[1][0]), str(j[1][1])),)\n",
    "\n",
    "        df_pandas = pd.DataFrame(grouped).applymap(lambda x: x[2])\n",
    "        df_pandas.columns = columns\n",
    "        df_pandas.index = columns\n",
    "        \n",
    "        return df_pandas\n",
    "\n",
    "    # Compute histogram \n",
    "    def create_hist_data(df, column, minim, maxim, bins=10):\n",
    "\n",
    "        def create_all_conditions(current_col, column, left_edges, count=1):\n",
    "            \"\"\"\n",
    "            Recursive function that exploits the\n",
    "            ability to call the Spark SQL Column method\n",
    "            .when() in a recursive way.\n",
    "            \"\"\"\n",
    "            left_edges = left_edges[:]\n",
    "            if len(left_edges) == 0:\n",
    "                return current_col\n",
    "            if len(left_edges) == 1:\n",
    "                next_col = current_col.when(col(column) >= float(left_edges[0]), count)\n",
    "                left_edges.pop(0)\n",
    "                return create_all_conditions(next_col, column, left_edges[:], count+1)\n",
    "            next_col = current_col.when((float(left_edges[0]) <= col(column))\n",
    "                                        & (col(column) < float(left_edges[1])), count)\n",
    "            left_edges.pop(0)\n",
    "            return create_all_conditions(next_col, column, left_edges[:], count+1)\n",
    "\n",
    "        num_range = maxim - minim\n",
    "        bin_width = num_range / float(bins)\n",
    "        left_edges = [minim]\n",
    "        for _bin in range(bins):\n",
    "            left_edges = left_edges + [left_edges[-1] + bin_width]\n",
    "        left_edges.pop()\n",
    "        expression_col = when((float(left_edges[0]) <= col(column))\n",
    "                              & (col(column) < float(left_edges[1])), 0)\n",
    "        left_edges_copy = left_edges[:]\n",
    "        left_edges_copy.pop(0)\n",
    "        bin_data = (df.select(col(column))\n",
    "                    .na.drop()\n",
    "                    .select(col(column),\n",
    "                            create_all_conditions(expression_col,\n",
    "                                                  column,\n",
    "                                                  left_edges_copy\n",
    "                                                 ).alias(\"bin_id\")\n",
    "                           )\n",
    "                    .groupBy(\"bin_id\").count()\n",
    "                   ).toPandas()\n",
    "\n",
    "        # If no data goes into one bin, it won't \n",
    "        # appear in bin_data; so we should fill\n",
    "        # in the blanks:\n",
    "        bin_data.index = bin_data[\"bin_id\"]\n",
    "        new_index = list(range(bins))\n",
    "        bin_data = bin_data.reindex(new_index)\n",
    "        bin_data[\"bin_id\"] = bin_data.index\n",
    "        bin_data = bin_data.fillna(0)\n",
    "\n",
    "        bin_data[\"left_edge\"] = left_edges\n",
    "        bin_data[\"width\"] = bin_width\n",
    "        \n",
    "\n",
    "        return bin_data\n",
    "\n",
    "\n",
    "    def describe_integer_1d(df, column, current_result, nrows):\n",
    "        \n",
    "        stats_df = df.select(column).na.drop().agg(mean(col(column)).alias(\"mean\"),\n",
    "                                                       df_min(col(column)).alias(\"min\"),\n",
    "                                                       df_max(col(column)).alias(\"max\"),\n",
    "                                                       variance(col(column)).alias(\"variance\"),\n",
    "                                                       kurtosis(col(column)).alias(\"kurtosis\"),\n",
    "                                                       stddev(col(column)).alias(\"std\"),\n",
    "                                                       skewness(col(column)).alias(\"skewness\"),\n",
    "                                                       df_sum(col(column)).alias(\"sum\")\n",
    "                                                       ).toPandas()\n",
    "\n",
    "\n",
    "        for x in np.array([0.05, 0.25, 0.5, 0.75, 0.95]):\n",
    "            stats_df[pretty_name(x)] = (df.select(column)\n",
    "                                        .na.drop()\n",
    "                                        .selectExpr(\"percentile(`{col}`,CAST({n} AS DOUBLE))\"\n",
    "                                                    .format(col=column, n=x)).toPandas().iloc[:,0]\n",
    "                                        )\n",
    "        stats = stats_df.iloc[0].copy()\n",
    "        stats.name = column\n",
    "        stats[\"range\"] = stats[\"max\"] - stats[\"min\"]\n",
    "        stats[\"iqr\"] = stats[pretty_name(0.75)] - stats[pretty_name(0.25)]\n",
    "        stats[\"cv\"] = stats[\"std\"] / float(stats[\"mean\"])\n",
    "        stats[\"mad\"] = (df.select(column)\n",
    "                        .na.drop()\n",
    "                        .select(df_abs(col(column)-stats[\"mean\"]).alias(\"delta\"))\n",
    "                        .agg(df_sum(col(\"delta\"))).toPandas().iloc[0,0] / float(current_result[\"count\"]))\n",
    "        stats[\"type\"] = \"NUM\"\n",
    "        stats['n_zeros'] = df.select(column).where(col(column)==0.0).count()\n",
    "        stats['p_zeros'] = stats['n_zeros'] / float(nrows)\n",
    "\n",
    "        hist_data = create_hist_data(df, column, stats[\"min\"], stats[\"max\"], bins)\n",
    "\n",
    "        return stats\n",
    "\n",
    "    def describe_float_1d(df, column, current_result, nrows):\n",
    "        stats_df = df.select(column).na.drop().agg(mean(col(column)).alias(\"mean\"),\n",
    "                                                       df_min(col(column)).alias(\"min\"),\n",
    "                                                       df_max(col(column)).alias(\"max\"),\n",
    "                                                       variance(col(column)).alias(\"variance\"),\n",
    "                                                       kurtosis(col(column)).alias(\"kurtosis\"),\n",
    "                                                       stddev(col(column)).alias(\"std\"),\n",
    "                                                       skewness(col(column)).alias(\"skewness\"),\n",
    "                                                       df_sum(col(column)).alias(\"sum\")\n",
    "                                                       ).toPandas()\n",
    "\n",
    "        for x in np.array([0.05, 0.25, 0.5, 0.75, 0.95]):\n",
    "            stats_df[pretty_name(x)] = (df.select(column)\n",
    "                                        .na.drop()\n",
    "                                        .selectExpr(\"percentile_approx(`{col}`,CAST({n} AS DOUBLE))\"\n",
    "                                                    .format(col=column, n=x)).toPandas().iloc[:,0]\n",
    "                                        )\n",
    "        stats = stats_df.iloc[0].copy()\n",
    "        stats.name = column\n",
    "        stats[\"range\"] = stats[\"max\"] - stats[\"min\"]\n",
    "        stats[\"iqr\"] = stats[pretty_name(0.75)] - stats[pretty_name(0.25)]\n",
    "        stats[\"cv\"] = stats[\"std\"] / float(stats[\"mean\"])\n",
    "        stats[\"mad\"] = (df.select(column)\n",
    "                        .na.drop()\n",
    "                        .select(df_abs(col(column)-stats[\"mean\"]).alias(\"delta\"))\n",
    "                        .agg(df_sum(col(\"delta\"))).toPandas().iloc[0,0] / float(current_result[\"count\"]))\n",
    "        stats[\"type\"] = \"NUM\"\n",
    "        stats['n_zeros'] = df.select(column).where(col(column)==0.0).count()\n",
    "        stats['p_zeros'] = stats['n_zeros'] / float(nrows)\n",
    "\n",
    "        hist_data = create_hist_data(df, column, stats[\"min\"], stats[\"max\"], bins)\n",
    "\n",
    "        return stats\n",
    "\n",
    "    def describe_date_1d(df, column):\n",
    "        stats_df = df.select(column).na.drop().agg(df_min(col(column)).alias(\"min\"),\n",
    "                                                   df_max(col(column)).alias(\"max\")\n",
    "                                                  ).toPandas()\n",
    "        stats = stats_df.iloc[0].copy()\n",
    "        stats.name = column\n",
    "\n",
    "        if isinstance(stats[\"max\"], pd.Timestamp):\n",
    "            stats = stats.astype(object)\n",
    "            stats[\"max\"] = str(stats[\"max\"].to_pydatetime())\n",
    "            stats[\"min\"] = str(stats[\"min\"].to_pydatetime())\n",
    "\n",
    "        else:\n",
    "            stats[\"range\"] = stats[\"max\"] - stats[\"min\"]\n",
    "        stats[\"type\"] = \"DATE\"\n",
    "        return stats\n",
    "\n",
    "    def guess_json_type(string_value):\n",
    "        try:\n",
    "            obj = json.loads(string_value)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        return type(obj)\n",
    "\n",
    "    def describe_categorical_1d(df, column):\n",
    "        value_counts = (df.select(column).na.drop()\n",
    "                        .groupBy(column)\n",
    "                        .agg(count(col(column)))\n",
    "                        .orderBy(\"count({c})\".format(c=column),ascending=False)\n",
    "                       ).cache()\n",
    "\n",
    "        # Get the most frequent class:\n",
    "        stats = (value_counts\n",
    "                 .limit(1)\n",
    "                 .withColumnRenamed(column, \"top\")\n",
    "                 .withColumnRenamed(\"count({c})\".format(c=column), \"freq\")\n",
    "                ).toPandas().iloc[0]\n",
    "\n",
    "        # Get the top 50 classes by value count,\n",
    "        # and put the rest of them grouped at the\n",
    "        # end of the Series:\n",
    "        top_50 = value_counts.limit(50).toPandas().sort_values(\"count({c})\".format(c=column),\n",
    "                                                               ascending=False)\n",
    "        top_50_categories = top_50[column].values.tolist()\n",
    "\n",
    "        others_count = pd.Series([df.select(column).na.drop()\n",
    "                        .where(~(col(column).isin(*top_50_categories)))\n",
    "                        .count()\n",
    "                        ], index=[\"***Other Values***\"])\n",
    "        others_distinct_count = pd.Series([value_counts\n",
    "                                .where(~(col(column).isin(*top_50_categories)))\n",
    "                                .count()\n",
    "                                ], index=[\"***Other Values Distinct Count***\"])\n",
    "\n",
    "        top = top_50.set_index(column)[\"count({c})\".format(c=column)]\n",
    "        top = top.append(others_count)\n",
    "        top = top.append(others_distinct_count)\n",
    "        stats[\"value_counts\"] = top\n",
    "        stats[\"type\"] = \"CAT\"\n",
    "        value_counts.unpersist()\n",
    "        unparsed_valid_jsons = df.select(column).na.drop().rdd.map(\n",
    "            lambda x: guess_json_type(x[column])).filter(\n",
    "            lambda x: x).distinct().collect()\n",
    "        stats[\"unparsed_json_types\"] = unparsed_valid_jsons\n",
    "        return stats\n",
    "\n",
    "    def describe_constant_1d(df, column):\n",
    "        stats = pd.Series(['CONST'], index=['type'], name=column)\n",
    "        stats[\"value_counts\"] = (df.select(column)\n",
    "                                 .na.drop()\n",
    "                                 .limit(1)).toPandas().iloc[:,0].value_counts()\n",
    "        return stats\n",
    "\n",
    "    def describe_unique_1d(df, column):\n",
    "        stats = pd.Series(['UNIQUE'], index=['type'], name=column)\n",
    "        stats[\"value_counts\"] = (df.select(column)\n",
    "                                 .na.drop()\n",
    "                                 .limit(50)).toPandas().iloc[:,0].value_counts()\n",
    "        return stats\n",
    "\n",
    "    def describe_1d(df, column, nrows, lookup_config=None):\n",
    "        column_type = df.select(column).dtypes[0][1]\n",
    "        if (\"array\" in column_type) or (\"stuct\" in column_type) or (\"map\" in column_type):\n",
    "            raise NotImplementedError(\"Column {c} is of type {t} and cannot be analyzed\".format(c=column, t=column_type))\n",
    "\n",
    "        distinct_count = df.select(column).agg(countDistinct(col(column)).alias(\"distinct_count\")).toPandas()\n",
    "        non_nan_count = df.select(column).na.drop().select(count(col(column)).alias(\"count\")).toPandas()\n",
    "        results_data = pd.concat([distinct_count, non_nan_count],axis=1)\n",
    "        results_data[\"p_unique\"] = results_data[\"distinct_count\"] / float(results_data[\"count\"])\n",
    "        results_data[\"is_unique\"] = results_data[\"distinct_count\"] == nrows\n",
    "        results_data[\"n_missing\"] = nrows - results_data[\"count\"]\n",
    "        results_data[\"p_missing\"] = results_data[\"n_missing\"] / float(nrows)\n",
    "        results_data[\"p_infinite\"] = 0\n",
    "        results_data[\"n_infinite\"] = 0\n",
    "        result = results_data.iloc[0].copy()\n",
    "        result[\"memorysize\"] = 0\n",
    "        result.name = column\n",
    "\n",
    "        if result[\"distinct_count\"] <= 1:\n",
    "            result =  pd.concat([result,describe_constant_1d(df, column)])\n",
    "        elif column_type in {\"tinyint\", \"smallint\", \"int\", \"bigint\"}:\n",
    "            result =  pd.concat([result,describe_integer_1d(df, column, result, nrows)])                                \n",
    "        elif column_type in {\"float\", \"double\", \"decimal\"}:\n",
    "            result =  pd.concat([result,describe_float_1d(df, column, result, nrows)])                                                                            \n",
    "        elif column_type in {\"date\", \"timestamp\"}:\n",
    "            result =  pd.concat([result,describe_date_1d(df, column)])                                                                                                            \n",
    "        elif result[\"is_unique\"] == True:\n",
    "            result =  pd.concat([result,describe_unique_1d(df, column)])                                \n",
    "        else:\n",
    "            result =  pd.concat([result,describe_categorical_1d(df, column)])                    \n",
    "            result = result.append(describe_categorical_1d(df, column))\n",
    "            # Fix to also count MISSING value in the distict_count field:\n",
    "            if result[\"n_missing\"] > 0:\n",
    "                result[\"distinct_count\"] = result[\"distinct_count\"] + 1\n",
    "\n",
    "        if (result[\"count\"] > result[\"distinct_count\"] > 1):\n",
    "            try:\n",
    "                result[\"mode\"] = result[\"top\"]\n",
    "            except KeyError:\n",
    "                result[\"mode\"] = 0\n",
    "        else:\n",
    "            try:\n",
    "                result[\"mode\"] = result[\"value_counts\"].index[0]\n",
    "            except KeyError:\n",
    "                result[\"mode\"] = 0\n",
    "            # If and IndexError happens,\n",
    "            # it is because all column are NULLs:\n",
    "            except IndexError:\n",
    "                result[\"mode\"] = \"MISSING\"\n",
    "\n",
    "        if lookup_config:\n",
    "            lookup_object = lookup_config['object']\n",
    "            col_name_in_db = lookup_config['col_name_in_db'] if 'col_name_in_db' in lookup_config else None\n",
    "            try:\n",
    "                matched, unmatched = lookup_object.lookup(df.select(column), col_name_in_db)\n",
    "                result['lookedup_values'] = str(matched.count()) + \"/\" + str(df.select(column).count())\n",
    "            except:\n",
    "                result['lookedup_values'] = 'FAILED'\n",
    "        else:\n",
    "            result['lookedup_values'] = ''\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    # build final report:\n",
    "    ldesc = {}\n",
    "    for colum in df.columns:\n",
    "        if colum in config:\n",
    "            if 'lookup' in config[colum]:\n",
    "                lookup_config = config[colum]['lookup']\n",
    "                desc = describe_1d(df, colum, table_stats[\"n\"], lookup_config=lookup_config)\n",
    "            else:\n",
    "                desc = describe_1d(df, colum, table_stats[\"n\"])\n",
    "        else:\n",
    "            desc = describe_1d(df, colum, table_stats[\"n\"])\n",
    "        ldesc.update({colum: desc})\n",
    "\n",
    "    # Compute correlation matrix\n",
    "    if corr_reject is not None:\n",
    "        computable_corrs = [colum for colum in ldesc if ldesc[colum][\"type\"] in {\"NUM\"}]\n",
    "\n",
    "        if len(computable_corrs) > 0:\n",
    "            corr = corr_matrix(df, columns=computable_corrs)\n",
    "            for x, corr_x in corr.iterrows():\n",
    "                for y, corr in corr_x.items():\n",
    "                    if x == y:\n",
    "                        break\n",
    "\n",
    "    # Convert ldesc (final report) to a DataFrame\n",
    "    variable_stats = pd.DataFrame(ldesc)\n",
    "\n",
    "    # General statistics\n",
    "    table_stats[\"nvar\"] = len(df.columns)\n",
    "    table_stats[\"total_missing\"] = float(variable_stats.loc[\"n_missing\"].sum()) / (table_stats[\"n\"] * table_stats[\"nvar\"])\n",
    "    memsize = 0\n",
    "    table_stats['memsize'] = fmt_bytesize(memsize)\n",
    "    table_stats['recordsize'] = fmt_bytesize(memsize / table_stats['n'])\n",
    "    table_stats.update({k: 0 for k in (\"NUM\", \"DATE\", \"CONST\", \"CAT\", \"UNIQUE\", \"CORR\")})\n",
    "    table_stats.update(dict(variable_stats.loc['type'].value_counts()))\n",
    "    table_stats['REJECTED'] = table_stats['CONST'] + table_stats['CORR']\n",
    "\n",
    "    freq_dict = {}\n",
    "    for var in variable_stats:\n",
    "        if \"value_counts\" not in variable_stats[var]:\n",
    "            pass\n",
    "        elif not(variable_stats[var][\"value_counts\"] is np.nan):\n",
    "            freq_dict[var] = variable_stats[var][\"value_counts\"]\n",
    "        else:\n",
    "            pass\n",
    "    try:\n",
    "        variable_stats = variable_stats.drop(\"value_counts\")\n",
    "    except (ValueError, KeyError):\n",
    "        pass\n",
    "\n",
    "    return table_stats, variable_stats.T, freq_dict\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import abs as absou\n",
    "\n",
    "SKEWNESS_CUTOFF = 20\n",
    "DEFAULT_FLOAT_FORMATTER = u'spark_df_profiling.__default_float_formatter'\n",
    "\n",
    "# formmating functions\n",
    "def gradient_format(value, limit1, limit2, c1, c2):\n",
    "    def LerpColour(c1,c2,t):\n",
    "        return (int(c1[0]+(c2[0]-c1[0])*t),int(c1[1]+(c2[1]-c1[1])*t),int(c1[2]+(c2[2]-c1[2])*t))\n",
    "    c = LerpColour(c1, c2, (value-limit1)/(limit2-limit1))\n",
    "    return fmt_color(value,\"rgb{}\".format(str(c)))\n",
    "\n",
    "\n",
    "def fmt_color(text, color):\n",
    "    return(u'<span style=\"color:{color}\">{text}</span>'.format(color=color,text=str(text)))\n",
    "\n",
    "\n",
    "def fmt_class(text, cls):\n",
    "    return(u'<span class=\"{cls}\">{text}</span>'.format(cls=cls,text=str(text)))\n",
    "\n",
    "\n",
    "def fmt_bytesize(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if num < 0:\n",
    "            num = num*-1\n",
    "            if num < 1024.0:\n",
    "                return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "            num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "\n",
    "def fmt_percent(v):\n",
    "    return  \"{:2.1f}%\".format(v*100)\n",
    "\n",
    "def fmt_varname(v):\n",
    "    return u'<code>{0}</code>'.format(v)\n",
    "\n",
    "\n",
    "value_formatters={\n",
    "        u'freq': (lambda v: gradient_format(v, 0, 62000, (30, 198, 244), (99, 200, 72))),\n",
    "        u'p_missing': fmt_percent,\n",
    "        u'p_infinite': fmt_percent,\n",
    "        u'p_unique': fmt_percent,\n",
    "        u'p_zeros': fmt_percent,\n",
    "        u'memorysize': fmt_bytesize,\n",
    "        u'total_missing': fmt_percent,\n",
    "        DEFAULT_FLOAT_FORMATTER: lambda v: str(float('{:.5g}'.format(v))).rstrip('0').rstrip('.'),\n",
    "        u'correlation_var': lambda v: fmt_varname(v),\n",
    "        u'unparsed_json_types': lambda v: ', '.join([s.__name__ for s in v])\n",
    "        }\n",
    "\n",
    "def fmt_row_severity(v):\n",
    "    if np.isnan(v) or v<= 0.01:\n",
    "        return \"ignore\"\n",
    "    else:\n",
    "        return \"alert\"\n",
    "\n",
    "def fmt_skewness(v):\n",
    "    if not np.isnan(v) and (v<-SKEWNESS_CUTOFF or v> SKEWNESS_CUTOFF):\n",
    "        return \"alert\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "row_formatters={\n",
    "    u'p_zeros': fmt_row_severity,\n",
    "    u'p_missing': fmt_row_severity,\n",
    "    u'p_infinite': fmt_row_severity,\n",
    "    u'n_duplicates': fmt_row_severity,\n",
    "    u'skewness': fmt_skewness,\n",
    "}\n",
    "\n",
    "## Set Spark Describe Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_spark(context: MLClientCtx, \n",
    "                   dataset: DataItem,\n",
    "                   bins: int=30,\n",
    "                   describe_extended: bool=True)-> None:\n",
    "    \"\"\"\n",
    "    Generates profile reports from an Apache Spark DataFrame. \n",
    "    Based on pandas_profiling, but for Spark's DataFrames instead of pandas.\n",
    "    For each column the following statistics - if relevant for the column type - are presented:\n",
    "    \n",
    "    Essentials: type, unique values, missing values\n",
    "    \n",
    "    Quantile statistics: minimum value, Q1, median, Q3, maximum, range, interquartile range\n",
    "    \n",
    "    Descriptive statistics: mean, mode, standard deviation, sum, median absolute deviation, \n",
    "                            coefficient of variation, kurtosis, skewness\n",
    "                            \n",
    "    Most frequent values: for categorical data \n",
    "    --------------------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "                context : MLClientCtx\n",
    "                          MLRun introduces a concept of a runtime \"context\", \n",
    "                          the code can be set up to get parameters and inputs from the context, \n",
    "                          as well as log run outputs, artifacts, tags, and time-series metrics in the context.\n",
    "                                      \n",
    "                dataset : csv_file\n",
    "                          csv file which needs to be local (on our machine)\n",
    "                          the default location will be \"/v3io/projects/<file_name> \n",
    "                          which can be change by using mlrun.mount_v3io later in the function specs\n",
    "                          \n",
    "                bins :    Integer\n",
    "                          Number of bin in histograms\n",
    "                          \n",
    "                describe_extended : Bool \n",
    "                         (True) set to False if the aim is to get a simple \n",
    "                         pandas.DataFrame.describe() like infomration\n",
    "    ---------------------------------------------------------------------------------------------\n",
    "    Examples: \n",
    "               run mlrun function example, inputs will be part of the function inputs.\n",
    "               artifact_path is part of mlrun function parameters which set the path \n",
    "               for logging artifacts, results, dataset, etc.\n",
    "               \n",
    "               function.run(inputs={\"dataset\": \"iris.csv\",\n",
    "                                    \"bins\": 30,\n",
    "                                    \"describe_extended\": True},\n",
    "                                     artifact_path=artifact_path)\n",
    "    \"\"\"\n",
    "    \n",
    "    # get file location\n",
    "    location = dataset.local()\n",
    "    \n",
    "    # build spark session\n",
    "    spark = SparkSession.builder.appName(\"Spark job\").config(\"spark.executor.memory\",\"6g\").getOrCreate()\n",
    "    \n",
    "    # read csv\n",
    "    df = spark.read.csv(location, header=True, inferSchema= True)\n",
    "\n",
    "    # No use for now\n",
    "    kwargs = []\n",
    "    \n",
    "    # take only numric column\n",
    "    float_cols = [item[0] for item in df.dtypes if item[1].startswith('float') or item[1].startswith('double')]\n",
    "    \n",
    "    if describe_extended == True:\n",
    "        \n",
    "        # run describe function\n",
    "        table, variables, freq = describe(df, bins, float_cols, kwargs)\n",
    "\n",
    "        # get summary table\n",
    "        tbl_1 = variables.reset_index()\n",
    "\n",
    "        # prep report \n",
    "        if len(freq) != 0:\n",
    "            tbl_2 = pd.DataFrame.from_dict(freq, orient = \"index\").sort_index().stack().reset_index()\n",
    "            tbl_2.columns = ['col', 'key', 'val']\n",
    "            tbl_2['Merged'] = [{key: val} for key, val in zip(tbl_2.key, tbl_2.val)]\n",
    "            tbl_2 = tbl_2.groupby('col', as_index=False).agg(lambda x: tuple(x))[['col','Merged']]\n",
    "\n",
    "            # get summary\n",
    "            summary = pd.merge(tbl_1, tbl_2, how='left', left_on='index', right_on='col')\n",
    "\n",
    "        else:\n",
    "            summary = tbl_1\n",
    "\n",
    "        # log final report\n",
    "        context.log_dataset(\"summary_stats\", \n",
    "                            df=summary,\n",
    "                            format=\"csv\", index=False,\n",
    "                            artifact_path=context.artifact_subpath('data'))\n",
    "\n",
    "        # log overview\n",
    "        context.log_results(table)\n",
    "    \n",
    "    else:\n",
    "        # run simple describe and save to pandas\n",
    "        tbl_1 = df.describe().toPandas()\n",
    "        \n",
    "        # save final report and transpose \n",
    "        summary = tbl_1.T\n",
    "        \n",
    "        # log final report\n",
    "        context.log_dataset(\"summary_stats\", \n",
    "                            df=summary,\n",
    "                            format=\"csv\", index=False,\n",
    "                            artifact_path=context.artifact_subpath('data'))\n",
    "    \n",
    "    # stop spark session\n",
    "    spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iris_dataset.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "\n",
    "def download_file(url,path):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    \n",
    "    #file_path = path+\"/\"+local_filename\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(\"/v3io/projects/\"+local_filename, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return local_filename\n",
    "\n",
    "url = \"https://s3.wasabisys.com/iguazio/data/iris/iris_dataset.csv\"\n",
    "\n",
    "download_file(url,'/v3io/projects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please don't remove the # nuclio: end-code cell above\n",
    "### Set MLRun Function Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spark/conf/spark-defaults.conf\n",
      "spark\n"
     ]
    }
   ],
   "source": [
    "#get spark service name\n",
    "from configparser import ConfigParser\n",
    "from itertools import chain\n",
    "\n",
    "parser = ConfigParser()\n",
    "configFilePath = os.environ['SPARK_HOME']+'/conf/spark-defaults.conf'\n",
    "print(configFilePath)\n",
    "with open(configFilePath) as lines:\n",
    "    lines = chain((\"[top]\",), lines)  # This line does the trick.\n",
    "    parser.read_file(lines)\n",
    "    spark_service_name = parser[\"top\"][\"spark.master\"].split(\"://\")[1].split(\"-master\")[0]   \n",
    "print(spark_service_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-10-25 08:06:12,175 [warning] Failed to add git metadata, ignore if path is not part of a git repo.: {'path': './', 'error': '/User/demos/howto/spark'}\n"
     ]
    }
   ],
   "source": [
    "# mlrun will transform the code above (up to nuclio: end-code cell) into serverless function \n",
    "# which will run in k8s pods\n",
    "fn = mlrun.code_to_function(handler=\"describe_spark\", kind=\"remote-spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-10-25 08:06:22,787 [info] Started building image: .mlrun/func-default-spark-mlrun-describe:latest\n",
      "\u001b[36mINFO\u001b[0m[0000] Retrieving image manifest gcr.io/iguazio/shell:3.5.4-b688.20230907171855 \n",
      "\u001b[36mINFO\u001b[0m[0000] Retrieving image gcr.io/iguazio/shell:3.5.4-b688.20230907171855 from registry gcr.io \n",
      "\u001b[36mINFO\u001b[0m[0000] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0000] Retrieving image manifest gcr.io/iguazio/shell:3.5.4-b688.20230907171855 \n",
      "\u001b[36mINFO\u001b[0m[0000] Returning cached image manifest              \n",
      "\u001b[36mINFO\u001b[0m[0000] Executing 0 build triggers                   \n",
      "\u001b[36mINFO\u001b[0m[0000] Building stage 'gcr.io/iguazio/shell:3.5.4-b688.20230907171855' [idx: '0', base-idx: '-1'] \n",
      "\u001b[36mINFO\u001b[0m[0000] Unpacking rootfs as cmd RUN pip install matplotlib pyspark requires it. \n",
      "\u001b[36mINFO\u001b[0m[0051] RUN pip install matplotlib pyspark           \n",
      "\u001b[36mINFO\u001b[0m[0051] Initializing snapshotter ...                 \n",
      "\u001b[36mINFO\u001b[0m[0051] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0081] Cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0081] Args: [-c pip install matplotlib pyspark]    \n",
      "\u001b[36mINFO\u001b[0m[0081] Util.Lookup returned: &{Uid:1000 Gid:1000 Username:iguazio Name: HomeDir:/igz} \n",
      "\u001b[36mINFO\u001b[0m[0081] Performing slow lookup of group ids for iguazio \n",
      "\u001b[36mINFO\u001b[0m[0081] Running: [/bin/sh -c pip install matplotlib pyspark] \n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 100.8 MB/s eta 0:00:00\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 316.9/316.9 MB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.9/301.9 kB 57.5 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.1/103.1 kB 29.6 MB/s eta 0:00:00\n",
      "Collecting python-dateutil>=2.7\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 54.0 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 109.8 MB/s eta 0:00:00\n",
      "Collecting numpy<2,>=1.21\n",
      "  Downloading numpy-1.26.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 78.4 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.4 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.43.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 111.2 MB/s eta 0:00:00\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 118.4 MB/s eta 0:00:00\n",
      "Collecting py4j==0.10.9.7\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.5/200.5 kB 41.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=3.1.0 in /conda/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425347 sha256=878d33c8b069f44eef1086d02d6e94bad0cafc0c5ee28eae044f84844e7737c7\n",
      "  Stored in directory: /igz/.cache/pip/wheels/23/6e/46/d22b2a968d8ca06247fd42f04d40a95741472068160bdd46dd\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, python-dateutil, pyspark, pyparsing, pillow, packaging, numpy, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.43.1 importlib-resources-6.1.0 kiwisolver-1.4.5 matplotlib-3.8.0 numpy-1.26.1 packaging-23.2 pillow-10.1.0 py4j-0.10.9.7 pyparsing-3.1.1 pyspark-3.5.0 python-dateutil-2.8.2\n",
      "\u001b[36mINFO\u001b[0m[0115] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0147] RUN python -m pip install --upgrade pip~=23.0 \n",
      "\u001b[36mINFO\u001b[0m[0147] Cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0147] Args: [-c python -m pip install --upgrade pip~=23.0] \n",
      "\u001b[36mINFO\u001b[0m[0147] Util.Lookup returned: &{Uid:1000 Gid:1000 Username:iguazio Name: HomeDir:/igz} \n",
      "\u001b[36mINFO\u001b[0m[0147] Performing slow lookup of group ids for iguazio \n",
      "\u001b[36mINFO\u001b[0m[0147] Running: [/bin/sh -c python -m pip install --upgrade pip~=23.0] \n",
      "Collecting pip~=23.0\n",
      "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 30.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3.1\n",
      "    Uninstalling pip-22.3.1:\n",
      "      Successfully uninstalled pip-22.3.1\n",
      "Successfully installed pip-23.3.1\n",
      "\u001b[36mINFO\u001b[0m[0149] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0168] RUN echo 'Installing /empty/requirements.txt...'; cat /empty/requirements.txt \n",
      "\u001b[36mINFO\u001b[0m[0168] Cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0168] Args: [-c echo 'Installing /empty/requirements.txt...'; cat /empty/requirements.txt] \n",
      "\u001b[36mINFO\u001b[0m[0168] Util.Lookup returned: &{Uid:1000 Gid:1000 Username:iguazio Name: HomeDir:/igz} \n",
      "\u001b[36mINFO\u001b[0m[0168] Performing slow lookup of group ids for iguazio \n",
      "\u001b[36mINFO\u001b[0m[0168] Running: [/bin/sh -c echo 'Installing /empty/requirements.txt...'; cat /empty/requirements.txt] \n",
      "Installing /empty/requirements.txt...\n",
      "\u001b[36mINFO\u001b[0m[0168] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0170] No files were changed, appending empty layer to config. No layer added to image. \n",
      "\u001b[36mINFO\u001b[0m[0170] RUN python -m pip install -r /empty/requirements.txt \n",
      "\u001b[36mINFO\u001b[0m[0170] Cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0170] Args: [-c python -m pip install -r /empty/requirements.txt] \n",
      "\u001b[36mINFO\u001b[0m[0170] Util.Lookup returned: &{Uid:1000 Gid:1000 Username:iguazio Name: HomeDir:/igz} \n",
      "\u001b[36mINFO\u001b[0m[0170] Performing slow lookup of group ids for iguazio \n",
      "\u001b[36mINFO\u001b[0m[0170] Running: [/bin/sh -c python -m pip install -r /empty/requirements.txt] \n",
      "mlrun[complete]==1.6.0-rc2Collecting mlrun==1.6.0-rc2 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading mlrun-1.6.0rc2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.26.9 in /conda/lib/python3.9/site-packages (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (1.26.14)\n",
      "Collecting chardet<4.0,>=3.0.2 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.4/133.4 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting GitPython>=3.1.30,~=3.1 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting aiohttp~=3.8 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading aiohttp-3.8.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohttp-retry~=2.8 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
      "Collecting click~=8.1 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting kfp<1.8.14,~=1.8.0 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading kfp-1.8.13.tar.gz (300 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.1/300.1 kB 21.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting nest-asyncio~=1.0 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading nest_asyncio-1.5.8-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting ipython~=8.10 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading ipython-8.16.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting nuclio-jupyter~=0.9.12 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading nuclio_jupyter-0.9.13-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting numpy<1.23.0,>=1.16.5 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.8/16.8 MB 106.3 MB/s eta 0:00:00\n",
      "Collecting pandas<3,>=1.2 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pandas-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting pyarrow<12,>=10.0 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pyarrow-11.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.9/34.9 MB 64.1 MB/s eta 0:00:00\n",
      "Collecting pyyaml~=5.1 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 630.1/630.1 kB 69.4 MB/s eta 0:00:00\n",
      "Collecting requests~=2.31 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tabulate~=0.8.6 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Collecting v3io~=0.5.21 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading v3io-0.5.21-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic>=1.10.8,~=1.10 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pydantic-1.10.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.6/149.6 kB 27.4 MB/s eta 0:00:00\n",
      "Collecting mergedeep~=1.3 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
      "Collecting v3io-frames~=0.10.7 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading v3io_frames-0.10.8-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting semver~=3.0 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting dask~=2023.9.0 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading dask-2023.9.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting distributed~=2023.9.0 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading distributed-2023.9.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting dependency-injector~=4.41 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading dependency_injector-4.41.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.1/4.1 MB 112.5 MB/s eta 0:00:00\n",
      "Collecting fsspec<2023.7,>=2023.1 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting v3iofs~=0.1.15 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading v3iofs-0.1.16-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting storey~=1.6.1 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading storey-1.6.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting inflection~=0.5.0 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
      "Collecting python-dotenv~=0.17.0 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading python_dotenv-0.17.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting setuptools~=68.2 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting deprecated~=1.2 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting jinja2~=3.1 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 27.3 MB/s eta 0:00:00\n",
      "Collecting anyio~=3.7 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting orjson~=3.9 (from mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading orjson-3.9.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.3/49.3 kB 8.1 MB/s eta 0:00:00\n",
      "Collecting adlfs<2023.5,>=2022.2 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading adlfs-2023.4.0-py3-none-any.whl (25 kB)\n",
      "Collecting aiobotocore<2.6,>=2.4.2 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading aiobotocore-2.5.4-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting avro~=1.11 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading avro-1.11.3.tar.gz (90 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.6/90.6 kB 17.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting azure-core~=1.24 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading azure_core-1.29.5-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting azure-identity~=1.5 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading azure_identity-1.14.1-py3-none-any.whl.metadata (72 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.2/72.2 kB 13.3 MB/s eta 0:00:00\n",
      "Collecting azure-keyvault-secrets~=4.2 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading azure_keyvault_secrets-4.7.0-py3-none-any.whl (348 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 348.6/348.6 kB 51.6 MB/s eta 0:00:00\n",
      "Collecting azure-storage-blob!=12.18.0,>=12.13 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading azure_storage_blob-12.18.3-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting boto3<1.27,>=1.24.59 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading boto3-1.26.165-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting databricks-sdk~=0.3.0 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading databricks_sdk-0.3.1-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting gcsfs<2023.7,>=2023.1 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading gcsfs-2023.6.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting google-cloud-bigquery~=3.2 (from google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_cloud_bigquery-3.12.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting graphviz~=0.20.0 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 9.9 MB/s eta 0:00:00\n",
      "Collecting kafka-python~=2.0 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 246.5/246.5 kB 42.7 MB/s eta 0:00:00\n",
      "Collecting msrest~=0.6.21 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.2/85.2 kB 15.9 MB/s eta 0:00:00\n",
      "Collecting plotly<5.12.0,~=5.4 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.3/15.3 MB 111.3 MB/s eta 0:00:00\n",
      "Collecting pyopenssl>=23 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pyOpenSSL-23.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting redis~=4.3 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading redis-4.6.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting s3fs<2023.7,>=2023.1 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading s3fs-2023.6.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting sqlalchemy~=1.4 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading SQLAlchemy-1.4.49-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting azure-datalake-store<0.1,>=0.0.46 (from adlfs<2023.5,>=2022.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading azure_datalake_store-0.0.53-py2.py3-none-any.whl (55 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.3/55.3 kB 6.2 MB/s eta 0:00:00\n",
      "Collecting botocore<1.31.18,>=1.31.17 (from aiobotocore<2.6,>=2.4.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading botocore-1.31.17-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<2.6,>=2.4.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 15.5 MB/s eta 0:00:00\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<2.6,>=2.4.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp~=3.8->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 11.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /conda/lib/python3.9/site-packages (from aiohttp~=3.8->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (2.0.4)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp~=3.8->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.2/114.2 kB 22.4 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp~=3.8->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp~=3.8->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 269.4/269.4 kB 44.3 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp~=3.8->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp~=3.8->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /conda/lib/python3.9/site-packages (from anyio~=3.7->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (3.4)\n",
      "Collecting sniffio>=1.1 (from anyio~=3.7->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting exceptiongroup (from anyio~=3.7->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /conda/lib/python3.9/site-packages (from azure-core~=1.24->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (1.16.0)\n",
      "Collecting typing-extensions>=4.6.0 (from azure-core~=1.24->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: cryptography>=2.5 in /conda/lib/python3.9/site-packages (from azure-identity~=1.5->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (38.0.4)\n",
      "Collecting msal<2.0.0,>=1.20.0 (from azure-identity~=1.5->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading msal-1.24.1-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions<2.0.0,>=0.3.0 (from azure-identity~=1.5->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting azure-common~=1.1 (from azure-keyvault-secrets~=4.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting isodate>=0.6.1 (from azure-keyvault-secrets~=4.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 kB 8.7 MB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of boto3 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting boto3<1.27,>=1.24.59 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading boto3-1.26.164-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.163-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.162-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.161-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.160-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.159-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.158-py3-none-any.whl.metadata (7.0 kB)\n",
      "INFO: pip is still looking at multiple versions of boto3 to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading boto3-1.26.157-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.156-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.155-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.154-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.153-py3-none-any.whl.metadata (7.0 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading boto3-1.26.152-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.151-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.150-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.149-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.148-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.147-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.146-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.145-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.144-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.143-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.142-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.141-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.140-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.139-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.138-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.137-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.136-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.135-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.134-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading boto3-1.26.133-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 25.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.132-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 23.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.131-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 21.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.130-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 25.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.129-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 25.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.128-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 21.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.127-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 26.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.126-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 24.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.125-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 23.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.124-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 21.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.123-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 20.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.122-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 23.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.121-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 22.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.120-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 26.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.119-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 21.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.118-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 24.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.117-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 20.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.116-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 21.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.115-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 25.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.114-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 18.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.113-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 21.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.112-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 23.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.111-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 25.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.110-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 22.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.109-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 24.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.108-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 26.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.107-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 26.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.106-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 28.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.105-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 25.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.104-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 25.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.103-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 24.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.102-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 24.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.101-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.5/135.5 kB 21.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.100-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.5/135.5 kB 24.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.99-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.5/135.5 kB 24.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.98-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.5/135.5 kB 22.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.97-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.5/135.5 kB 26.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.96-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.5/135.5 kB 25.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.95-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.5/135.5 kB 22.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.94-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.1/135.1 kB 24.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.93-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.1/135.1 kB 23.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.92-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 23.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.91-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 24.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.90-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 20.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.89-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 22.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.88-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 19.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.87-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 24.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.86-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 22.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.85-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 21.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.84-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 23.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.83-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 19.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.82-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 22.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.81-py3-none-any.whl (134 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.7/134.7 kB 18.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.80-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.79-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 21.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.78-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 4.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.77-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.76-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 19.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.75-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.74-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 25.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.73-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.72-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 25.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.71-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 24.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.70-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 26.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.69-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.68-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 26.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.67-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.66-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.65-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 18.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.64-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 19.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.63-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 16.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.62-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 21.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.61-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.60-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.59-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 24.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.58-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 24.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.57-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 20.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.56-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.55-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 21.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.54-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 26.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.53-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 25.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.52-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.51-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.50-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 21.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.49-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 25.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.48-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 25.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.47-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.46-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.45-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.44-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 20.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.43-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 17.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.42-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 20.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.41-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.40-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 12.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.39-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.38-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.37-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 21.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.36-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 23.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.35-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.34-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 25.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.33-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 21.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.32-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.7/132.7 kB 22.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.31-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 18.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.30-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 22.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.29-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 21.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.28-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 24.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.27-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 22.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.26-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 24.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.25-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 20.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.24-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 22.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.23-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 23.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.22-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 24.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.21-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 26.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.20-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 19.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.19-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 24.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.18-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 19.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.17-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.6/132.6 kB 21.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.16-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 22.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.15-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.14-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.13-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.12-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.11-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 21.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.10-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 23.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.9-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.8-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 21.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.7-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 23.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.6-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 18.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.5-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 25.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.4-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 23.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.3-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 22.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.2-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 17.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.1-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 15.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.26.0-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 19.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.25.5-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 22.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.25.4-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 24.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.25.3-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 23.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.25.2-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 14.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.25.1-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.25.0-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 16.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.96-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 18.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.95-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 23.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.94-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.93-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 26.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.92-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 24.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.91-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 25.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.90-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 22.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.89-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.88-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 21.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.87-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 23.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.86-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 18.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.85-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 25.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.84-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 23.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.83-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 21.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.82-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 21.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.81-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 21.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.80-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 21.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.79-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 21.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.78-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 25.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.77-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 25.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.76-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 18.4 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.75-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.74-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 25.8 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.73-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 25.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.72-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 26.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.71-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 24.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.70-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 22.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.69-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 22.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.68-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 24.1 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.67-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 24.5 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.66-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 25.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.65-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 21.6 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.64-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 24.9 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.63-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 25.3 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.62-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 22.0 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.61-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 23.7 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.60-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 20.2 MB/s eta 0:00:00\n",
      "  Downloading boto3-1.24.59-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 kB 26.2 MB/s eta 0:00:00\n",
      "Collecting aiobotocore<2.6,>=2.4.2 (from mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading aiobotocore-2.5.3-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading aiobotocore-2.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting botocore<1.29.162,>=1.29.161 (from aiobotocore<2.6,>=2.4.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading botocore-1.29.161-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<1.27,>=1.24.59->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3<1.27,>=1.24.59->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading s3transfer-0.6.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /conda/lib/python3.9/site-packages (from botocore<1.29.162,>=1.29.161->aiobotocore<2.6,>=2.4.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (2.8.2)\n",
      "Collecting cloudpickle>=1.5.0 (from dask~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /conda/lib/python3.9/site-packages (from dask~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (23.2)\n",
      "Collecting partd>=1.2.0 (from dask~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading partd-1.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /conda/lib/python3.9/site-packages (from dask~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /conda/lib/python3.9/site-packages (from dask~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (6.8.0)\n",
      "Collecting locket>=1.0.0 (from distributed~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting msgpack>=1.0.0 (from distributed~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading msgpack-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting psutil>=5.7.2 (from distributed~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting sortedcontainers>=2.0.5 (from distributed~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting tblib>=1.6.0 (from distributed~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tornado>=6.0.4 (from distributed~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting zict>=3.0.0 (from distributed~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.3/43.3 kB 8.6 MB/s eta 0:00:00\n",
      "Collecting decorator>4.1.2 (from gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting google-auth>=1.2 (from gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib (from gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-storage (from gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_cloud_storage-2.12.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.1.30,~=3.1->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting grpcio<2.0dev,>=1.47.0 (from google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading grpcio-1.59.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_api_core-2.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.15.0 (from google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading proto_plus-1.22.3-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.6.0 (from google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_cloud_core-2.3.3-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0 (from google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_resumable_media-2.6.0-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Collecting google-cloud-bigquery-storage<3.0.0dev,>=2.6.0 (from google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_cloud_bigquery_storage-2.22.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting db-dtypes<2.0.0dev,>=0.3.0 (from google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading db_dtypes-1.1.1-py2.py3-none-any.whl (14 kB)\n",
      "Collecting backcall (from ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting jedi>=0.16 (from ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting matplotlib-inline (from ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Collecting pickleshare (from ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 (from ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading prompt_toolkit-3.0.39-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pygments>=2.4.0 (from ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading Pygments-2.16.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting stack-data (from ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting traitlets>=5 (from ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading traitlets-5.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pexpect>4.3 (from ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.0/59.0 kB 11.2 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0 (from jinja2~=3.1->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting absl-py<2,>=0.9 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 24.3 MB/s eta 0:00:00\n",
      "Collecting google-cloud-storage (from gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 106.8/106.8 kB 19.7 MB/s eta 0:00:00\n",
      "Collecting kubernetes<19,>=8.0.0 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading kubernetes-18.20.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 106.5 MB/s eta 0:00:00\n",
      "Collecting google-api-python-client<2,>=1.7.8 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.1/62.1 kB 10.2 MB/s eta 0:00:00\n",
      "Collecting google-auth>=1.2 (from gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.9/152.9 kB 29.5 MB/s eta 0:00:00\n",
      "Collecting requests-toolbelt<1,>=0.8.0 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 11.6 MB/s eta 0:00:00\n",
      "Collecting cloudpickle>=1.5.0 (from dask~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.1/58.1 kB 12.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jsonschema<4,>=3.0.1 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 kB 11.2 MB/s eta 0:00:00\n",
      "Collecting strip-hints<1,>=0.1.8 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docstring-parser<1,>=0.7.3 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.14 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Collecting fire<1,>=0.3.1 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.3/88.3 kB 18.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 84.1 MB/s eta 0:00:00\n",
      "Collecting uritemplate<4,>=3.0.1 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting typer<1.0,>=0.3.2 (from kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.9/45.9 kB 9.3 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest~=0.6.21->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /conda/lib/python3.9/site-packages (from msrest~=0.6.21->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (2023.7.22)\n",
      "Collecting nbconvert>=6.4.5 (from nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading nbconvert-7.9.2-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting notebook<7.0.0,>=6.4 (from nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading notebook-6.5.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.2->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas<3,>=1.2->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.8/341.8 kB 45.5 MB/s eta 0:00:00\n",
      "Collecting tenacity>=6.2.0 (from plotly<5.12.0,~=5.4->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy~=1.4->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading greenlet-3.0.0-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting xxhash>=1 (from storey~=1.6.1->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting nuclio-sdk>=0.5.3 (from storey~=1.6.1->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading nuclio_sdk-0.5.7-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting future>=0.18.2 (from v3io~=0.5.21->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 840.9/840.9 kB 87.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ujson>=3 (from v3io~=0.5.21->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading ujson-5.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting googleapis-common-protos>=1.5.3 (from v3io-frames~=0.10.7->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting grpcio-tools!=1.34.0,<1.49,>=1.30 (from v3io-frames~=0.10.7->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading grpcio_tools-1.48.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 57.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cffi in /conda/lib/python3.9/site-packages (from azure-datalake-store<0.1,>=0.0.46->adlfs<2023.5,>=2022.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (1.15.1)\n",
      "Collecting termcolor (from fire<1,>=0.3.1->kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.1.30,~=3.1->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "INFO: pip is looking at multiple versions of google-api-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 120.3/120.3 kB 23.3 MB/s eta 0:00:00\n",
      "  Downloading google_api_core-2.10.2-py3-none-any.whl (115 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.6/115.6 kB 21.8 MB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0 (from google-api-python-client<2,>=1.7.8->kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.9/96.9 kB 18.4 MB/s eta 0:00:00\n",
      "Collecting google-auth-httplib2>=0.0.3 (from google-api-python-client<2,>=1.7.8->kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_auth_httplib2-0.1.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth>=1.2->gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.2->gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 31.1 MB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.2->gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "INFO: pip is looking at multiple versions of google-cloud-bigquery-storage to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-bigquery-storage<3.0.0dev,>=2.6.0 (from google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_cloud_bigquery_storage-2.21.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading google_cloud_bigquery_storage-2.20.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading google_cloud_bigquery_storage-2.19.1-py2.py3-none-any.whl (190 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.1/190.1 kB 37.9 MB/s eta 0:00:00\n",
      "  Downloading google_cloud_bigquery_storage-2.19.0-py2.py3-none-any.whl (190 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.2/190.2 kB 31.0 MB/s eta 0:00:00\n",
      "  Downloading google_cloud_bigquery_storage-2.18.1-py2.py3-none-any.whl (189 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189.8/189.8 kB 33.3 MB/s eta 0:00:00\n",
      "  Downloading google_cloud_bigquery_storage-2.18.0-py2.py3-none-any.whl (187 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 187.7/187.7 kB 35.8 MB/s eta 0:00:00\n",
      "  Downloading google_cloud_bigquery_storage-2.17.0-py2.py3-none-any.whl (187 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 187.7/187.7 kB 34.2 MB/s eta 0:00:00\n",
      "INFO: pip is still looking at multiple versions of google-cloud-bigquery-storage to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading google_cloud_bigquery_storage-2.16.2-py2.py3-none-any.whl (185 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 185.4/185.4 kB 32.4 MB/s eta 0:00:00\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /conda/lib/python3.9/site-packages (from importlib-metadata>=4.13.0->dask~=2023.9.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (3.16.2)\n",
      "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.8/100.8 kB 22.3 MB/s eta 0:00:00\n",
      "Collecting pyrsistent>=0.14.0 (from jsonschema<4,>=3.0.1->kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 12.7 MB/s eta 0:00:00\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes<19,>=8.0.0->kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading websocket_client-1.6.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.20.0->azure-identity~=1.5->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting portalocker<3,>=1.0 (from msal-extensions<2.0.0,>=0.3.0->azure-identity~=1.5->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.0/143.0 kB 28.0 MB/s eta 0:00:00\n",
      "Collecting bleach!=5.0.0 (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting jupyter-core>=4.7 (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jupyter_core-5.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading nbclient-0.8.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading nbformat-5.9.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting tinycss2 (from nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting pyzmq<25,>=17 (from notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pyzmq-24.0.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 91.4 MB/s eta 0:00:00\n",
      "Collecting argon2-cffi (from notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-client<8,>=5.3.4 (from notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.5/133.5 kB 25.1 MB/s eta 0:00:00\n",
      "Collecting ipython-genutils (from notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting ipykernel (from notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading ipykernel-6.26.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting Send2Trash>=1.8.0 (from notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading Send2Trash-1.8.2-py3-none-any.whl (18 kB)\n",
      "Collecting terminado>=0.8.3 (from notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading terminado-0.17.1-py3-none-any.whl (17 kB)\n",
      "Collecting prometheus-client (from notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading prometheus_client-0.17.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting nbclassic>=0.4.7 (from notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading nbclassic-1.0.0-py3-none-any.whl (10.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.0/10.0 MB 132.1 MB/s eta 0:00:00\n",
      "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading wcwidth-0.2.8-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest~=0.6.21->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 23.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel in /conda/lib/python3.9/site-packages (from strip-hints<1,>=0.1.8->kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (0.38.4)\n",
      "INFO: pip is looking at multiple versions of google-auth-oauthlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-auth-oauthlib (from gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "  Downloading google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB)\n",
      "  Downloading google_auth_oauthlib-0.7.1-py2.py3-none-any.whl (19 kB)\n",
      "  Downloading google_auth_oauthlib-0.7.0-py2.py3-none-any.whl (19 kB)\n",
      "  Downloading google_auth_oauthlib-0.5.3-py2.py3-none-any.whl (19 kB)\n",
      "Collecting executing>=1.2.0 (from stack-data->ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading executing-2.0.0-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting asttokens>=2.1.0 (from stack-data->ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading asttokens-2.4.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pure-eval (from stack-data->ipython~=8.10->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pycparser in /conda/lib/python3.9/site-packages (from cffi->azure-datalake-store<0.1,>=0.0.46->adlfs<2023.5,>=2022.2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (2.21)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery~=3.2->google-cloud-bigquery[bqstorage,pandas]~=3.2; extra == \"complete\"->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading grpcio_status-1.58.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.56.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.55.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.54.0-py3-none-any.whl (5.1 kB)\n",
      "  Downloading grpcio_status-1.53.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.0-py3-none-any.whl (5.1 kB)\n",
      "  Downloading grpcio_status-1.51.3-py3-none-any.whl (5.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.51.1-py3-none-any.whl (5.1 kB)\n",
      "  Downloading grpcio_status-1.50.0-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.49.1-py3-none-any.whl (14 kB)\n",
      "  Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /conda/lib/python3.9/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp<1.8.14,~=1.8.0->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1)) (3.1.1)\n",
      "Collecting entrypoints (from jupyter-client<8,>=5.3.4->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting platformdirs>=2.5 (from jupyter-core>=4.7->nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading platformdirs-3.11.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jupyter-server>=1.8 (from nbclassic>=0.4.7->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jupyter_server-2.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting notebook-shim>=0.2.3 (from nbclassic>=0.4.7->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading notebook_shim-0.2.3-py3-none-any.whl (13 kB)\n",
      "Collecting fastjsonschema (from nbformat>=5.7->nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading fastjsonschema-2.18.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs<2023.7,>=2023.1->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.9/83.9 kB 17.0 MB/s eta 0:00:00\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.2/86.2 kB 15.0 MB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert>=6.4.5->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting comm>=0.1.1 (from ipykernel->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading comm-0.1.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting debugpy>=1.6.5 (from ipykernel->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading debugpy-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting jupyter-events>=0.6.0 (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jupyter_events-0.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jupyter-server-terminals (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
      "Collecting overrides (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading overrides-7.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-events to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter-events>=0.6.0 (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading jupyter_events-0.7.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "  Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook<7.0.0,>=6.4->nuclio-jupyter~=0.9.12->mlrun==1.6.0-rc2->mlrun[complete]==1.6.0-rc2->-r /empty/requirements.txt (line 1))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "WARNING: jsonschema 3.2.0 does not provide the extra 'format-nongpl'\n",
      "Downloading mlrun-1.6.0rc2-py3-none-any.whl (978 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 978.5/978.5 kB 88.7 MB/s eta 0:00:00\n",
      "Downloading aiobotocore-2.5.2-py3-none-any.whl (72 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 15.5 MB/s eta 0:00:00\n",
      "Downloading boto3-1.26.161-py3-none-any.whl (135 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.9/135.9 kB 27.4 MB/s eta 0:00:00\n",
      "Downloading botocore-1.29.161-py3-none-any.whl (10.9 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 131.8 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.8.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 95.3 MB/s eta 0:00:00\n",
      "Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.9/80.9 kB 17.0 MB/s eta 0:00:00\n",
      "Downloading azure_core-1.29.5-py3-none-any.whl (192 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 192.4/192.4 kB 34.9 MB/s eta 0:00:00\n",
      "Downloading azure_identity-1.14.1-py3-none-any.whl (161 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.2/161.2 kB 35.6 MB/s eta 0:00:00\n",
      "Downloading azure_storage_blob-12.18.3-py3-none-any.whl (392 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 393.0/393.0 kB 52.9 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 20.7 MB/s eta 0:00:00\n",
      "Downloading dask-2023.9.3-py3-none-any.whl (1.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 106.8 MB/s eta 0:00:00\n",
      "Downloading databricks_sdk-0.3.1-py3-none-any.whl (271 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 271.3/271.3 kB 44.2 MB/s eta 0:00:00\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading distributed-2023.9.3-py3-none-any.whl (995 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 995.5/995.5 kB 88.5 MB/s eta 0:00:00\n",
      "Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 32.6 MB/s eta 0:00:00\n",
      "Downloading gcsfs-2023.6.0-py2.py3-none-any.whl (26 kB)\n",
      "Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.6/190.6 kB 37.1 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigquery-3.12.0-py2.py3-none-any.whl (220 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 220.4/220.4 kB 39.2 MB/s eta 0:00:00\n",
      "Downloading ipython-8.16.1-py3-none-any.whl (806 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 807.0/807.0 kB 83.5 MB/s eta 0:00:00\n",
      "Downloading nest_asyncio-1.5.8-py3-none-any.whl (5.3 kB)\n",
      "Downloading nuclio_jupyter-0.9.13-py3-none-any.whl (51 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.5/51.5 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading orjson-3.9.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.6/138.6 kB 27.8 MB/s eta 0:00:00\n",
      "Downloading pandas-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 129.4 MB/s eta 0:00:00\n",
      "Downloading pydantic-1.10.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 126.6 MB/s eta 0:00:00\n",
      "Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.0/59.0 kB 10.8 MB/s eta 0:00:00\n",
      "Downloading redis-4.6.0-py3-none-any.whl (241 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 241.1/241.1 kB 39.5 MB/s eta 0:00:00\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 12.8 MB/s eta 0:00:00\n",
      "Downloading s3fs-2023.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Using cached setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
      "Downloading SQLAlchemy-1.4.49-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 104.9 MB/s eta 0:00:00\n",
      "Downloading storey-1.6.1-py3-none-any.whl (161 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.1/161.1 kB 21.2 MB/s eta 0:00:00\n",
      "Downloading v3io-0.5.21-py3-none-any.whl (64 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.2/64.2 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading v3io_frames-0.10.8-py3-none-any.whl (35 kB)\n",
      "Downloading v3iofs-0.1.16-py3-none-any.whl (13 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 228.0/228.0 kB 39.8 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_resumable_media-2.6.0-py2.py3-none-any.whl (80 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.3/80.3 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 230.9/230.9 kB 39.3 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.0-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (610 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 610.4/610.4 kB 80.5 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.59.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 135.0 MB/s eta 0:00:00\n",
      "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 102.2 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading msal-1.24.1-py2.py3-none-any.whl (95 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.0/96.0 kB 20.3 MB/s eta 0:00:00\n",
      "Downloading msgpack-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (530 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 531.0/531.0 kB 64.4 MB/s eta 0:00:00\n",
      "Downloading nbconvert-7.9.2-py3-none-any.whl (256 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 256.4/256.4 kB 48.7 MB/s eta 0:00:00\n",
      "Downloading notebook-6.5.6-py3-none-any.whl (529 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 529.8/529.8 kB 69.9 MB/s eta 0:00:00\n",
      "Downloading nuclio_sdk-0.5.7-py2.py3-none-any.whl (24 kB)\n",
      "Downloading partd-1.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading prompt_toolkit-3.0.39-py3-none-any.whl (385 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.2/385.2 kB 60.6 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.22.3-py3-none-any.whl (48 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.1/48.1 kB 10.4 MB/s eta 0:00:00\n",
      "Downloading psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 283.6/283.6 kB 48.0 MB/s eta 0:00:00\n",
      "Downloading Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 108.2 MB/s eta 0:00:00\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 502.5/502.5 kB 67.3 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 17.0 MB/s eta 0:00:00\n",
      "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 427.7/427.7 kB 58.2 MB/s eta 0:00:00\n",
      "Downloading traitlets-5.12.0-py3-none-any.whl (84 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.0/84.0 kB 17.8 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Downloading ujson-5.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 11.5 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 193.8/193.8 kB 31.7 MB/s eta 0:00:00\n",
      "Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading asttokens-2.4.0-py2.py3-none-any.whl (27 kB)\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 162.8/162.8 kB 31.0 MB/s eta 0:00:00\n",
      "Downloading executing-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading google_auth_httplib2-0.1.1-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading jupyter_core-5.4.0-py3-none-any.whl (28 kB)\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.0/48.0 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading nbclient-0.8.0-py3-none-any.whl (73 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.1/73.1 kB 14.5 MB/s eta 0:00:00\n",
      "Downloading nbformat-5.9.2-py3-none-any.whl (77 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.6/77.6 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading websocket_client-1.6.4-py3-none-any.whl (57 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.3/57.3 kB 12.7 MB/s eta 0:00:00\n",
      "Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading ipykernel-6.26.0-py3-none-any.whl (114 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.3/114.3 kB 24.2 MB/s eta 0:00:00\n",
      "Downloading prometheus_client-0.17.1-py3-none-any.whl (60 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 13.5 MB/s eta 0:00:00\n",
      "Downloading wcwidth-0.2.8-py2.py3-none-any.whl (31 kB)\n",
      "Downloading comm-0.1.4-py3-none-any.whl (6.6 kB)\n",
      "Downloading debugpy-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 129.7 MB/s eta 0:00:00\n",
      "Downloading jupyter_server-2.9.0-py3-none-any.whl (377 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 377.7/377.7 kB 58.8 MB/s eta 0:00:00\n",
      "Downloading platformdirs-3.11.0-py3-none-any.whl (17 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading fastjsonschema-2.18.1-py3-none-any.whl (23 kB)\n",
      "Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: avro, kfp, fire, future, kfp-server-api, strip-hints\n",
      "  Building wheel for avro (pyproject.toml): started\n",
      "  Building wheel for avro (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for avro: filename=avro-1.11.3-py2.py3-none-any.whl size=123912 sha256=aeb0e6f8508b4158fd24c74b57aef45d511725a41bf4a51a14ff45d49d52aac6\n",
      "  Stored in directory: /igz/.cache/pip/wheels/86/49/c2/fc3ff718776289c141d01d69ffda1f3fb3798c8b0b5aac3c15\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.8.13-py3-none-any.whl size=422423 sha256=90927f23914fd4c76da73eca3ba6de24a877be9ef5c4ac833be29f5ca326d553\n",
      "  Stored in directory: /igz/.cache/pip/wheels/f1/8a/2c/9e05c111b747d0af00f3d454cb180afc8ad877ecbfdf582760\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116931 sha256=e0aa86b738d38dfd49b592ff36fcd1e587425f2ee318688c65b7d0831263aa36\n",
      "  Stored in directory: /igz/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=d55406515a0293d829294f53ea5f1c5a5eb3169c1bd88029e97db45c48809917\n",
      "  Stored in directory: /igz/.cache/pip/wheels/bf/5d/6a/2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99699 sha256=199d9f75244ea3df9ecc20fcb999504aea8d2e20926b4956c876dc1bb3d04bc2\n",
      "  Stored in directory: /igz/.cache/pip/wheels/eb/ee/9b/1bb6039c237dcc9586d2b2034107b003d86afc7cbdc7613b5d\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22283 sha256=71347f395711001ed97199ed3d30bf0976f271bcbbec30532f9eae82d9d48c1a\n",
      "  Stored in directory: /igz/.cache/pip/wheels/eb/82/45/f4240f75b8cd041477e71032ea28652c913c0323f479032018\n",
      "Successfully built avro kfp fire future kfp-server-api strip-hints\n",
      "Installing collected packages: webencodings, wcwidth, sortedcontainers, pytz, python-dotenv, pure-eval, ptyprocess, pickleshare, kafka-python, ipython-genutils, fastjsonschema, executing, chardet, backcall, azure-common, zict, xxhash, wrapt, websocket-client, uritemplate, ujson, tzdata, typing-extensions, traitlets, tornado, tinycss2, termcolor, tenacity, tblib, tabulate, strip-hints, soupsieve, sniffio, smmap, setuptools, Send2Trash, semver, rfc3986-validator, rfc3339-validator, requests, pyzmq, pyyaml, python-json-logger, pyrsistent, PyJWT, pygments, pyasn1, psutil, protobuf, prompt-toolkit, prometheus-client, portalocker, platformdirs, pexpect, parso, pandocfilters, overrides, orjson, oauthlib, numpy, nuclio-sdk, nest-asyncio, multidict, msgpack, mistune, mergedeep, MarkupSafe, locket, jupyterlab-pygments, jmespath, isodate, inflection, httplib2, grpcio, greenlet, graphviz, google-crc32c, future, fsspec, frozenlist, exceptiongroup, entrypoints, docstring-parser, dependency-injector, defusedxml, decorator, debugpy, cloudpickle, click, cachetools, bleach, avro, attrs, async-timeout, asttokens, absl-py, yarl, v3io, typer, terminado, stack-data, sqlalchemy, rsa, requests-toolbelt, requests-oauthlib, redis, pydantic, pyasn1-modules, pyarrow, proto-plus, plotly, partd, pandas, matplotlib-inline, kfp-server-api, kfp-pipeline-spec, jupyter-core, jsonschema, jinja2, jedi, grpcio-tools, googleapis-common-protos, google-resumable-media, gitdb, fire, deprecated, databricks-sdk, comm, botocore, beautifulsoup4, azure-core, argon2-cffi-bindings, anyio, aiosignal, aioitertools, v3iofs, v3io-frames, s3transfer, pyopenssl, nbformat, msrest, jupyter-server-terminals, jupyter-client, ipython, grpcio-status, google-auth, GitPython, db-dtypes, dask, azure-storage-blob, azure-keyvault-secrets, argon2-cffi, aiohttp, storey, nbclient, msal, kubernetes, jupyter-events, ipykernel, google-auth-oauthlib, google-auth-httplib2, google-api-core, distributed, boto3, aiohttp-retry, aiobotocore, s3fs, nbconvert, msal-extensions, google-cloud-core, google-api-python-client, azure-datalake-store, jupyter-server, google-cloud-storage, google-cloud-bigquery-storage, google-cloud-bigquery, azure-identity, notebook-shim, kfp, gcsfs, adlfs, nbclassic, notebook, nuclio-jupyter, mlrun\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.6.3\n",
      "    Uninstalling setuptools-65.6.3:\n",
      "      Successfully uninstalled setuptools-65.6.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.1\n",
      "    Uninstalling numpy-1.26.1:\n",
      "      Successfully uninstalled numpy-1.26.1\n",
      "  Attempting uninstall: pyopenssl\n",
      "    Found existing installation: pyOpenSSL 22.0.0\n",
      "    Uninstalling pyOpenSSL-22.0.0:\n",
      "      Successfully uninstalled pyOpenSSL-22.0.0\n",
      "Successfully installed GitPython-3.1.40 MarkupSafe-2.1.3 PyJWT-2.8.0 Send2Trash-1.8.2 absl-py-1.4.0 adlfs-2023.4.0 aiobotocore-2.5.2 aiohttp-3.8.6 aiohttp-retry-2.8.3 aioitertools-0.11.0 aiosignal-1.3.1 anyio-3.7.1 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 asttokens-2.4.0 async-timeout-4.0.3 attrs-23.1.0 avro-1.11.3 azure-common-1.1.28 azure-core-1.29.5 azure-datalake-store-0.0.53 azure-identity-1.14.1 azure-keyvault-secrets-4.7.0 azure-storage-blob-12.18.3 backcall-0.2.0 beautifulsoup4-4.12.2 bleach-6.1.0 boto3-1.26.161 botocore-1.29.161 cachetools-4.2.4 chardet-3.0.4 click-8.1.7 cloudpickle-2.2.1 comm-0.1.4 dask-2023.9.3 databricks-sdk-0.3.1 db-dtypes-1.1.1 debugpy-1.8.0 decorator-5.1.1 defusedxml-0.7.1 dependency-injector-4.41.0 deprecated-1.2.14 distributed-2023.9.3 docstring-parser-0.15 entrypoints-0.4 exceptiongroup-1.1.3 executing-2.0.0 fastjsonschema-2.18.1 fire-0.5.0 frozenlist-1.4.0 fsspec-2023.6.0 future-0.18.3 gcsfs-2023.6.0 gitdb-4.0.11 google-api-core-2.10.2 google-api-python-client-1.12.11 google-auth-1.35.0 google-auth-httplib2-0.1.1 google-auth-oauthlib-0.5.3 google-cloud-bigquery-3.12.0 google-cloud-bigquery-storage-2.16.2 google-cloud-core-2.3.3 google-cloud-storage-1.44.0 google-crc32c-1.5.0 google-resumable-media-2.6.0 googleapis-common-protos-1.61.0 graphviz-0.20.1 greenlet-3.0.0 grpcio-1.59.0 grpcio-status-1.48.2 grpcio-tools-1.48.2 httplib2-0.22.0 inflection-0.5.1 ipykernel-6.26.0 ipython-8.16.1 ipython-genutils-0.2.0 isodate-0.6.1 jedi-0.19.1 jinja2-3.1.2 jmespath-1.0.1 jsonschema-3.2.0 jupyter-client-7.4.9 jupyter-core-5.4.0 jupyter-events-0.6.3 jupyter-server-2.9.0 jupyter-server-terminals-0.4.4 jupyterlab-pygments-0.2.2 kafka-python-2.0.2 kfp-1.8.13 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kubernetes-18.20.0 locket-1.0.0 matplotlib-inline-0.1.6 mergedeep-1.3.4 mistune-3.0.2 mlrun-1.6.0rc2 msal-1.24.1 msal-extensions-1.0.0 msgpack-1.0.7 msrest-0.6.21 multidict-6.0.4 nbclassic-1.0.0 nbclient-0.8.0 nbconvert-7.9.2 nbformat-5.9.2 nest-asyncio-1.5.8 notebook-6.5.6 notebook-shim-0.2.3 nuclio-jupyter-0.9.13 nuclio-sdk-0.5.7 numpy-1.22.4 oauthlib-3.2.2 orjson-3.9.9 overrides-7.4.0 pandas-2.1.1 pandocfilters-1.5.0 parso-0.8.3 partd-1.4.1 pexpect-4.8.0 pickleshare-0.7.5 platformdirs-3.11.0 plotly-5.11.0 portalocker-2.8.2 prometheus-client-0.17.1 prompt-toolkit-3.0.39 proto-plus-1.22.3 protobuf-3.20.3 psutil-5.9.6 ptyprocess-0.7.0 pure-eval-0.2.2 pyarrow-11.0.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pydantic-1.10.13 pygments-2.16.1 pyopenssl-23.2.0 pyrsistent-0.19.3 python-dotenv-0.17.1 python-json-logger-2.0.7 pytz-2023.3.post1 pyyaml-5.4.1 pyzmq-24.0.1 redis-4.6.0 requests-2.31.0 requests-oauthlib-1.3.1 requests-toolbelt-0.10.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rsa-4.9 s3fs-2023.6.0 s3transfer-0.6.2 semver-3.0.2 setuptools-68.2.2 smmap-5.0.1 sniffio-1.3.0 sortedcontainers-2.4.0 soupsieve-2.5 sqlalchemy-1.4.49 stack-data-0.6.3 storey-1.6.1 strip-hints-0.1.10 tabulate-0.8.10 tblib-3.0.0 tenacity-8.2.3 termcolor-2.3.0 terminado-0.17.1 tinycss2-1.2.1 tornado-6.3.3 traitlets-5.12.0 typer-0.9.0 typing-extensions-4.8.0 tzdata-2023.3 ujson-5.8.0 uritemplate-3.0.1 v3io-0.5.21 v3io-frames-0.10.8 v3iofs-0.1.16 wcwidth-0.2.8 webencodings-0.5.1 websocket-client-1.6.4 wrapt-1.15.0 xxhash-3.4.1 yarl-1.9.2 zict-3.0.0\n",
      "\u001b[36mINFO\u001b[0m[0291] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0325] Pushing image to docker-registry.default-tenant.app.app-lab-b688.iguazio-cd0.com/mlrun/func-default-spark-mlrun-describe:latest \n",
      "\u001b[36mINFO\u001b[0m[0337] Pushed docker-registry.default-tenant.app.app-lab-b688.iguazio-cd0.com/mlrun/func-default-spark-mlrun-describe@sha256:c251f032fd27bae443645dab3fd136b145a80c4d0fb5582306b28d95e80cf061 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.with_spark_service(spark_service=spark_service_name)\n",
    "\n",
    "fn.spec.build.commands = ['pip install matplotlib pyspark']\n",
    "fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set MLRun and Run Function\n",
    "Once running the function get be monitored here and our projects dashbaord<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set mlrun api path and arrtifact path for logging\n",
    "artifact_path = mlrun.set_environment(api_path = 'http://mlrun-api:8080',\n",
    "                                      artifact_path = os.path.abspath('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-10-25 08:12:08,217 [info] Storing function: {'name': 'spark-mlrun-describe-describe-spark', 'uid': '731d733b58e149fcaeb99af47b4ce372', 'db': 'http://mlrun-api:8080'}\n",
      "> 2023-10-25 08:12:08,528 [info] Job is running in the background, pod: spark-mlrun-describe-describe-spark-kbr4x\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/spark/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/10/25 08:13:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "package mlrun installed\n",
      "package matplotlib installed\n",
      "> 2023-10-25 08:14:08,965 [info] Run execution finished: {'status': 'completed', 'name': 'spark-mlrun-describe-describe-spark'}\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>default</td>\n",
       "      <td><div title=\"731d733b58e149fcaeb99af47b4ce372\"><a href=\"https://dashboard.default-tenant.app.app-lab-b688.iguazio-cd0.com/mlprojects/default/jobs/monitor/731d733b58e149fcaeb99af47b4ce372/overview\" target=\"_blank\" >...7b4ce372</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Oct 25 08:13:15</td>\n",
       "      <td>completed</td>\n",
       "      <td>spark-mlrun-describe-describe-spark</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=avia</div><div class=\"dictlist\">kind=remote-spark</div><div class=\"dictlist\">owner=avia</div><div class=\"dictlist\">mlrun/client_version=1.6.0-rc2</div><div class=\"dictlist\">mlrun/client_python_version=3.9.16</div><div class=\"dictlist\">host=spark-mlrun-describe-describe-spark-kbr4x</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result2b6e74aa\" title=\"/files/demos/howto/spark/iris_dataset.csv\">dataset</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">n=150</div><div class=\"dictlist\">nvar=5</div><div class=\"dictlist\">total_missing=0.0</div><div class=\"dictlist\">memsize=0.0 YiB</div><div class=\"dictlist\">recordsize=0.0 YiB</div><div class=\"dictlist\">NUM=5</div><div class=\"dictlist\">DATE=0</div><div class=\"dictlist\">CONST=0</div><div class=\"dictlist\">CAT=0</div><div class=\"dictlist\">UNIQUE=0</div><div class=\"dictlist\">CORR=0</div><div class=\"dictlist\">REJECTED=0</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result2b6e74aa\" title=\"/files/demos/howto/spark/data/spark-mlrun-describe-describe-spark/0/summary_stats.csv\">summary_stats</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result2b6e74aa-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result2b6e74aa-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result2b6e74aa\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result2b6e74aa-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b> > to track results use the .show() or .logs() methods  or <a href=\"https://dashboard.default-tenant.app.app-lab-b688.iguazio-cd0.com/mlprojects/default/jobs/monitor/731d733b58e149fcaeb99af47b4ce372/overview\" target=\"_blank\">click here</a> to open in UI</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-10-25 08:14:17,144 [info] Run execution finished: {'status': 'completed', 'name': 'spark-mlrun-describe-describe-spark'}\n"
     ]
    }
   ],
   "source": [
    "# run our functions with the relevant params\n",
    "run_res = fn.run(inputs={\"dataset\": \"iris_dataset.csv\"},\n",
    "                 artifact_path=artifact_path[1], watch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>default</td>\n",
       "      <td><div title=\"731d733b58e149fcaeb99af47b4ce372\"><a href=\"https://dashboard.default-tenant.app.app-lab-b688.iguazio-cd0.com/mlprojects/default/jobs/monitor/731d733b58e149fcaeb99af47b4ce372/overview\" target=\"_blank\" >...7b4ce372</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Oct 25 08:13:15</td>\n",
       "      <td>completed</td>\n",
       "      <td>spark-mlrun-describe-describe-spark</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=avia</div><div class=\"dictlist\">kind=remote-spark</div><div class=\"dictlist\">owner=avia</div><div class=\"dictlist\">mlrun/client_version=1.6.0-rc2</div><div class=\"dictlist\">mlrun/client_python_version=3.9.16</div><div class=\"dictlist\">host=spark-mlrun-describe-describe-spark-kbr4x</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result2de9a264\" title=\"/files/demos/howto/spark/iris_dataset.csv\">dataset</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">n=150</div><div class=\"dictlist\">nvar=5</div><div class=\"dictlist\">total_missing=0.0</div><div class=\"dictlist\">memsize=0.0 YiB</div><div class=\"dictlist\">recordsize=0.0 YiB</div><div class=\"dictlist\">NUM=5</div><div class=\"dictlist\">DATE=0</div><div class=\"dictlist\">CONST=0</div><div class=\"dictlist\">CAT=0</div><div class=\"dictlist\">UNIQUE=0</div><div class=\"dictlist\">CORR=0</div><div class=\"dictlist\">REJECTED=0</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result2de9a264\" title=\"/files/demos/howto/spark/data/spark-mlrun-describe-describe-spark/0/summary_stats.csv\">summary_stats</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result2de9a264-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result2de9a264-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result2de9a264\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result2de9a264-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-base",
   "language": "python",
   "name": "conda-env-mlrun-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
