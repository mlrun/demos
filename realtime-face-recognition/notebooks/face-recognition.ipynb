{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-mlrun-install\"></a>The notebook runs the face recognition pipeline flow. \n",
    "the flow order is\n",
    "1. encode image: encode the images using open cv into numbers vector\n",
    "2. train: train the model based on the images encoded in step before and save model into mlrun artifacts\n",
    "3. deploy the nuclio face recognition function from nuclio-face-prediction-notebook to predict person based on model deployed\n",
    "4. deploy the api-serving function from nuclio-api-serving notebook to serve images sent from client and return response to clients \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the MLRun Python Package (mlrun)\n",
    "\n",
    "To use the MLRun Python library, you need to install the `mlrun` Python package in your development environment.\n",
    "This needs to be done only once, although you might occasionally need to update the package version.\n",
    "When running on the Iguazio Data Science Platform you can use the provided **align_mlrun.sh** script in your **/User** directory to install the MLRun package or upgrade the version of an installed package.\n",
    "By default, the script attempts to download the latest version of the MLRun package that matches the version of the running MLRun service.\n",
    "To manually install the MLRun package, run `pip install mlrun` with the MLRun version that matches your MLRun service.\n",
    "\n",
    "> **Note:** After installing or updating the MLRun package, restart the notebook kernel in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already installed: mlrun\n"
     ]
    }
   ],
   "source": [
    "!/User/align_mlrun.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration below is shared across the notebooks. Change the values in this subsection if you would like different configuration settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projects in the platform are used to package multiple functions, workflows, and artifacts. Set here the project base name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_BASE_NAME = \"faces\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data in the platform is stored in user-defined data containers. In this case we use the predefined \"users\" container. For more information refer to [Data containers, collections, and objects documentation](https://www.iguazio.com/docs/latest-release/concepts/containers-collections-objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER = 'users'\n",
    "WEB_API = \"http://v3io-webapi:8081\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv, path\n",
    "\n",
    "V3IO_USERNAME = getenv('V3IO_USERNAME')\n",
    "DATA_PATH = path.join('/User', 'examples',PROJECT_BASE_NAME, 'data/')\n",
    "ARTIFACTS_PATH = path.join(V3IO_USERNAME, 'examples',PROJECT_BASE_NAME, 'artifacts')\n",
    "USER_ARTIFACTS_PATH = path.join('/User', 'examples',PROJECT_BASE_NAME, 'artifacts')\n",
    "FUNCTIONS_PATH=path.abspath('./functions')\n",
    "MODELS_PATH = path.join(FUNCTIONS_PATH, 'models.py')\n",
    "MODEL_PATH=path.join(USER_ARTIFACTS_PATH, 'model.bst')\n",
    "CLASSES_MAP=path.join(ARTIFACTS_PATH, 'idx2name.csv')\n",
    "USER_NAME = getenv('V3IO_USERNAME')\n",
    "ENCODINGS_PATH = path.join(ARTIFACTS_PATH,'encodings') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the mlrun project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /User/mlrun/demos/realtime-face-recognition/notebooks\n",
      "Project name: faces-avia\n"
     ]
    }
   ],
   "source": [
    "from mlrun import new_project\n",
    "\n",
    "project_name = '-'.join(filter(None, [PROJECT_BASE_NAME, getenv('V3IO_USERNAME', None)]))\n",
    "project_path = path.abspath('./')\n",
    "project = new_project(project_name, project_path)\n",
    "\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts path: avia/examples/faces/artifacts\n",
      "MLRun DB path: http://mlrun-api:8080\n"
     ]
    }
   ],
   "source": [
    "from mlrun import mlconf\n",
    "\n",
    "# Target location for storing pipeline artifacts\n",
    "project.artifact_path = ARTIFACTS_PATH\n",
    "# MLRun DB path or API service URL\n",
    "\n",
    "print(f'Artifacts path: {project.artifact_path}\\nMLRun DB path: {mlconf.dbpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the configuration defined in this notebook in the project `params`. We will use these values in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.spec.params = {}\n",
    "\n",
    "project.spec.params['PROJECT_BASE_NAME'] = PROJECT_BASE_NAME\n",
    "project.spec.params['CONTAINER'] = CONTAINER\n",
    "project.spec.params['WEB_API'] = WEB_API\n",
    "project.spec.params['DATA_PATH'] = DATA_PATH\n",
    "project.spec.params['ENCODINGS_PATH'] = ENCODINGS_PATH\n",
    "project.spec.params['MODELS_PATH'] = MODELS_PATH\n",
    "project.spec.params['MODEL_PATH'] = MODEL_PATH\n",
    "project.spec.params['ARTIFACTS_PATH'] = ARTIFACTS_PATH\n",
    "project.spec.params['USER_ARTIFACTS_PATH'] = USER_ARTIFACTS_PATH\n",
    "project.spec.params['CLASSES_MAP'] = CLASSES_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### declare encode-images function for encoding initial images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import mount_v3io, code_to_function\n",
    "encode_images_func = code_to_function('encode-images', kind='job', filename='functions/encode_images.py',image='aviaigz/faces:0.6.0')\n",
    "encode_images_func.deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### declare train function for training the encoded images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import mount_v3io, code_to_function\n",
    "train_func = code_to_function('train', kind='job', filename='functions/train.py',image='aviaigz/faces:0.6.0')\n",
    "train_func.deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### declare face-prediction nuclio function for predicting face based on model created in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio\n",
    "import os\n",
    "from mlrun import mount_v3io, code_to_function\n",
    "nuclio_face_prediction_func = code_to_function('nuclio-face-prediction', kind='nuclio', filename='nuclio-face-prediction.ipynb')\n",
    "# set the API/trigger, attach the home dir to the function\n",
    "nuclio_face_prediction_func.with_http(workers=2).apply(mount_v3io())\n",
    "\n",
    "# set environment variables\n",
    "nuclio_face_prediction_func.set_env('MODELS_PATH', MODELS_PATH)\n",
    "nuclio_face_prediction_func.set_env('MODEL_PATH', MODEL_PATH)\n",
    "nuclio_face_prediction_func.set_env('CLASSES_MAP', CLASSES_MAP)\n",
    "nuclio_face_prediction_func.set_env('V3IO_ACCESS_KEY', os.environ['V3IO_ACCESS_KEY'])\n",
    "nuclio_face_prediction_func.spec.build.base_image = 'mlrun/ml-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### declare nuclio api-serving function for managing images requests and process face-prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio\n",
    "import os\n",
    "from mlrun import mount_v3io, code_to_function\n",
    "nuclio_api_serving_func = code_to_function('nuclio-api-serving', kind='nuclio', filename='nuclio-api-serving.ipynb')\n",
    "# set the API/trigger, attach the home dir to the function\n",
    "nuclio_api_serving_func.with_http(workers=2).apply(mount_v3io())\n",
    "\n",
    "# set environment variables\n",
    "nuclio_api_serving_func.set_env('DATA_PATH' ,DATA_PATH)\n",
    "nuclio_api_serving_func.set_env('V3IO_ACCESS_KEY', os.environ['V3IO_ACCESS_KEY'])\n",
    "nuclio_api_serving_func.spec.build.base_image = 'mlrun/ml-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mount_v3io, code_to_function\n",
    "\n",
    "\n",
    "project.set_function(encode_images_func,name='encode-images')\n",
    "project.set_function(train_func,name = 'train')\n",
    "project.set_function(nuclio_face_prediction_func,name = 'nuclio-face-prediction')\n",
    "project.set_function(nuclio_api_serving_func,name = 'nuclio-api-serving')\n",
    "\n",
    "project.func('encode-images').apply(mount_v3io())\n",
    "project.func('train').apply(mount_v3io())\n",
    "project.func('nuclio-face-prediction').apply(mount_v3io())\n",
    "project.func('nuclio-api-serving').apply(mount_v3io())\n",
    "\n",
    "\n",
    "project.func('encode-images').set_env('PYTHONPATH', project_path)\n",
    "project.func('train').set_env('PYTHONPATH', project_path)\n",
    "project.func('nuclio-face-prediction').set_env('PYTHONPATH', project_path)\n",
    "project.func('nuclio-api-serving').set_env('PYTHONPATH', project_path)\n",
    "\n",
    "\n",
    "project.func('encode-images').spec.artifact_path = ARTIFACTS_PATH\n",
    "project.func('train').spec.artifact_path = ARTIFACTS_PATH\n",
    "project.func('nuclio-face-prediction').spec.artifact_path = ARTIFACTS_PATH\n",
    "project.func('nuclio-api-serving').spec.artifact_path = ARTIFACTS_PATH\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-step-create-n-run-ml-pipeline\"></a>\n",
    "## Create and Run a Fully Automated ML Pipeline\n",
    "\n",
    "You're now ready to create a full ML pipeline.\n",
    "This is done by using [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/), which is integrated into the Iguazio Data Science Platform.\n",
    "Kubeflow Pipelines is an open-source framework for building and deploying portable, scalable machine-learning workflows based on Docker containers.\n",
    "MLRun leverages this framework to take your existing code and deploy it as steps in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /User/mlrun/demos/realtime-face-recognition/notebooks/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {path.join(project_path, 'workflow.py')}\n",
    "\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io, load_project\n",
    "from os import getenv, path\n",
    "\n",
    "project_path = path.abspath('./')\n",
    "project = load_project(project_path)\n",
    "\n",
    "DATA_PATH =project.spec.params.get('DATA_PATH')\n",
    "USER_ARTIFACTS_PATH = project.spec.params.get('USER_ARTIFACTS_PATH')\n",
    "ARTIFACTS_PATH = project.spec.params.get('ARTIFACTS_PATH')\n",
    "\n",
    "MODELS_PATH = project.spec.params.get('MODELS_PATH')\n",
    "FRAMES_URL = 'framesd:8081'\n",
    "V3IO_ACCESS_KEY = getenv('V3IO_ACCESS_KEY')\n",
    "WEB_API = \"http://v3io-webapi:8081\"\n",
    "ENCODINGS_PATH = project.spec.params.get('ENCODINGS_PATH')\n",
    "\n",
    "funcs = {}\n",
    "project_path = path.abspath('./')\n",
    "faces_params = {'data_path' : DATA_PATH,\n",
    "                'artifacts_path': USER_ARTIFACTS_PATH,\n",
    "                'models_path': MODELS_PATH,\n",
    "                'frames_url': FRAMES_URL,\n",
    "                'token' : V3IO_ACCESS_KEY, \n",
    "                'encodings_path': ENCODINGS_PATH }\n",
    "\n",
    "# Configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    project_path = path.abspath('./')\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        f.set_env('PYTHONPATH', project_path)\n",
    "        f.spec.artifact_path = ARTIFACTS_PATH\n",
    "        \n",
    "        \n",
    "        \n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name = \"faces-pipeline\",\n",
    "    description = \"faces demo pipeline\"\n",
    ")\n",
    "def kfpipeline():\n",
    "    # encode images\n",
    "    encode = funcs['encode-images'].as_step(\n",
    "        name=\"encode_images\",\n",
    "        params=faces_params,\n",
    "        outputs=['encode']\n",
    "    )\n",
    "    \n",
    "    # train the model based on the images\n",
    "    train = funcs['train'].as_step(\n",
    "        name=\"train\",\n",
    "        params = faces_params,\n",
    "        inputs={'table': encode.outputs},                       \n",
    "        outputs=['training']\n",
    "    )\n",
    "    # deploy the model as nuclio function\n",
    "    nuclio_face_prediction = funcs['nuclio-face-prediction'].deploy_step(                \n",
    "        models={\"nuclio-face-prediction\": train.outputs['training']}        \n",
    "    )    \n",
    "    \n",
    "    # deploy api serving as nuclio function\n",
    "    nuclio_api_serving = funcs['nuclio-api-serving'].deploy_step()\n",
    "    nuclio_api_serving.after(nuclio_face_prediction)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-register-workflow\"></a>\n",
    "#### Register the Workflow\n",
    "\n",
    "Use the `set_workflow` MLRun project method to register your workflow with MLRun.\n",
    "The following code sets the `name` parameter to the selected workflow name (\"main\") and the `code` parameter to the name of the workflow file that is found in your project directory (**workflow.py**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-01-25 07:22:00,173 [info] using in-cluster config.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.gcp-gke-1.iguazio-cd0.com/pipelines/#/experiments/details/7ade83f5-d81d-4853-b2e7-a21cd5583e9e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.gcp-gke-1.iguazio-cd0.com/pipelines/#/runs/details/5318559d-406d-46eb-a7fc-8b1063e5225e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-01-25 07:22:00,895 [info] Pipeline run id=5318559d-406d-46eb-a7fc-8b1063e5225e, check UI or DB for progress\n"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    \n",
    "    artifact_path=path.abspath(path.join('pipeline','{{workflow.uid}}'),\n",
    "    \n",
    "                              )\n",
    "    ,dirty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to [**client README.md**](../client/README.md) to clone client and generate images from your webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
