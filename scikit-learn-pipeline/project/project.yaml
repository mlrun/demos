kind: project
metadata:
  name: sk-project
spec:
  functions:
  - name: gen-iris
    spec:
      kind: job
      metadata:
        name: gen-iris
        tag: ''
        project: sk-project
      spec:
        command: ''
        args: []
        image: mlrun/mlrun
        env: []
        default_handler: ''
        entry_points:
          iris_generator:
            name: iris_generator
            doc: ''
            parameters:
            - name: context
              default: ''
            - name: format
              default: csv
            outputs:
            - default: ''
            lineno: 11
        description: ''
        build:
          functionSourceCode: IyBHZW5lcmF0ZWQgYnkgbnVjbGlvLmV4cG9ydC5OdWNsaW9FeHBvcnRlcgoKaW1wb3J0IG9zCmZyb20gc2tsZWFybi5kYXRhc2V0cyBpbXBvcnQgbG9hZF9pcmlzCmZyb20gc2tsZWFybi5tb2RlbF9zZWxlY3Rpb24gaW1wb3J0IHRyYWluX3Rlc3Rfc3BsaXQKaW1wb3J0IG51bXB5IGFzIG5wCmZyb20gc2tsZWFybi5tZXRyaWNzIGltcG9ydCBhY2N1cmFjeV9zY29yZQpmcm9tIG1scnVuLmFydGlmYWN0cyBpbXBvcnQgVGFibGVBcnRpZmFjdCwgUGxvdEFydGlmYWN0CmltcG9ydCBwYW5kYXMgYXMgcGQKCmRlZiBpcmlzX2dlbmVyYXRvcihjb250ZXh0LCBmb3JtYXQ9J2NzdicpOgogICAgaXJpcyA9IGxvYWRfaXJpcygpCiAgICBpcmlzX2RhdGFzZXQgPSBwZC5EYXRhRnJhbWUoZGF0YT1pcmlzLmRhdGEsIGNvbHVtbnM9aXJpcy5mZWF0dXJlX25hbWVzKQogICAgaXJpc19sYWJlbHMgPSBwZC5EYXRhRnJhbWUoZGF0YT1pcmlzLnRhcmdldCwgY29sdW1ucz1bJ2xhYmVsJ10pCiAgICBpcmlzX2RhdGFzZXQgPSBwZC5jb25jYXQoW2lyaXNfZGF0YXNldCwgaXJpc19sYWJlbHNdLCBheGlzPTEpCiAgICAKICAgIGNvbnRleHQubG9nZ2VyLmluZm8oJ3NhdmluZyBpcmlzIGRhdGFmcmFtZSB0byB7fScuZm9ybWF0KGNvbnRleHQuYXJ0aWZhY3RfcGF0aCkpCiAgICBjb250ZXh0LmxvZ19kYXRhc2V0KCdpcmlzX2RhdGFzZXQnLCBkZj1pcmlzX2RhdGFzZXQsIGZvcm1hdD1mb3JtYXQsIGluZGV4PUZhbHNlKQoK
          commands:
          - pip install sklearn
          - pip install pyarrow
          code_origin: https://github.com/daniels290813/demos.git#82b82bb1a7bc2919443104af6367b1c7ba04a846:gen_iris.ipynb
          origin_filename: gen-iris.ipynb
        mount_applied: false
        affinity: null
      verbose: false
  - url: hub://describe
    name: describe
  - url: hub://sklearn_classifier
    name: train
  - url: hub://test_classifier
    name: test
  - url: hub://model_server
    name: serving
  - url: hub://model_server_tester
    name: live_tester
  workflows:
  - name: main
    code: "from kfp import dsl\nfrom mlrun import mount_v3io\n\nfuncs = {}\nDATASET\
      \ = 'iris_dataset'\nLABELS  = \"label\"\n\n\n# init functions is used to configure\
      \ function resources and local settings\ndef init_functions(functions: dict,\
      \ project=None, secrets=None):\n    for f in functions.values():\n        f.apply(mount_v3io())\n\
      \     \n    # uncomment this line to collect the inference results into a stream\n\
      \    # and specify a path in V3IO (<datacontainer>/<subpath>)\n    #functions['serving'].set_env('INFERENCE_STREAM',\
      \ 'users/admin/model_stream')\n    \n@dsl.pipeline(\n    name=\"Demo training\
      \ pipeline\",\n    description=\"Shows how to use mlrun.\"\n)\ndef kfpipeline():\n\
      \    \n    # build our ingestion function (container image)\n    builder = funcs['gen-iris'].deploy_step(skip_deployed=True)\n\
      \    \n    # run the ingestion function with the new image and params\n    ingest\
      \ = funcs['gen-iris'].as_step(\n        name=\"get-data\",\n        handler='iris_generator',\n\
      \        image=builder.outputs['image'],\n        params={'format': 'pq'},\n\
      \        outputs=[DATASET])\n\n    # analyze our dataset\n    describe = funcs[\"\
      describe\"].as_step(\n        name=\"summary\",\n        params={\"label_column\"\
      : LABELS},\n        inputs={\"table\": ingest.outputs[DATASET]})\n    \n   \
      \ # train with hyper-paremeters \n    train = funcs[\"train\"].as_step(\n  \
      \      name=\"train-skrf\",\n        params={\"sample\"          : -1, \n  \
      \              \"label_column\"    : LABELS,\n                \"test_size\"\
      \       : 0.10},\n        hyperparams={'model_pkg_class': [\"sklearn.ensemble.RandomForestClassifier\"\
      , \n                                         \"sklearn.linear_model.LogisticRegression\"\
      ,\n                                         \"sklearn.ensemble.AdaBoostClassifier\"\
      ]},\n        selector='max.accuracy',\n        inputs={\"dataset\"         :\
      \ ingest.outputs[DATASET]},\n        outputs=['model', 'test_set'])\n\n    #\
      \ test and visualize our model\n    test = funcs[\"test\"].as_step(\n      \
      \  name=\"test\",\n        params={\"label_column\": LABELS},\n        inputs={\"\
      models_path\" : train.outputs['model'],\n                \"test_set\"    : train.outputs['test_set']})\n\
      \n    # deploy our model as a serverless function\n    deploy = funcs[\"serving\"\
      ].deploy_step(models={f\"{DATASET}_v1\": train.outputs['model']}, tag='v2')\n\
      \    \n    # test out new model server (via REST API calls)\n    tester = funcs[\"\
      live_tester\"].as_step(name='model-tester',\n        params={'addr': deploy.outputs['endpoint'],\
      \ 'model': f\"{DATASET}_v1\"},\n        inputs={'table': train.outputs['test_set']})\n"
    engine: kfp
  artifacts: []
  source: ''
  subpath: ''
  origin_url: ''
  desired_state: online
