kind: project
metadata:
  name: sk-project-orz
spec:
  functions:
  - name: gen-iris
    spec:
      kind: job
      metadata:
        name: gen-iris
        tag: ''
        project: sk-project-orz
      spec:
        command: ''
        args: []
        image: ''
        env: []
        default_handler: ''
        entry_points:
          iris_generator:
            name: iris_generator
            doc: ''
            parameters:
            - name: context
              default: ''
            - name: format
              default: csv
            outputs:
            - default: ''
            lineno: 11
        description: ''
        build:
          functionSourceCode: IyBHZW5lcmF0ZWQgYnkgbnVjbGlvLmV4cG9ydC5OdWNsaW9FeHBvcnRlcgoKaW1wb3J0IG9zCmZyb20gc2tsZWFybi5kYXRhc2V0cyBpbXBvcnQgbG9hZF9pcmlzCmZyb20gc2tsZWFybi5tb2RlbF9zZWxlY3Rpb24gaW1wb3J0IHRyYWluX3Rlc3Rfc3BsaXQKaW1wb3J0IG51bXB5IGFzIG5wCmZyb20gc2tsZWFybi5tZXRyaWNzIGltcG9ydCBhY2N1cmFjeV9zY29yZQpmcm9tIG1scnVuLmFydGlmYWN0cyBpbXBvcnQgVGFibGVBcnRpZmFjdCwgUGxvdEFydGlmYWN0CmltcG9ydCBwYW5kYXMgYXMgcGQKCmRlZiBpcmlzX2dlbmVyYXRvcihjb250ZXh0LCBmb3JtYXQ9J2NzdicpOgogICAgaXJpcyA9IGxvYWRfaXJpcygpCiAgICBpcmlzX2RhdGFzZXQgPSBwZC5EYXRhRnJhbWUoZGF0YT1pcmlzLmRhdGEsIGNvbHVtbnM9aXJpcy5mZWF0dXJlX25hbWVzKQogICAgaXJpc19sYWJlbHMgPSBwZC5EYXRhRnJhbWUoZGF0YT1pcmlzLnRhcmdldCwgY29sdW1ucz1bJ2xhYmVsJ10pCiAgICBpcmlzX2RhdGFzZXQgPSBwZC5jb25jYXQoW2lyaXNfZGF0YXNldCwgaXJpc19sYWJlbHNdLCBheGlzPTEpCiAgICAKICAgIGNvbnRleHQubG9nZ2VyLmluZm8oJ3NhdmluZyBpcmlzIGRhdGFmcmFtZSB0byB7fScuZm9ybWF0KGNvbnRleHQuYXJ0aWZhY3RfcGF0aCkpCiAgICBjb250ZXh0LmxvZ19kYXRhc2V0KCdpcmlzX2RhdGFzZXQnLCBkZj1pcmlzX2RhdGFzZXQsIGZvcm1hdD1mb3JtYXQsIGluZGV4PUZhbHNlKQoK
          base_image: mlrun/mlrun
          commands:
          - pip install sklearn
          - pip install pyarrow
          code_origin: https://github.com/mlrun/demos#167072d3b3a6c7a381b8d97bbaac0d048a28d0af:gen_iris.ipynb
      verbose: false
  - url: hub://describe
    name: describe
  - url: hub://sklearn_classifier
    name: train
  - url: hub://test_classifier
    name: test
  - url: hub://v2_model_server
    name: serving
  - url: hub://v2_model_tester
    name: live_tester
  workflows:
  - name: main
    code: "from kfp import dsl\nfrom mlrun import mount_v3io\n\nfuncs = {}\nDATASET\
      \ = 'iris_dataset'\nLABELS  = \"label\"\n\n\n# init functions is used to configure\
      \ function resources and local settings\ndef init_functions(functions: dict,\
      \ project=None, secrets=None):\n    for f in functions.values():\n        f.apply(mount_v3io())\n\
      \     \n    # uncomment this line to collect the inference results into a stream\n\
      \    # and specify a path in V3IO (<datacontainer>/<subpath>)\n    # functions['serving'].set_tracking(f'projects/{project.name}/model_stream')\n\
      \n    \n@dsl.pipeline(\n    name=\"Demo training pipeline\",\n    description=\"\
      Shows how to use mlrun.\"\n)\ndef kfpipeline():\n    \n    # build our ingestion\
      \ function (container image)\n    builder = funcs['gen-iris'].deploy_step(skip_deployed=True)\n\
      \    \n    # run the ingestion function with the new image and params\n    ingest\
      \ = funcs['gen-iris'].as_step(\n        name=\"get-data\",\n        handler='iris_generator',\n\
      \        image=builder.outputs['image'],\n        params={'format': 'pq'},\n\
      \        outputs=[DATASET])\n\n    # analyze our dataset\n    describe = funcs[\"\
      describe\"].as_step(\n        name=\"summary\",\n        params={\"label_column\"\
      : LABELS},\n        inputs={\"table\": ingest.outputs[DATASET]})\n    \n   \
      \ # train with hyper-paremeters \n    train = funcs[\"train\"].as_step(\n  \
      \      name=\"train\",\n        params={\"sample\"          : -1, \n       \
      \         \"label_column\"    : LABELS,\n                \"test_size\"     \
      \  : 0.10},\n        hyperparams={'model_pkg_class': [\"sklearn.ensemble.RandomForestClassifier\"\
      , \n                                         \"sklearn.linear_model.LogisticRegression\"\
      ,\n                                         \"sklearn.ensemble.AdaBoostClassifier\"\
      ]},\n        selector='max.accuracy',\n        inputs={\"dataset\"         :\
      \ ingest.outputs[DATASET]},\n        outputs=['model', 'test_set'])\n\n    #\
      \ test and visualize our model\n    test = funcs[\"test\"].as_step(\n      \
      \  name=\"test\",\n        params={\"label_column\": LABELS},\n        inputs={\"\
      models_path\" : train.outputs['model'],\n                \"test_set\"    : train.outputs['test_set']})\n\
      \n    # deploy our model as a serverless function, we can pass a list of models\
      \ to serve \n    deploy = funcs[\"serving\"].deploy_step(models=[{\"key\": f\"\
      {DATASET}:v1\", \"model_path\": train.outputs['model']}])\n    \n    # test\
      \ out new model server (via REST API calls)\n    tester = funcs[\"live_tester\"\
      ].as_step(name='model-tester',\n        params={'addr': deploy.outputs['endpoint'],\
      \ 'model': f\"{DATASET}:v1\"},\n        inputs={'table': train.outputs['test_set']})\n"
  artifacts: []
  artifact_path: /User/mlrun-demos/demos/scikit-learn-pipeline
  source: ''
  subpath: ''
  origin_url: ''
  desired_state: online
