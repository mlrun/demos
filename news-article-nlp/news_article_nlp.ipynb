{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Article Summarization and Keyword Extraction via NLP\n",
    "\n",
    "In this demo, we will create an NLP pipeline that will summarize and extract keywords from a news article URL. We will be using state-of-the-art transformer models such as BERT to perform these NLP tasks.\n",
    "\n",
    "Additionally, we will be using MLRun's real-time inference graphs to create the pipeline. This allows for easy containerization and deployment of our pipeline on top of a production-ready Kubernetes cluster.\n",
    "\n",
    "The full pipeline will do the following:\n",
    "1. Retrieve news article text and metadata from URL using newspaper3k\n",
    "2. Summarize article text via Huggingface pipeline using DistilBart model\n",
    "3. Extract article keywords via KeyBERT using BERT-embeddings and cosine similarity\n",
    "4. Remove the original article text from the response (optional)\n",
    "5. Persist record in KV table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Local Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.11.3\n",
      "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting newspaper3k==0.2.8\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 99.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keybert==0.5.0\n",
      "  Downloading keybert-0.5.0.tar.gz (19 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /conda/lib/python3.7/site-packages (from transformers==4.11.3) (5.3.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /conda/lib/python3.7/site-packages (from transformers==4.11.3) (4.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /conda/lib/python3.7/site-packages (from transformers==4.11.3) (21.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[K     |████████████████████████████████| 751 kB 100.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 96.2 MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /conda/lib/python3.7/site-packages (from transformers==4.11.3) (1.19.2)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /conda/lib/python3.7/site-packages (from transformers==4.11.3) (2.24.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 94.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 99.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /conda/lib/python3.7/site-packages (from transformers==4.11.3) (4.64.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /conda/lib/python3.7/site-packages (from newspaper3k==0.2.8) (4.8.2)\n",
      "Collecting lxml>=3.6.0\n",
      "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 78.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk>=3.2.1\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 87.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting feedparser>=5.2.1\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 93.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cssselect>=0.9.2\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tinysegmenter==0.3\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /conda/lib/python3.7/site-packages (from newspaper3k==0.2.8) (2.8.2)\n",
      "Collecting jieba3k>=0.35.1\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.4 MB 86.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /conda/lib/python3.7/site-packages (from newspaper3k==0.2.8) (9.0.1)\n",
      "Collecting tldextract>=2.0.1\n",
      "  Downloading tldextract-3.3.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 62.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentence-transformers>=0.3.8\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 88.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /conda/lib/python3.7/site-packages (from keybert==0.5.0) (0.23.2)\n",
      "Collecting rich>=10.4.0\n",
      "  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 102.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /User/.pythonlibs/jupyter-nick/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.11.3) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.11.3) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /conda/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.11.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /conda/lib/python3.7/site-packages (from requests->transformers==4.11.3) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /conda/lib/python3.7/site-packages (from requests->transformers==4.11.3) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /conda/lib/python3.7/site-packages (from requests->transformers==4.11.3) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /conda/lib/python3.7/site-packages (from requests->transformers==4.11.3) (2.8)\n",
      "Requirement already satisfied: six in /conda/lib/python3.7/site-packages (from sacremoses->transformers==4.11.3) (1.12.0)\n",
      "Requirement already satisfied: click in /conda/lib/python3.7/site-packages (from sacremoses->transformers==4.11.3) (8.0.4)\n",
      "Requirement already satisfied: joblib in /conda/lib/python3.7/site-packages (from sacremoses->transformers==4.11.3) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /conda/lib/python3.7/site-packages (from beautifulsoup4>=4.4.1->newspaper3k==0.2.8) (2.3.1)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "Collecting requests-file>=1.4\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: torch>=1.6.0 in /conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.5.0) (1.7.0)\n",
      "Requirement already satisfied: torchvision in /conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.5.0) (0.8.0)\n",
      "Requirement already satisfied: scipy in /conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert==0.5.0) (1.4.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 89.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2->keybert==0.5.0) (2.2.0)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 78.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /conda/lib/python3.7/site-packages (from rich>=10.4.0->keybert==0.5.0) (2.11.2)\n",
      "Requirement already satisfied: future in /conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert==0.5.0) (0.18.2)\n",
      "Requirement already satisfied: dataclasses in /conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert==0.5.0) (0.6)\n",
      "Building wheels for collected packages: keybert, sacremoses, tinysegmenter, jieba3k, feedfinder2, sentence-transformers, sgmllib3k\n",
      "  Building wheel for keybert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keybert: filename=keybert-0.5.0-py3-none-any.whl size=20490 sha256=9dfeee0b4c2195375721d2ff033dc2dd1cfee7e3b3dcc10d819a18747e28b525\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4tb1lsxq/wheels/99/1f/3f/590d2997adbb2d0e1f82e8ee05d42d6910e92c3ed283015ff8\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=5dfdd26342d224c8074a137b3ed2f222040682301b9cb2b04af1740ac3f1d692\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4tb1lsxq/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13536 sha256=e390c7ec0130d5ef84dec6d376a62ef29dcef267b5251c257ba5b6900fe0f542\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4tb1lsxq/wheels/df/67/41/faca10fa501ca010be41b49d40360c2959e1c4f09bcbfa37fa\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398407 sha256=17eb829d26531266f1e01468dca007644364c4fa6fdb8d3e88a8167ecfd3cb9c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4tb1lsxq/wheels/4c/91/46/3c208287b726df325a5979574324878b679116e4baae1af3c3\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3356 sha256=17a5fdc86f0d75fd39289f2f62e6805110374abd96237fa3070d4f19e0790a37\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4tb1lsxq/wheels/7f/d4/8f/6e2ca54744c9d7292d88ddb8d42876bcdab5e6d84a21c10346\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125919 sha256=0886309d0e56f38a3b78b4849ad0e954c8dba8efd4321fa66f50157c8c5c3f96\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4tb1lsxq/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=9c678939472e36da99efb499a99a5a4d81f2993e92e8a1326b77188e79cdcb7f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4tb1lsxq/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
      "Successfully built keybert sacremoses tinysegmenter jieba3k feedfinder2 sentence-transformers sgmllib3k\n",
      "Installing collected packages: regex, filelock, huggingface-hub, tokenizers, sacremoses, transformers, lxml, nltk, sgmllib3k, feedparser, cssselect, tinysegmenter, jieba3k, feedfinder2, requests-file, tldextract, newspaper3k, sentencepiece, sentence-transformers, commonmark, rich, keybert\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "rich 12.5.1 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you'll have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\n",
      "Successfully installed commonmark-0.9.1 cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.10 filelock-3.7.1 huggingface-hub-0.8.1 jieba3k-0.35.1 keybert-0.5.0 lxml-4.9.1 newspaper3k-0.2.8 nltk-3.7 regex-2022.7.25 requests-file-1.5.1 rich-12.5.1 sacremoses-0.0.53 sentence-transformers-2.2.2 sentencepiece-0.1.96 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.3.1 tokenizers-0.10.3 transformers-4.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.11.3 newspaper3k==0.2.8 keybert==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MLRun Function\n",
    "Here we define the serverless function that will containerize and deploy our application. We can add dependencies and commands to the image build, define replicas for scaling, add environment variables, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-27 19:01:08,070 [info] created and saved project nlp-demo\n"
     ]
    }
   ],
   "source": [
    "project_name = \"nlp-demo\"\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = mlrun.code_to_function(name=\"news-article-nlp\", filename=\"nlp_transformations.py\",\n",
    "                            kind=\"serving\", image='mlrun/ml-models')\n",
    "fn.spec.min_replicas = 1\n",
    "fn.spec.max_replicas = 1\n",
    "fn.spec.build.commands = [\n",
    "    \"python -m pip install transformers==4.11.3 newspaper3k==0.2.8 keybert==0.5.0\",\n",
    "    \"python -c 'from transformers import pipeline; pipeline(\\\"summarization\\\")'\",\n",
    "    \"python -c 'from keybert import KeyBERT; KeyBERT()'\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Real-Time Serving Graph\n",
    "Here we will orchestrate the functions and classes we want to run in our pipeline. The source code for these functions is located in `project/nlp_transformations.py`. Notice, this is the same file we used when running `code_to_function` in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"bigdata\"\n",
    "table_path = f\"nlp-{os.getenv('V3IO_USERNAME')}\"\n",
    "key = \"title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"1201pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 1200.62 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 1196.6187,-40 1196.6187,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"38.5476,-.0493 40.698,-.1479 42.8263,-.2953 44.9236,-.4913 46.9815,-.7353 48.9917,-1.0266 50.9463,-1.3645 52.8377,-1.7479 54.6587,-2.1759 56.4025,-2.6472 58.0628,-3.1606 59.634,-3.7147 61.1107,-4.308 62.4882,-4.9388 63.7625,-5.6054 64.9302,-6.3059 65.9882,-7.0385 66.9343,-7.8012 67.7669,-8.5918 68.4849,-9.4082 69.0878,-10.2481 69.5758,-11.1093 69.9496,-11.9894 70.2102,-12.886 70.3595,-13.7965 70.3997,-14.7186 70.3334,-15.6497 70.1636,-16.5873 69.8937,-17.5287 69.5276,-18.4713 69.0691,-19.4127 68.5225,-20.3503 67.8923,-21.2814 67.1831,-22.2035 66.3996,-23.114 65.5464,-24.0106 64.6285,-24.8907 63.6504,-25.7519 62.617,-26.5918 61.5329,-27.4082 60.4024,-28.1988 59.2299,-28.9615 58.0197,-29.6941 56.7755,-30.3946 55.5012,-31.0612 54.2002,-31.692 52.8757,-32.2853 51.5309,-32.8394 50.1684,-33.3528 48.7908,-33.8241 47.4003,-34.2521 45.9989,-34.6355 44.5886,-34.9734 43.1708,-35.2647 41.7472,-35.5087 40.3189,-35.7047 38.8872,-35.8521 37.4531,-35.9507 36.0175,-36 34.5815,-36 33.146,-35.9507 31.7119,-35.8521 30.2801,-35.7047 28.8519,-35.5087 27.4282,-35.2647 26.0105,-34.9734 24.6001,-34.6355 23.1988,-34.2521 21.8083,-33.8241 20.4306,-33.3528 19.0681,-32.8394 17.7233,-32.2853 16.3989,-31.692 15.0979,-31.0612 13.8236,-30.3946 12.5794,-29.6941 11.3691,-28.9615 10.1967,-28.1988 9.0662,-27.4082 7.982,-26.5918 6.9486,-25.7519 5.9706,-24.8907 5.0526,-24.0106 4.1995,-23.114 3.4159,-22.2035 2.7067,-21.2814 2.0765,-20.3503 1.53,-19.4127 1.0715,-18.4713 .7053,-17.5287 .4355,-16.5873 .2657,-15.6497 .1993,-14.7186 .2395,-13.7965 .3888,-12.886 .6495,-11.9894 1.0232,-11.1093 1.5112,-10.2481 2.1141,-9.4082 2.8321,-8.5918 3.6647,-7.8012 4.6109,-7.0385 5.6689,-6.3059 6.8365,-5.6054 8.1108,-4.9388 9.4884,-4.308 10.9651,-3.7147 12.5362,-3.1606 14.1966,-2.6472 15.9404,-2.1759 17.7614,-1.7479 19.6528,-1.3645 21.6074,-1.0266 23.6176,-.7353 25.6755,-.4913 27.7728,-.2953 29.901,-.1479 32.0515,-.0493 34.2154,0 36.3837,0 38.5476,-.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.2995\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<!-- fetch_article -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>fetch_article</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"176.1429\" cy=\"-18\" rx=\"69.5877\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.1429\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">fetch_article</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;fetch_article -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;fetch_article</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M69.7537,-18C77.9472,-18 87.0286,-18 96.3326,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.4844,-21.5001 106.4844,-18 96.4844,-14.5001 96.4844,-21.5001\"/>\n",
       "</g>\n",
       "<!-- summarize_article -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>summarize_article</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"378.5281\" cy=\"-18\" rx=\"96.6831\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.5281\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">summarize_article</text>\n",
       "</g>\n",
       "<!-- fetch_article&#45;&gt;summarize_article -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>fetch_article&#45;&gt;summarize_article</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M245.7924,-18C254.0929,-18 262.708,-18 271.3816,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"271.5752,-21.5001 281.5752,-18 271.5752,-14.5001 271.5752,-21.5001\"/>\n",
       "</g>\n",
       "<!-- extract_keywords -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>extract_keywords</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"605.6112\" cy=\"-18\" rx=\"94.4839\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"605.6112\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">extract_keywords</text>\n",
       "</g>\n",
       "<!-- summarize_article&#45;&gt;extract_keywords -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>summarize_article&#45;&gt;extract_keywords</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M475.4905,-18C483.8892,-18 492.4117,-18 500.8687,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"501.1392,-21.5001 511.1392,-18 501.1392,-14.5001 501.1392,-21.5001\"/>\n",
       "</g>\n",
       "<!-- filter_article -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>filter_article</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"804.7467\" cy=\"-18\" rx=\"68.7879\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"804.7467\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">filter_article</text>\n",
       "</g>\n",
       "<!-- extract_keywords&#45;&gt;filter_article -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>extract_keywords&#45;&gt;filter_article</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M699.9304,-18C708.5067,-18 717.1351,-18 725.5601,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"725.7187,-21.5001 735.7187,-18 725.7186,-14.5001 725.7187,-21.5001\"/>\n",
       "</g>\n",
       "<!-- kv_format -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>kv_format</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"967.4854\" cy=\"-18\" rx=\"57.6901\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"967.4854\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">kv_format</text>\n",
       "</g>\n",
       "<!-- filter_article&#45;&gt;kv_format -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>filter_article&#45;&gt;kv_format</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M873.7626,-18C882.2002,-18 890.8192,-18 899.2453,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"899.4026,-21.5001 909.4025,-18 899.4025,-14.5001 899.4026,-21.5001\"/>\n",
       "</g>\n",
       "<!-- write_to_kv -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>write_to_kv</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1126.9745\" cy=\"-18\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1126.9745\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">write_to_kv</text>\n",
       "</g>\n",
       "<!-- kv_format&#45;&gt;write_to_kv -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>kv_format&#45;&gt;write_to_kv</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1025.5158,-18C1033.8379,-18 1042.5016,-18 1051.1049,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1051.1528,-21.5001 1061.1528,-18 1051.1527,-14.5001 1051.1528,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fdec9f64fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = fn.set_topology(\"flow\", engine=\"async\")\n",
    "\n",
    "graph.to(name=\"fetch_article\", handler=\"fetch_article\")\\\n",
    "     .to(name=\"summarize_article\", class_name=\"SummarizeArticle\")\\\n",
    "     .to(name=\"extract_keywords\", class_name=\"ExtractKeywords\")\\\n",
    "     .to(name=\"filter_article\", handler=\"filter_article\")\\\n",
    "     .to(name=\"kv_format\", handler=\"kv_format\", full_event=True)\\\n",
    "     .to(name=\"write_to_kv\", class_name=\"storey.NoSqlTarget\", table=f\"v3io:///{container}/{table_path}\").respond()\n",
    "\n",
    "graph.plot(rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Pipeline Locally (using simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ffec5bcc81431caf86fdfb620b76e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74597369ce9a4762b5bd7089083afc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e62074850f54e9cba00b79df2e2441b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b1994aa90f44cc8dc6533c26c1bf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da3f60cb6e3400f9aca79b94538b649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba115b7f950f42febf75b8aaa4b8c273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb6cae8c7264c0ea6a4ca0b2d3dc4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7207a53b086340a19e2001c0d344538d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b31b871cef49c59bfd74e5501d83e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226e5cd4556141f5926063199a1d7848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d8d6ae2ae34711b5a0d7871c90c6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f2c1d2bf254cda89c5fcad73f6554d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cd811d8bd8472e99be15e0a1c9e0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00d4a82629a4c63ad44733eedfec6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318571c73c564de5ad34e95986c7ffb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7622eec5174eab903112bd44254c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30dd81be8964ee29e0fd24642b0832b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1c5348b05f4e158356f8d072b5c507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4526af0e194c70bd994182624d10b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/c10/cuda/CUDAFunctions.cpp:100.)\n"
     ]
    }
   ],
   "source": [
    "# import the step functions for simulation\n",
    "from nlp_transformations import *\n",
    "\n",
    "# create a mock server (simulator)\n",
    "server = fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.cnn.com/2021/11/01/politics/vaccine-rules-osha/index.html',\n",
       " 'title': 'Emergency vaccine rule for large employers will be issued in the coming days',\n",
       " 'authors': '[\"Kaitlan Collins\", \"Kate Sullivan\"]',\n",
       " 'publish_date': '2021-11-01 00:00:00',\n",
       " 'summarized_text': ' The Federal Register will publish the Labor Departments emergency temporary standard in the coming days . The rule requires private businesses with 100 or more employees to vaccinate or test them weekly . President Joe Biden announced the rule in September . Employers must develop, implement, and enforce a mandatory COVID-19 vaccination policy .',\n",
       " 'keywords': '[\"vaccination\", \"compliance\", \"announced\", \"biden\", \"emergency\"]'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the pipeline\n",
    "server.test(\"/\", body={\"url\" : \"https://www.cnn.com/2021/11/01/politics/vaccine-rules-osha/index.html\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containerize and Deploy Pipeline on K8s\n",
    "Here we easily containerize and deploy our application to our K8s cluster with a single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-27 19:02:17,488 [info] Starting remote function deploy\n",
      "2022-07-27 19:02:17  (info) Deploying function\n",
      "2022-07-27 19:02:17  (info) Building\n",
      "2022-07-27 19:02:17  (info) Staging files and preparing base images\n",
      "2022-07-27 19:02:17  (info) Building processor image\n",
      "2022-07-27 19:06:53  (info) Build complete\n",
      "2022-07-27 19:07:31  (info) Function deploy complete\n",
      "> 2022-07-27 19:07:32,077 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-nlp-demo-nick-news-article-nlp.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['nlp-demo-nick-news-article-nlp-nlp-demo-nick.default-tenant.app.uss-sales-350.iguazio-cd2.com/']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://nlp-demo-nick-news-article-nlp-nlp-demo-nick.default-tenant.app.uss-sales-350.iguazio-cd2.com/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.spec.readinessTimeoutSeconds = 60 * 20  # 20 minutes.\\n\",\n",
    "fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Pipeline with URLs From Various News Sources \n",
    "Here we can test the pipeline with various news sources. This pipeline should work with any source compatible with the `newspaper3k` Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-27 19:07:41,291 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-nlp-demo-nick-news-article-nlp.default-tenant.svc.cluster.local:8080/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.cnn.com/2021/11/01/politics/vaccine-rules-osha/index.html',\n",
       " 'title': 'Emergency vaccine rule for large employers will be issued in the coming days',\n",
       " 'authors': '[\"Kaitlan Collins\", \"Kate Sullivan\"]',\n",
       " 'publish_date': '2021-11-01 00:00:00',\n",
       " 'summarized_text': ' The Federal Register will publish the Labor Departments emergency temporary standard in the coming days . The rule requires private businesses with 100 or more employees to vaccinate or test them weekly . President Joe Biden announced the rule in September . Employers must develop, implement, and enforce a mandatory COVID-19 vaccination policy .',\n",
       " 'keywords': '[\"vaccination\", \"compliance\", \"announced\", \"biden\", \"emergency\"]'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://www.cnn.com/2021/11/01/politics/vaccine-rules-osha/index.html\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-27 19:07:53,741 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-nlp-demo-nick-news-article-nlp.default-tenant.svc.cluster.local:8080/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.cnn.com/travel/article/americans-bought-bargain-homes-in-italy-cmd/index.html',\n",
       " 'title': 'The Americans who bought bargain homes in Italys deep south',\n",
       " 'authors': '[\"Silvia Marchetti\"]',\n",
       " 'publish_date': 'None',\n",
       " 'summarized_text': ' Latronico, Italy, is selling abandoned homes for €10,000 to $30,000 . 90% of those who bought the abandoned homes are from the United States . Frank Cohen, a retired U.S. freelance reporter from New Haven, bought three houses in the towns historical district .',\n",
       " 'keywords': '[\"latronico\", \"renovating\", \"prices\", \"agrees\", \"americans\"]'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://www.cnn.com/travel/article/americans-bought-bargain-homes-in-italy-cmd/index.html\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-27 19:08:14,019 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-nlp-demo-nick-news-article-nlp.default-tenant.svc.cluster.local:8080/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.npr.org/2021/11/01/1050212278/public-school-meals-students-labor-issues',\n",
       " 'title': 'Your public school kids lunch might be served on a pizza slice box. Heres why',\n",
       " 'authors': '[\"Frank Morris\"]',\n",
       " 'publish_date': '2021-11-01 00:00:00',\n",
       " 'summarized_text': ' The U.S. Department of Agriculture is reimbursing school districts for free meals this year . But labor shortages are crimping the program and costs are rising . Some districts are scrambling to feed their students . The USDA has announced that another $1.5 billion in aid is forthcoming .',\n",
       " 'keywords': '[\"lunch\", \"reimbursed\", \"inch\", \"necessarily\", \"costco\"]'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://www.npr.org/2021/11/01/1050212278/public-school-meals-students-labor-issues\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-27 19:08:32,520 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-nlp-demo-nick-news-article-nlp.default-tenant.svc.cluster.local:8080/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://abcnews.go.com/Entertainment/wireStory/jon-bon-jovi-tests-positive-covid-19-cancels-80903055',\n",
       " 'filter_article': False,\n",
       " 'title': 'Jon Bon Jovi tests positive for COVID-19, cancels concert',\n",
       " 'authors': '[\"Abc News\"]',\n",
       " 'publish_date': 'None',\n",
       " 'original_text': 'Jon Bon Jovi tested positive for COVID-19 just before he was set to perform a concert in Miami Beach\\n\\nMIAMI -- Jon Bon Jovi tested positive for COVID-19 during a rapid test just before he was set to perform a concert in Miami Beach.\\n\\nAn announcer took to the stage to give the crowd the bad news just before Saturday nights concert at Loews South Beach was set to begin, WSVN in Miami reported.\\n\\nBon Jovi, 59, and his bandmates took rapid tests just before the concert and Bon Jovi tested positive. He is fully vaccinated. Ticket holders were required to show proof of vaccination or negative test results to get into the concert, the highlight of a three-day hotel package costing up to thousands of dollars a person.\\n\\n“Jon feels great,” the announcer told the crowd, adding that the “Livin On a Prayer\" singer was going to bed.\\n\\nHe also had been scheduled to participate in a Q & A session and a photo op on Saturday night.\\n\\nThere was no word on whether the concert would be rescheduled.',\n",
       " 'summarized_text': ' Jon Bon Jovi tested positive for COVID-19 just before he was set to perform a concert in Miami . The singer and his bandmates took rapid tests just before the concert . Ticket holders were required to show proof of vaccination or negative test results to get into the show .',\n",
       " 'keywords': '[\"jovi\", \"vaccinated\", \"stage\", \"saturday\", \"negative\"]'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://abcnews.go.com/Entertainment/wireStory/jon-bon-jovi-tests-positive-covid-19-cancels-80903055\",\n",
    "          \"filter_article\" : False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define KV Table Schema for Dashboard\n",
    "While a schema is not required to write records to a table, it is required for the table to be displayed in a Grafana dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<v3io.dataplane.response.Response at 0x7fde1cd48050>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import v3io.dataplane\n",
    "\n",
    "v3io_client = v3io.dataplane.Client()\n",
    "\n",
    "v3io_client.kv.create_schema(\n",
    "    container=container,\n",
    "    table_path=table_path,\n",
    "    key=key,\n",
    "    fields = [\n",
    "        {'name': 'url',\n",
    "         'type': 'string',\n",
    "         'nullable': False},\n",
    "        {'name': 'filter_article',\n",
    "         'type': 'boolean',\n",
    "         'nullable': False},\n",
    "        {'name': 'title',\n",
    "         'type': 'string',\n",
    "         'nullable': False},\n",
    "        {'name': 'authors',\n",
    "         'type': 'string',\n",
    "         'nullable': False},\n",
    "        {'name': 'publish_date',\n",
    "         'type': 'string',\n",
    "         'nullable': False},\n",
    "        {'name': 'original_text',\n",
    "         'type': 'string',\n",
    "         'nullable': False},\n",
    "        {'name': 'summarized_text',\n",
    "         'type': 'string',\n",
    "         'nullable': False},\n",
    "        {'name': 'keywords',\n",
    "         'type': 'string',\n",
    "         'nullable': False}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the pipeline, we will be able to visualize the article summary, keywords, and metadata in a Grafana dashboard. The JSON file for the dashboard is available under `grafana_dashboard.json`.\n",
    "\n",
    "After importing into Grafana and running the pipeline above, the dashboard will look something like the following:\n",
    "![](./dashboard_preview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
