{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import IPython\n",
    "\n",
    "required = {'mlrun == 0.6.*', 'v3io == 0.6.*', 'faker'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "previously_installed = required.intersection(installed)\n",
    "\n",
    "if missing:\n",
    "    print(f'Installing {\",\".join(missing)}')\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "    print('Restarting kernel')\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel\n",
    "if previously_installed:\n",
    "    print(f'Already installed: {\",\".join(previously_installed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses the `# nuclio: start-code` marker to instruct Nuclio to start processing code only from this location, and then performs basic Nuclio function configuration &mdash; defining the name of the function's container image (`mlrun/ml-models`), the function type (`nuclio`), and some additional package installation commands.\n",
    "\n",
    "> **Note:** You can add code to define function dependencies and perform additional configuration after the `# nuclio: start-code` marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "\n",
    "python -m pip install v3io == 0.6.*\n",
    "python -m pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio config\n",
    "spec.build.baseImage = \"mlrun/ml-models\"\n",
    "spec.readinessTimeoutSeconds = 200\n",
    "kind = \"job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, random\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import uuid\n",
    "from faker import Faker\n",
    "import v3io.dataplane\n",
    "import os\n",
    "from mlrun.execution import MLClientCtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_postcode(is_churn):\n",
    "    # if is_churn is true the postcode modulu 3 will return 0 or 1\n",
    "    # if is_churn is false the postcode modulu 3 will return 0 or 2\n",
    "    # this will encode information in postcode that our ML model will learn\n",
    "    base_postcode = 3 * randint(3334, 33333)\n",
    "    group = randint(0, 1)\n",
    "    if is_churn:\n",
    "        return base_postcode + group\n",
    "    else:\n",
    "        return base_postcode + (group * 2)\n",
    "\n",
    "\n",
    "# event functions\n",
    "def new_registration(fake, user_id, event_time, is_churn):\n",
    "    return {'user_id': user_id,\n",
    "            'event_type': 'registration',\n",
    "            'event_time': event_time,\n",
    "            'name': fake.name(),\n",
    "            'date_of_birth': fake.date(),\n",
    "            'street_address': fake.street_address(),\n",
    "            'city': fake.city(),\n",
    "            'country': fake.country(),\n",
    "            'postcode': gen_postcode(is_churn),\n",
    "            'affiliate_url': fake.image_url(),\n",
    "            'campaign': fake.ean8()}\n",
    "\n",
    "\n",
    "def new_purchase(fake, user_id, event_time):\n",
    "    return {'user_id': user_id,\n",
    "            'event_type': 'purchase',\n",
    "            'event_time': event_time,\n",
    "            'amount': fake.randomize_nb_elements(number=50)}\n",
    "\n",
    "\n",
    "def new_bet(fake, user_id, event_time):\n",
    "    return {'user_id': user_id,\n",
    "            'event_type': 'bet',\n",
    "            'event_time': event_time,\n",
    "            'bet_amount': fake.randomize_nb_elements(number=10)}\n",
    "\n",
    "\n",
    "def new_win(fake, user_id, event_time):\n",
    "    return {'user_id': user_id,\n",
    "            'event_type': 'win',\n",
    "            'event_time': event_time,\n",
    "            'win_amount': fake.randomize_nb_elements(number=200)}\n",
    "\n",
    "\n",
    "def gen_event_date(is_churn, prev_event_date=None):\n",
    "    if prev_event_date is None:\n",
    "        # generate first event date\n",
    "        return datetime.now() - timedelta(hours=randint(48, 96))\n",
    "    else:\n",
    "        if prev_event_date + timedelta(hours=30) < datetime.now() and not is_churn and randint(1, 1000) <= 5:\n",
    "            # if the user is not churned and it is possible, generate event in the following day with prbability 0.005\n",
    "            return prev_event_date + timedelta(hours=randint(15, 24))\n",
    "        else:\n",
    "            return prev_event_date + timedelta(seconds=randint(5, 100))\n",
    "\n",
    "\n",
    "def generate_events(fake, num_users, events_dist, num_events, is_churn):\n",
    "    user_ids = generate_user_ids(num_users)\n",
    "    events = []\n",
    "    for user_id in user_ids:\n",
    "        # register\n",
    "        event_time = gen_event_date(is_churn)\n",
    "        reg_event = new_registration(fake, user_id, event_time, is_churn)\n",
    "        reg_event['label'] = int(is_churn)\n",
    "        events.append(reg_event)\n",
    "        for _ in range(num_events):\n",
    "            # generate event according to dist\n",
    "            acc_prob = 0\n",
    "            rand = random()\n",
    "            for event_dist in events_dist:\n",
    "                if rand <= event_dist['probability'] + acc_prob:\n",
    "                    event_time = gen_event_date(is_churn, event_time)\n",
    "                    new_event = event_dist['generator'](fake, user_id, event_time)\n",
    "                    events.append(new_event)\n",
    "                    break\n",
    "                else:\n",
    "                    acc_prob += event_dist['probability']\n",
    "    return events\n",
    "\n",
    "\n",
    "def generate_user_ids(n: int):\n",
    "    return (str(uuid.uuid4()) for _ in range(n))\n",
    "\n",
    "\n",
    "def generate_event_stream(v3io_client,\n",
    "                          container,\n",
    "                          output_stream_path,\n",
    "                          num_users_group1,\n",
    "                          num_users_group2,\n",
    "                          events_per_user):\n",
    "    # 70% churn users\n",
    "\n",
    "    fake = Faker()\n",
    "\n",
    "    group1_events_dist = [{'probability': 0.1, 'generator': new_purchase},\n",
    "                          {'probability': 0.89, 'generator': new_bet},\n",
    "                          {'probability': 0.01, 'generator': new_win}]\n",
    "\n",
    "    group2_events_dist = [{'probability': 0.1, 'generator': new_purchase},\n",
    "                          {'probability': 0.85, 'generator': new_bet},\n",
    "                          {'probability': 0.05, 'generator': new_win}]\n",
    "\n",
    "    group1_events = generate_events(fake, num_users_group1, group1_events_dist, events_per_user, True)\n",
    "    group2_events = generate_events(fake, num_users_group2, group2_events_dist, events_per_user, False)\n",
    "\n",
    "    events = (group1_events + group2_events)\n",
    "    events.sort(key=lambda event: event.get('event_time'))\n",
    "\n",
    "    # ingest events to stream\n",
    "    batch_size = 1000\n",
    "    for i in range(0, len(events), batch_size):\n",
    "        # Convert the events to records\n",
    "        records = [{'data': json.dumps(event, default=str)} for event in events[i:i+batch_size]]\n",
    "        v3io_client.batch.stream.put_records(container=container, stream_path=output_stream_path, records=records)\n",
    "\n",
    "    return v3io_client.batch.wait()\n",
    "\n",
    "\n",
    "def create_enrichment_table(v3io_client, container, enrichment_table_path):\n",
    "    for postcode in range(10000, 99999):\n",
    "        remainder = postcode % 3\n",
    "        if remainder == 0:\n",
    "            idx = randint(3, 5)\n",
    "        elif remainder == 1:\n",
    "            idx = randint(1, 3)\n",
    "        else:\n",
    "            idx = randint(5, 7)\n",
    "\n",
    "        attr = {'postcode': postcode, 'socioeconomic_idx': idx}\n",
    "        v3io_client.batch.kv.put(container=container,\n",
    "                                 table_path=enrichment_table_path,\n",
    "                                 key=str(postcode),\n",
    "                                 attributes=attr)\n",
    "    return v3io_client.batch.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(context: MLClientCtx,\n",
    "         container: str,\n",
    "         output_stream_path: str,\n",
    "         enrichment_table_path: str,\n",
    "         num_users_group1: int = 1400,\n",
    "         num_users_group2: int = 600,\n",
    "         events_per_user: int = 1000) -> None:\n",
    "\n",
    "    v3io_client = v3io.dataplane.Client(endpoint=os.getenv('V3IO_API'),\n",
    "                                        access_key=os.getenv('V3IO_ACCESS_KEY'))\n",
    "    \n",
    "    # generate enrichment table\n",
    "    table_resps = create_enrichment_table(v3io_client, container, enrichment_table_path)\n",
    "    written_items = sum(int(resp.status_code == 200) for resp in table_resps)\n",
    "    context.logger.info(f'Created enrichment table with {written_items} items')\n",
    "    \n",
    "    # generate event stream\n",
    "    stream_resps = generate_event_stream(v3io_client, container, output_stream_path,\n",
    "                                         num_users_group1, num_users_group2, events_per_user)\n",
    "\n",
    "    records_sent = sum(len(json.loads(resp.body)['Records']) for resp in stream_resps)\n",
    "    context.logger.info(f'Records sent {records_sent}')\n",
    "\n",
    "    failed_records = sum(json.loads(resp.body)['FailedRecordCount'] for resp in stream_resps)\n",
    "\n",
    "    if failed_records > 0:\n",
    "        context.logger.warn(f'Failed to stream {failed_records}')\n",
    "    else:\n",
    "        context.logger.info('All data streamed successfully.')\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell uses the `# nuclio: end-code` marker to mark the end of a Nuclio code section and instruct Nuclio to stop parsing the notebook at this point.<br>\n",
    "> **IMPORTANT:** Do not remove the end-code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert code to function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use MLRun `code_to_function` in order to convert the python code to a Nuclio function. We then set the relevant enrivonment variables and streaming trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mlconf\n",
    "from mlrun import code_to_function\n",
    "import os\n",
    "\n",
    "mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'\n",
    "mlconf.artifact_path = mlconf.artifact_path or f'{os.environ[\"HOME\"]}/artifacts'\n",
    "\n",
    "\n",
    "fn = code_to_function(name='data-generator', kind = 'job', handler='main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test target stream \n",
    "test_path = os.path.join(os.getcwd(), 'test')\n",
    "\n",
    "v3io_client = v3io.dataplane.Client()\n",
    "container = 'users'\n",
    "output_stream_path = os.path.join(test_path.replace('/User', os.getenv('V3IO_USERNAME')), 'data-generator-stream')\n",
    "v3io_client.stream.create(container=container, stream_path=output_stream_path, shard_count=1)\n",
    "\n",
    "#set enrichment table path\n",
    "enrichment_table_path = os.path.join(test_path.replace('/User', os.getenv('V3IO_USERNAME')), 'data-generator-table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters and  environment variables\n",
    "envs = {'V3IO_API': os.getenv('V3IO_API'),\n",
    "        'V3IO_ACCESS_KEY': os.getenv('V3IO_ACCESS_KEY')}\n",
    "params = {'container': 'users',\n",
    "         'output_stream_path': output_stream_path,\n",
    "         'enrichment_table_path': enrichment_table_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure function instances\n",
    "Here we configure a function instances for each of the streams we want to use `stream to parquet` upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.set_envs(envs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build\n",
    "fn.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run\n",
    "fn.run(params=params,\n",
    "      artifact_path=mlconf.artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "!rm -rf {test_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
