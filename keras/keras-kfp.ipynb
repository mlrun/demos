{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tensorflow-Keras and Scikit-Learn With MLRun**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLRun is an open-source Python package that provides a framework for running machine learning tasks transparently in multiple, scalable, runtime environments.  MLRun provides tracking of code, metadata, inputs, outputs and the results of machine learning pipelines. \n",
    "\n",
    "In this notebook we\"ll compose a pipeline that deploys a classifier model, and uses it as the input in a training and validation step. We'll be working with a synthetic features matrix of dimension 10 million rows by 20 features and a binary label.  The model will be a 2-layer neural net classifier using **[tensorflow-keras](https://www.tensorflow.org/)** (v2.0.0b1), without gpu support.\n",
    "\n",
    "The dataset we create is balanced, however there is a `weight` parameter in the data generator function specifying the fraction of observations that are labeled 0/False. The number of samples and features are also parameters.  The demonstration could be modified easily to allow for a more fine-grained control over the simulated dataset either by adding more parameters or replacing the underlying function altogether.\n",
    "\n",
    "The training and validation step employs a scikit learn `Pipeline` to perform feature engineering. Some of the feature engineering needs to be done _**after**_ the train-valid-test set split. In some preprocessing scenarios we might estimate a data transformation on the training set before model training, and then apply the estimate to the validation and test sets before prediction. Since we need to perform the same transformation pre-inference, all pipeline model steps are stored.\n",
    "\n",
    "Serializing models can be challenging for number of reasons:  a pipeline with multiple steps may require just as many encoding and decoding routines--applying Python's `pickle` to a Keras model that has been wrapped in a scikit-learn api fails.  Since we have the model architecture in a class definition, all we need to do is save the weights.  Some steps in a pipeline may have no internal state to store, while others can be stored and loaded using `pickle`.  Most of it all boils down to storing dicts/json with numpy objects.\n",
    "\n",
    "One of the upsides of the present architecture is that we can mix many simulations of data with a given model estimator, or many models with a given data sample and track everything in **MLRun**.  Research, development, and deployment, all on one page, running under multiple configurations, limited only by the compute resources at our disposal.\n",
    "\n",
    "\n",
    "#### **notebook take-aways**\n",
    "* write and test reusable and replaceable **[MLRun](https://github.com/mlrun)** components in a notebook, file or github repository\n",
    "* store and load models\n",
    "* run the components as a **[KubeFlow](https://www.kubeflow.org/)** pipeline\n",
    "\n",
    "<a id='top'></a>\n",
    "#### **steps**\n",
    "**[nuclio code section](#nuclio-code-section)**<br>\n",
    "    - [nuclio's ignore](#ignore)<br>\n",
    "    - [function dependencies](#function-dependencies)<br>\n",
    "\n",
    "**[components](#components)**<br>\n",
    "    - [supporting functions](#imports)<br>\n",
    "    - [data simulation](#data_generator)<br>\n",
    "    - [feature engineering](#feateng)<br>\n",
    "    - [a classifier](#classifier)<br>\n",
    "    - [save and load pipeline model](#save-load)<br>\n",
    "    - [training and validation](#train)<br>\n",
    "**[local tests](#local-testing)**<br>\n",
    "**[remote tests](#remote)**<br>\n",
    "**[compose pipeline](#compose)**<br>\n",
    "**[run](#run)**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nuclio-code-section\"></a>\n",
    "# **nuclio code section**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ignore'></a>\n",
    "### _nuclio's **ignore** notation_\n",
    "\n",
    "You'll write all the code that gets packaged for execution between the tags ```# nuclio: ignore```, meaning ignore all the code here and above, and ```# nuclio: end-code```, meaning ignore everything after this annotation.  The **[docs](https://github.com/nuclio/nuclio-jupyter#creating-and-debugging-functions-using-nuclio-magic)** also suggest another approach: we can use ```# nuclio: start``` at the first relevant code cell instead of marking all the cells above with ```# nuclio: ignore```.\n",
    "\n",
    "See the **[nuclio-jupyter](https://github.com/nuclio/nuclio-jupyter)** repo for further information on these and many other **[nuclio magic commands](https://github.com/nuclio/nuclio-jupyter#creating-and-debugging-functions-using-nuclio-magic)** that make it easy to transform a Jupyter notebook environment into a platform for developing production-quality, machine learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two lines _**should be in the same cell**_ and mark the start of your mchine learning coding section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"function-dependencies\"></a>\n",
    "### _function dependencies_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The installs made in the section **[Setup](#Setup)** covered the Jupyter environment within which this notebook runs.  However, we need to ensure that all the dependencies our nuclio function relies upon (such as ```matplotlib```, ```sklearn```, ```lightgbm```), will be available when that code is wrapped up into a nuclio function _**on some presently unknown runtime**_.   Within the nuclio code section we can ensure these dependencies get built into the function with the ```%nuclio cmd``` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "rm /conda/lib/python3.6/site-packages/seaborn* -rf\n",
    "pip install -U -q seaborn\n",
    "pip install -U -q matplotlib\n",
    "pip install -U -q tensorflow==2.0.0b1\n",
    "pip install -U -q scikit-learn\n",
    "pip install -U -q pyarrow\n",
    "pip install -U -q pandas \n",
    "pip install -U -q numpy==1.17.4\n",
    "pip install -U -q git+https://github.com/yjb-ds/functions-demo.git\n",
    "    \n",
    "pip uninstall -y mlrun\n",
    "pip install -U -q mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We\"ll use a standard base image here, however the build step can be shortened by preparing images with pre-installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.build.baseImage to 'python:3.6-jessie'\n"
     ]
    }
   ],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"support\"></a>\n",
    "### _imports_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from pickle import dump, load\n",
    "import json\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, roc_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Union, Optional, List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun.artifacts import TableArtifact, PlotArtifact\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.models import KerasClassifier, FeaturesEngineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='paths'></a>\n",
    "### _paths and parameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PATH = '/User/mlrun/simdata'\n",
    "\n",
    "# data simulation and ml training parameter\n",
    "BATCH_SIZE = 1_024\n",
    "LEARNING_RATE = 0.1\n",
    "EPOCHS= 3\n",
    "N_SAMPLES = 1_000_000\n",
    "M_FEATURES = 20\n",
    "CLASS_BALANCE = 0.5\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"components\" ></a>\n",
    "______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **components**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_generator'></a>\n",
    "## **data generator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function we wrap a scikit-learn data generator and log the data and header as artifacts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feateng'></a>\n",
    "## **feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class implements the scikit-learn transformer API, enabling it to fit into an sklearn `Pipeline` as a step.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classifier\"></a>\n",
    "## **classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a list of classifiers we will run against the artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier_model_generator(\n",
    "    metrics: list = [],\n",
    "    input_size: int = 20,\n",
    "    dropout: float = 0.5,\n",
    "    output_bias: float = None,\n",
    "    learning_rate: float = 1e-3\n",
    "):\n",
    "    \"\"\"Generate a super simple classifier\n",
    "\n",
    "    :param metrics:      select metrics to be evaluated\n",
    "    :param output_bias:  layer initializer\n",
    "    :param input_size:   number of features, size of input\n",
    "    :param dropout:      dropout frequency\n",
    "    :param learning_rate:\n",
    "\n",
    "    returns a compiled keras model used as input to the KerasClassifer wrapper\n",
    "    \"\"\"\n",
    "    if output_bias is not None:\n",
    "        output_bias = Constant(output_bias)\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(16, activation=\"relu\", input_shape=(input_size,)),\n",
    "            Dropout(dropout),\n",
    "            Dense(1, activation=\"sigmoid\", bias_initializer=output_bias),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=learning_rate),\n",
    "        loss=BinaryCrossentropy(),\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [keras.metrics.BinaryAccuracy(name=\"accuracy\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train'></a>\n",
    "## **training and validation**\n",
    "\n",
    "In this notebook demonstration we follow standard practice by wrapping the training/validation and test steps into the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_validation(\n",
    "    context: MLClientCtx, \n",
    "    train_metric,\n",
    "    valid_metric,\n",
    "    title: str = \"training validation results\",\n",
    "    xlabel: str = \"epoch\",\n",
    "    ylabel: str = \"\",\n",
    "    target_path: str = \"\",\n",
    "    key: str = \"\",\n",
    ") -> None:\n",
    "    \"\"\"Plot train and validation loss curves from a metrics table in an\n",
    "    artifact store.\n",
    "    \n",
    "    These curves represent the training round losses from the training\n",
    "    and validation sets.\n",
    "    :param train_metric:    train metric\n",
    "    :param valid_metric:    validation metric\n",
    "    :param title:           plot title\n",
    "    :param xlabel:          X-axis label\n",
    "    :param ylabel:          Y-axis label\n",
    "    :param target_path:     save plot in this folder\n",
    "    :param key:             plot's key in the artifact store\n",
    "    \"\"\"\n",
    "    plt.plot(train_metric)\n",
    "    plt.plot(valid_metric)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend([\"train\", \"valid\"])\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    plotpath = os.path.join(target_path, \"history.png\")\n",
    "    plt.savefig(plotpath)\n",
    "    context.log_artifact(PlotArtifact('training-validation-plot',\n",
    "                                      body=fig,\n",
    "                                      target_path=plotpath))\n",
    "\n",
    "    # to ensure we don't overwrite this figure when creating the next:\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_roc(\n",
    "    context: MLClientCtx, \n",
    "    y_labels,\n",
    "    y_probs,\n",
    "    title: str = \"roc curve\",\n",
    "    xlabel: str = \"false positive rate\",\n",
    "    ylabel: str = \"true positive rate\",\n",
    "    fmt: str = \"png\",\n",
    "    target_path: str = \"\",\n",
    "    key: str = \"\",\n",
    ") -> None:\n",
    "    \"\"\"Plot an ROC curve from test data saved in an artifact store.\n",
    "    :param y_labels:        test data labels\n",
    "    :param y_probs:         test data \n",
    "    :param title:           plot title\n",
    "    :param xlabel:          X-axis label (not tick labels)\n",
    "    :param ylabel:          Y-axis label (not tick labels)\n",
    "    :param fmt:             plot file image format (png, jpg, ...)\n",
    "    :param target_path:     save plot in this folder\n",
    "    :param key:             plot's key in the artifact store                \n",
    "    \"\"\"\n",
    "    fpr_xg, tpr_xg, _ = roc_curve(y_labels, y_probs)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.plot(fpr_xg, tpr_xg, label=\"roc\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"best\")\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    plotpath = os.path.join(target_path, \"roc.png\")\n",
    "    fig.savefig(plotpath, format=fmt)\n",
    "    context.log_artifact(PlotArtifact('roc', body=fig))\n",
    "    \n",
    "    # to ensure we don't overwrite this figure when creating the next:\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_confusion_matrix(\n",
    "    context: MLClientCtx, \n",
    "    labels,\n",
    "    predictions,\n",
    "    title: str = \"confusion matrix\",\n",
    "    axislabels: List = None,\n",
    "    target_path: str = \"\",\n",
    "    key: str = \"\",\n",
    ") -> None:\n",
    "    \"\"\"Create a confusion matrix.\n",
    "    Plot and save a confusion matrix using test_data from a\n",
    "    pipeline step.  The plot is generated usung default arguments.\n",
    "    The present example could be extended by including a parameters `dict`\n",
    "    that is passed through to sklearn's `confusion_matrix`,\n",
    "    `ConfusionMatrixDisplay`, and matplotlib `plot`.\n",
    "    :param labels:          test data labels\n",
    "    :param predictions:     test data predictions\n",
    "    :param title:           plot title\n",
    "    :param axislabels:      list of classes, for labeling axes\n",
    "    :param target_path:     save plot in this folder\n",
    "    :param key:             plot's key in the artifact store\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(labels,\n",
    "                          predictions,\n",
    "                          sample_weight=None,\n",
    "                          labels=axislabels,\n",
    "                          normalize='all')\n",
    "    sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "    plotpath = os.path.join(target_path, \"confusion.png\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(plotpath)\n",
    "    context.log_artifact(PlotArtifact('confusion_matrix', body=fig))\n",
    "\n",
    "    # to ensure we don't overwrite this figure when creating the next:\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_importance(\n",
    "    context: MLClientCtx, \n",
    "    model,\n",
    "    header: List = [],\n",
    "    title: str = 'LightGBM Features',\n",
    "    fmt: str = \"png\",\n",
    "    target_path: str = '',\n",
    "    key: str = ''\n",
    ")-> None:\n",
    "    \"\"\"Display estimated feature importances.\n",
    "    \n",
    "    :param model:       fitted lightgbm model\n",
    "    :param header:      list of feature names\n",
    "    :param title:       ('LightGBM Features') plot title\n",
    "    :param fmt:         plot file image format (png, jpg, ...)\n",
    "    :param target_path: destination folder for files\n",
    "    :param key:         key of artifact in artifact store\n",
    "    \n",
    "    \"\"\"\n",
    "    # create a feature importance table with desired labels\n",
    "    zipped = zip(model.feature_importances_, header)\n",
    "    \n",
    "    feature_imp = pd.DataFrame(sorted(zipped), columns=['freq','feature']\n",
    "                              ).sort_values(by=\"freq\", ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.barplot(x=\"freq\", y=\"feature\", data=feature_imp)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()\n",
    "    plotpath = os.path.join(target_path, \"feature-importances.png\")\n",
    "    fig.savefig(plotpath)\n",
    "    context.log_artifact(PlotArtifact('feature-importances-plot', body=fig))\n",
    "\n",
    "    # feature importances are also saved as a table:\n",
    "    tablepath = os.path.join(target_path, \"feature-importances-table.csv\")\n",
    "    feature_imp.to_csv(tablepath)\n",
    "    context.log_artifact(TableArtifact('feature-importances-table',\n",
    "                                       target_path=tablepath))\n",
    "    \n",
    "    # to ensure we don't overwrite this figure when creating the next:\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_instance(module_class: str, target_path: Optional[str] = None):\n",
    "    \"\"\"Instantiate a class from strings\n",
    "    \n",
    "    :param module_class:   full package and module string\n",
    "    :param target_path:    (Optional) destination folder for the serialized\n",
    "                           class\n",
    "    \n",
    "    For example, to instantiate a sklearn StandardScaler,\n",
    "    use:\n",
    "    >>> ss = class_instance('sklearn.preprocessing.data.StandardScaler')\n",
    "     \n",
    "    :param module_class:   module and class name\n",
    "    \n",
    "    \"\"\"\n",
    "    splits = module_class.split(\".\")\n",
    "    module = \".\".join(splits[:-1])\n",
    "    aclass = splits[-1]\n",
    "\n",
    "    module = importlib.import_module(module)\n",
    "    class_ = getattr(module, aclass)\n",
    "    if target_path:\n",
    "        setattr(class_, 'target_path', target_path)\n",
    "    \n",
    "    return class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model(\n",
    "    context: MLClientCtx,\n",
    "    model,\n",
    "    history,\n",
    "    test_data: pd.DataFrame, \n",
    "    header: List = [],\n",
    "    target_path: str = '',\n",
    "    name: str = 'model.pkl',  # with file extension\n",
    "    key: str = 'model',\n",
    "    labels: dict = {}\n",
    "):\n",
    "    \"\"\"log a classifier model to the artifact store\n",
    "    \n",
    "    :param context:       function context\n",
    "    :param model:         estimated model\n",
    "    :param history:       training-validation metrics\n",
    "    :param test_data:     test labels and test predictions\n",
    "    :param header:        features labels\n",
    "    :param target_path:   destintion folder for file artifacts\n",
    "    :param name:          name of model file (or, prefix to model files)\n",
    "    :param key:           key of model in artifact store\n",
    "    :param labels:        model artifact labels\n",
    "    \n",
    "    Save an estimated model along with metadata, it's training-validation metrics \n",
    "    history and plots, roc curve, confusion matrix and feature importances.  \n",
    "    \"\"\"\n",
    "    loss = np.asarray(history['train']['binary_logloss'], dtype=np.float)\n",
    "    val_loss = np.asarray(history['valid']['binary_logloss'], dtype=np.float)\n",
    "    \n",
    "    _plot_validation(context, loss, val_loss, target_path=target_path, key='training-validation-metrics')\n",
    "    _plot_roc(context, test_data.y_test, test_data.y_probs, target_path=target_path, key='roc-curve')\n",
    "    _plot_confusion_matrix(context, test_data.y_test, test_data.y_pred, target_path=target_path, key='confusion-matrix')\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        _plot_importance(context, model, header, target_path=target_path, key='feature-importances')\n",
    "    else:\n",
    "        # do something else here to calculate importances (use a generic package like SHAPELY)\n",
    "        pass\n",
    "   \n",
    "    # save the model and log  as an artifact\n",
    "    filepath = os.path.join(target_path, name)\n",
    "    dump(model, open(filepath, 'wb'))\n",
    "    context.log_artifact(key,\n",
    "                         target_path=filepath)\n",
    "                         #,\n",
    "                         #labels=labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    context: MLClientCtx,\n",
    "    data_src_file: str,\n",
    "    engineer_cls: str,\n",
    "    scaler_cls: str,\n",
    "    classifier_cls: str,\n",
    "    #classifier_model: Optional[Callable] = None, \n",
    "    classifier_params: Optional[dict] = {}, \n",
    "    target_path: str = '',\n",
    "    key: str = '',\n",
    "    name: str = '',\n",
    "    test_size: float = 0.1,\n",
    "    valid_size: float = 0.3,\n",
    "    batch_size: int = 1024,\n",
    "    epochs: int = 5,\n",
    "    verbose: bool = True,\n",
    "    random_state: int = 1,\n",
    "    ) -> None:\n",
    "    \"\"\"Train, validate, test and save a classifier model pipeline.\n",
    "    \n",
    "    Here we split the data, instantiate our pipeline and its models, and proceed\n",
    "    to training and validation.\n",
    "    \n",
    "    The target_path defines the base folder where artifacts will be stored.  Since we\n",
    "    intend to save both the model (and its components), the test set and \n",
    "    its predictions, and the history of metric estimates we provide three keys.\n",
    "    \n",
    "    :param context:             function context\n",
    "    :param data_src_file:       location of cleaned input\n",
    "    :param engineer_cls:        feature engineering class\n",
    "    :param scaler_cls:          scaler class\n",
    "    :param classifier_cls:      classifier class    \n",
    "    :param classifier_model:    if the classifier has a model generator (Keras, Pytorch\n",
    "                                using sklearn API)\n",
    "    :param classifier_params:   parameters used in classifier model\n",
    "    :param target_path:         destination (folder) for artifact files\n",
    "    :param key:                 model key in the artifact store\n",
    "    :param name:                name of model file\n",
    "    :param test_size:           (0.1) test set size as fraction\n",
    "    :param valid_size:          (0.3) validation set size as fraction\n",
    "    :param batch_size:          (1024) network feed batch size\n",
    "    :param epochs:              (5) training epochs\n",
    "    :param verbose:             (default True) Show metrics for \n",
    "                                training/validation steps\n",
    "        \n",
    "    Also included for demonstration are a randomly selected sample\n",
    "    of training parameters:\n",
    "    :param learning_rate: Step size at each iteration, constant.\n",
    "    \"\"\"\n",
    "    srcfilepath = os.path.join(target_path, data_src_file)\n",
    "    raw = pd.read_parquet(srcfilepath, engine='pyarrow')\n",
    "    \n",
    "    train, test = train_test_split(raw, test_size=test_size)\n",
    "    train, valid = train_test_split(train, test_size=valid_size)\n",
    "    \n",
    "    ytrain = train.pop('labels')\n",
    "    yvalid = valid.pop('labels')\n",
    "    ytest = test.pop('labels')\n",
    "\n",
    "    # instantiate features engineer, scaler and classifier\n",
    "    Engineer = class_instance(engineer_cls)\n",
    "    Scaler = class_instance(scaler_cls)\n",
    "    Classifier = class_instance(classifier_cls, target_path=target_path)\n",
    "    \n",
    "    if my_classifier_model_generator:\n",
    "        pipe = Pipeline(\n",
    "            steps=[('engineer', Engineer()),\n",
    "                   ('scaler', Scaler()),\n",
    "                   ('classifier', Classifier(my_classifier_model_generator, **classifier_params))]\n",
    "                   #('classifier', Classifier(my_classifier_model_generator, input_size=20))]\n",
    "        )\n",
    "    else:\n",
    "        pipe = Pipeline(\n",
    "            steps=[('engineer', Engineer()),\n",
    "                   ('scaler', Scaler()),\n",
    "                   ('classifier', Classifier(**classifier_params))])\n",
    "                   #('classifier', Classifier(input_size=20))])\n",
    "        \n",
    "    pipe.fit(train, ytrain,\n",
    "             classifier__epochs=epochs, \n",
    "             classifier__batch_size=batch_size,\n",
    "             classifier__validation_split=0.25) # fudge\n",
    "\n",
    "    # check to see if 'predict_proba' exists for this extimator:\n",
    "    if hasattr(pipe, 'predict_proba'):\n",
    "        ypred_probs = pipe.predict_proba(test)[:, 1]\n",
    "        ypred = np.where(ypred_probs >= 0.5, 1, 0)\n",
    "    else:\n",
    "        ypred = pipe.predict(test)\n",
    "        ypred_probs = []\n",
    "\n",
    "        # we can eliminate one of y_pred or y_probs\n",
    "    test_data = dict({\n",
    "        'y_test': ytest.values,\n",
    "        'y_pred': ypred, \n",
    "        'y_probs': ypred_probs\n",
    "    })\n",
    "        \n",
    "    acc = accuracy_score(ytest, ypred)\n",
    "    context.log_result(\"accuracy\", float(acc))\n",
    "\n",
    "    # keras metrics history\n",
    "    history = dict({\n",
    "        'train': {'binary_logloss' : pipe.named_steps.classifier.model.history.history['loss']},\n",
    "        'valid': {'binary_logloss' : pipe.named_steps.classifier.model.history.history['val_loss']},\n",
    "    })\n",
    "    \n",
    "    log_model(context, \n",
    "          pipe, \n",
    "          history, \n",
    "          pd.DataFrame({'y_test': ytest.values, \n",
    "                        'y_pred': ypred, \n",
    "                        'y_probs': ypred_probs}),\n",
    "          target_path=target_path,\n",
    "          header=list(raw),\n",
    "          name=name, \n",
    "          key=key)\n",
    "          #, \n",
    "          #labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _end of nuclio function definition_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"local-testing\" ></a>\n",
    "______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **testing your code locally**\n",
    "\n",
    "The function can be run locally and debugged/tested before deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import (mlconf,\n",
    "                   code_to_function,\n",
    "                   new_function,\n",
    "                   NewTask,\n",
    "                   new_model_server,\n",
    "                   mount_v3io)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set MLRun's DB path.  MLRun wil generate and store all of its tracking and metadata to the `MLRUN_DBATH` environment variable.  We have set a `TARGET_PATH` earlier in this notebook in the above section **[paths and parameters](#paths)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = new_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-01-16 13:04:13,499 log artifact header at /User/mlrun/simdata/header.json, size: None, db: Y\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"afe532ee873b437fb438486b8c062ee0\">...062ee0</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Jan 16 13:04:11</td>\n",
       "      <td>completed</td>\n",
       "      <td>data generator</td>\n",
       "      <td><div class=\"dictlist\">host=jupyter-1-6c8766ddb7-rp87j</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">n_samples=1000000</div><div class=\"dictlist\">m_features=20</div><div class=\"dictlist\">weight=0.5</div><div class=\"dictlist\">target_path=/User/mlrun/simdata</div><div class=\"dictlist\">key=simdata</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resulta3e713fe\" title=\"/files/mlrun/simdata/header.json\">header</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resulta3e713fe-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resulta3e713fe-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resulta3e713fe\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resulta3e713fe-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run afe532ee873b437fb438486b8c062ee0  , !mlrun logs afe532ee873b437fb438486b8c062ee0 \n",
      "[mlrun] 2020-01-16 13:04:15,451 run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "datagen_run = workflow.run(\n",
    "    name='data generator',\n",
    "    handler=create_binary_classification,\n",
    "    params={\n",
    "        'n_samples':      N_SAMPLES,\n",
    "        'm_features':     M_FEATURES,\n",
    "        'weight':         CLASS_BALANCE,\n",
    "        'target_path':    TARGET_PATH,\n",
    "        'key':          'simdata'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 472500 samples, validate on 157500 samples\n",
      "Epoch 1/3\n",
      "472500/472500 [==============================] - 1s 3us/sample - loss: 0.4235 - val_loss: 0.2363\n",
      "Epoch 2/3\n",
      "472500/472500 [==============================] - 1s 2us/sample - loss: 0.2481 - val_loss: 0.1634\n",
      "Epoch 3/3\n",
      "472500/472500 [==============================] - 1s 2us/sample - loss: 0.1953 - val_loss: 0.1322\n",
      "[mlrun] 2020-01-16 13:08:02,796 log artifact training-validation-plot.html at /User/mlrun/simdata/history.png, size: 18696, db: Y\n",
      "[mlrun] 2020-01-16 13:08:02,979 log artifact roc.html at roc.html, size: 19159, db: Y\n",
      "[mlrun] 2020-01-16 13:08:03,243 log artifact confusion_matrix.html at confusion_matrix.html, size: 9440, db: Y\n",
      "GETSTATE\n",
      "[mlrun] 2020-01-16 13:08:03,336 log artifact model at /User/mlrun/simdata/model.pkl, size: None, db: Y\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"1735652826bb49aaaeede8226aaa2129\">...aa2129</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Jan 16 13:07:55</td>\n",
       "      <td>completed</td>\n",
       "      <td>train, validate and store model</td>\n",
       "      <td><div class=\"dictlist\">host=jupyter-1-6c8766ddb7-rp87j</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">data_src_file=simdata-1e06X20.parquet</div><div class=\"dictlist\">scaler_cls=sklearn.preprocessing.data.StandardScaler</div><div class=\"dictlist\">engineer_cls=functions.models.FeaturesEngineer</div><div class=\"dictlist\">classifier_cls=functions.models.KerasClassifier</div><div class=\"dictlist\">classifier_params={'input_size': 20}</div><div class=\"dictlist\">target_path=/User/mlrun/simdata</div><div class=\"dictlist\">name=model.pkl</div><div class=\"dictlist\">key=model</div><div class=\"dictlist\">batch_size=1024</div><div class=\"dictlist\">epochs=3</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=0.95738</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resultac86449d\" title=\"/files/mlrun/simdata/history.png\">training-validation-plot.html</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resultac86449d\" title=\"/files/repos/demos/keras/roc.html\">roc.html</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resultac86449d\" title=\"/files/repos/demos/keras/confusion_matrix.html\">confusion_matrix.html</div><div title=\"/User/mlrun/simdata/model.pkl\">model</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resultac86449d-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resultac86449d-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resultac86449d\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resultac86449d-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 1735652826bb49aaaeede8226aaa2129  , !mlrun logs 1735652826bb49aaaeede8226aaa2129 \n",
      "[mlrun] 2020-01-16 13:08:03,393 run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "train_run = workflow.run(\n",
    "    name='train, validate and store model',\n",
    "    handler=train,\n",
    "    params={\n",
    "        'data_src_file':    'simdata-1e06X20.parquet',\n",
    "        'scaler_cls':       'sklearn.preprocessing.data.StandardScaler',\n",
    "        'engineer_cls':     'functions.models.FeaturesEngineer',\n",
    "        'classifier_cls':   'functions.models.KerasClassifier',\n",
    "        #'classifier_model':  my_classifier_model_generator,\n",
    "        'classifier_params': {'input_size':20},\n",
    "        'target_path':     TARGET_PATH,\n",
    "        'name':            'model.pkl',\n",
    "        'key':             'model',\n",
    "        'batch_size':      BATCH_SIZE,\n",
    "        'epochs':          3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"image\"></a>\n",
    "#### _Create a deployment image_\n",
    "\n",
    "Once debugged you can create a reusable image, and then deploy it for testing. In the following line we are converting the code block between the ```#nuclio: ignore``` and ```#nuclio: end-code``` to be run as a KubeJob. _**It is important to ensure that this function has been `deploy`ed at least once, and that you have access to it.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfkeras_job = code_to_function(name='tfkeras_job',\n",
    "                               runtime=\"job\").apply(mount_v3io())\n",
    "\n",
    "# set this to True so that updates to our git package are reflected in the built image,\n",
    "# but please note however that this may lengthen image build times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfkeras_job.spec.no_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfkeras_job.deploy()\n",
    "# other options:\n",
    "# ignore if exists\n",
    "# save and/or export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfkeras_job.with_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"remote\"></a>\n",
    "# **test your code remotely**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-01-16 13:17:58,793 starting run create_binary_classification uid=4f3194306e7c440f9108390d6e0c81d9  -> http://mlrun-api:8080\n",
      "[mlrun] 2020-01-16 13:17:58,945 Job is running in the background, pod: create-binary-classification-z6rr5\n",
      "2020-01-16 13:18:08.152271: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-01-16 13:18:08.157964: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499995000 Hz\n",
      "2020-01-16 13:18:08.158794: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5bf9fb0 executing computations on platform Host. Devices:\n",
      "2020-01-16 13:18:08.158816: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "[mlrun] 2020-01-16 13:18:10,168 log artifact header at /User/mlrun/simdata/header.json, size: None, db: Y\n",
      "\n",
      "[mlrun] 2020-01-16 13:18:11,933 run executed, status=completed\n",
      "final state: succeeded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"4f3194306e7c440f9108390d6e0c81d9\">...0c81d9</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Jan 16 13:18:08</td>\n",
       "      <td>completed</td>\n",
       "      <td>tfkeras-job</td>\n",
       "      <td><div class=\"dictlist\">host=create-binary-classification-z6rr5</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">key=simdata</div><div class=\"dictlist\">m_features=20</div><div class=\"dictlist\">n_samples=1000000</div><div class=\"dictlist\">target_path=/User/mlrun/simdata</div><div class=\"dictlist\">weight=0.5</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resultb168c0a9\" title=\"/files/mlrun/simdata/header.json\">header</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resultb168c0a9-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resultb168c0a9-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resultb168c0a9\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resultb168c0a9-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 4f3194306e7c440f9108390d6e0c81d9  , !mlrun logs 4f3194306e7c440f9108390d6e0c81d9 \n",
      "[mlrun] 2020-01-16 13:18:18,124 run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "task = NewTask()\n",
    "\n",
    "task.with_params(\n",
    "    n_samples=N_SAMPLES,\n",
    "    m_features=M_FEATURES,\n",
    "    weight=CLASS_BALANCE,\n",
    "    target_path=TARGET_PATH,\n",
    "    key='simdata')\n",
    "\n",
    "nrun = tfkeras_job.run(task, handler='create_binary_classification', out_path=TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-01-16 13:18:23,837 starting run train uid=ca58459ea36345309cd03999101e3af5  -> http://mlrun-api:8080\n",
      "[mlrun] 2020-01-16 13:18:23,990 Job is running in the background, pod: train-vjw84\n",
      "2020-01-16 13:18:33.234972: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-01-16 13:18:33.240288: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499995000 Hz\n",
      "2020-01-16 13:18:33.241107: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x51c2240 executing computations on platform Host. Devices:\n",
      "2020-01-16 13:18:33.241131: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-01-16 13:18:35.391089: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "Train on 472500 samples, validate on 157500 samples\n",
      "Epoch 1/3\n",
      "472500/472500 [==============================] - 1s 3us/sample - loss: 0.5158 - val_loss: 0.2543\n",
      "Epoch 2/3\n",
      "472500/472500 [==============================] - 1s 2us/sample - loss: 0.2679 - val_loss: 0.1710\n",
      "Epoch 3/3\n",
      "472500/472500 [==============================] - 1s 2us/sample - loss: 0.2017 - val_loss: 0.1290\n",
      "[mlrun] 2020-01-16 13:18:40,536 log artifact training-validation-plot.html at /User/mlrun/simdata/history.png, size: 39296, db: Y\n",
      "[mlrun] 2020-01-16 13:18:40,897 log artifact roc.html at /User/mlrun/simdata/roc.html, size: 36803, db: Y\n",
      "[mlrun] 2020-01-16 13:18:41,270 log artifact confusion_matrix.html at /User/mlrun/simdata/confusion_matrix.html, size: 16832, db: Y\n",
      "GETSTATE\n",
      "[mlrun] 2020-01-16 13:18:41,359 Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/mlrun/runtimes/local.py\", line 174, in exec_from_params\n",
      "    val = handler(*args_list)\n",
      "  File \"main.py\", line 481, in train\n",
      "    key=key)\n",
      "  File \"main.py\", line 368, in log_model\n",
      "    dump(model, open(filepath, 'wb'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/functions/models.py\", line 64, in __getstate__\n",
      "    dump(state['build_fn'], open(os.path.join(tpath, 'build-fn.pkl'), 'wb'))\n",
      "_pickle.PicklingError: Can't pickle <function my_classifier_model_generator at 0x7ff37f2b4378>: import of module 'main' failed\n",
      "\n",
      "\n",
      "[mlrun] 2020-01-16 13:18:41,388 exec error - Can't pickle <function my_classifier_model_generator at 0x7ff37f2b4378>: import of module 'main' failed\n",
      "[mlrun] 2020-01-16 13:18:41,429 run executed, status=error\n",
      "Can't pickle <function my_classifier_model_generator at 0x7ff37f2b4378>: import of module 'main' failed\n",
      "runtime error: Can't pickle <function my_classifier_model_generator at 0x7ff37f2b4378>: import of module 'main' failed\n",
      "final state: failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"ca58459ea36345309cd03999101e3af5\">...1e3af5</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Jan 16 13:18:33</td>\n",
       "      <td><div style=\"color: red;\" title=\"Can't pickle <function my_classifier_model_generator at 0x7ff37f2b4378>: import of module 'main' failed\">error</div></td>\n",
       "      <td>tfkeras-job</td>\n",
       "      <td><div class=\"dictlist\">host=train-vjw84</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">batch_size=1024</div><div class=\"dictlist\">classifier_cls=functions.models.KerasClassifier</div><div class=\"dictlist\">classifier_params={'input_size': 20}</div><div class=\"dictlist\">data_src_file=simdata-1e06X20.parquet</div><div class=\"dictlist\">engineer_cls=functions.models.FeaturesEngineer</div><div class=\"dictlist\">epochs=3</div><div class=\"dictlist\">key=model</div><div class=\"dictlist\">name=model.pkl</div><div class=\"dictlist\">scaler_cls=sklearn.preprocessing.data.StandardScaler</div><div class=\"dictlist\">target_path=/User/mlrun/simdata</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=0.96257</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resulta8bdfade\" title=\"/files/mlrun/simdata/history.png\">training-validation-plot.html</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resulta8bdfade\" title=\"/files/mlrun/simdata/roc.html\">roc.html</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resulta8bdfade\" title=\"/files/mlrun/simdata/confusion_matrix.html\">confusion_matrix.html</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resulta8bdfade-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resulta8bdfade-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resulta8bdfade\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resulta8bdfade-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run ca58459ea36345309cd03999101e3af5  , !mlrun logs ca58459ea36345309cd03999101e3af5 \n",
      "[mlrun] 2020-01-16 13:18:43,167 run executed, status=error\n",
      "runtime error: Can't pickle <function my_classifier_model_generator at 0x7ff37f2b4378>: import of module 'main' failed\n"
     ]
    },
    {
     "ename": "RunError",
     "evalue": "Can't pickle <function my_classifier_model_generator at 0x7ff37f2b4378>: import of module 'main' failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRunError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-3c574e058fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     epochs=3)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnrun2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfkeras_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter-1/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, runspec, handler, name, project, params, inputs, out_path, watch, schedule)\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_api_server\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-1/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(self, result, runspec, err)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runtime error: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRunError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRunError\u001b[0m: Can't pickle <function my_classifier_model_generator at 0x7ff37f2b4378>: import of module 'main' failed"
     ]
    }
   ],
   "source": [
    "task.with_params(\n",
    "    data_src_file='simdata-1e06X20.parquet',\n",
    "    scaler_cls='sklearn.preprocessing.data.StandardScaler',\n",
    "    engineer_cls='functions.models.FeaturesEngineer',\n",
    "    classifier_cls='functions.models.KerasClassifier',\n",
    "    #classifier_model=my_classifier_model_generator,\n",
    "    classifier_params= {'input_size':20},\n",
    "    target_path=TARGET_PATH,\n",
    "    name='model.pkl',\n",
    "    key='model',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=3)\n",
    "\n",
    "nrun2 = tfkeras_job.run(task, handler='train', out_path=TARGET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"compose\"></a>\n",
    "# **Create a KubeFlow Pipeline from our functions**\n",
    "\n",
    "Our pipeline will consist of two steps, ```data_generator``` and ```train```.\n",
    "\n",
    "For complete details on KubeFlow Pipelines please refer to the following docs:\n",
    "1. **[KubeFlow pipelines](https://www.kubeflow.org/docs/pipelines/)**.\n",
    "2. **[kfp.dsl Python package](https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.dsl.html#module-kfp.dsl)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note, the model server file name in the ```new_model_server``` function call below should identical in every respect to the name of the model server notebook (here, **[model_server.ipynb](#model-server.ipynb)**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srvfn = new_model_server(\"tfkeras\",  \n",
    "                         model_class=\"MyKerasClassifier\",   \n",
    "                         filename=\"model_server.ipynb\")\n",
    "srvfn.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Sklearn and KubeFlow\",\n",
    "    description=\"Shows how to use mlrun/kfp.\"\n",
    ")\n",
    "def tfkeras_pipeline(\n",
    "    neg_weight = [0.5, 0.1],\n",
    "):\n",
    "\n",
    "    datagen = tfkeras_job.as_step(\n",
    "        name='data generator',\n",
    "        handler='create_binary_classification',\n",
    "        out_path=TARGET_PATH, \n",
    "        params={        \n",
    "            'samples':         N_SAMPLES,\n",
    "            'features':        M_FEATURES,\n",
    "            'neg_weight':      CLASS_BALANCE,\n",
    "            'target_path':     TARGET_PATH,\n",
    "            'key':            'simdata'}).apply(mount_v3io())\n",
    "    \n",
    "    train = tfkeras_job.as_step(\n",
    "        name='sklearn pipe train',\n",
    "        handler='train',\n",
    "        out_path=TARGET_PATH, \n",
    "        outputs=['model'],\n",
    "        params={\n",
    "            'data_src_file':       'simdata-1e06X20.parquet',\n",
    "            'scaler_cls':     'sklearn.preprocessing.data.StandardScaler',\n",
    "            'engineer_cls':   'functions.models.FeaturesEngineer',\n",
    "            'classifier_cls': 'functions.models.classifier',\n",
    "            'target_path':     TARGET_PATH,\n",
    "            'name':           'model.pkl',\n",
    "            'key':            'model',\n",
    "            'batch_size':      BATCH_SIZE,\n",
    "            'epochs':          3}).apply(mount_v3io()).after(datagen)\n",
    "\n",
    "    # define a nuclio-serving function, generated from a notebook file\n",
    "    srvfn.deploy_step(project=\"mlrun-demos\", \n",
    "                      models={\"tfkeras_pickle\": train.outputs[\"model\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"compile the pipeline\"></a>\n",
    "### _compile the pipeline_\n",
    "\n",
    "We can compile our KubeFlow pipeline and produce a yaml description of the pipeline worflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(tfkeras_pipeline, TARGET_PATH+\"/mlrunpipe.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace=\"default-tenant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following line will run the pipeline as a job::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {\n",
    "    'neg_weight' : [0.5, 0.1]    \n",
    "}\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(\n",
    "    tfkeras_pipeline, \n",
    "    arguments, \n",
    "    run_name=\"tfkeras\",\n",
    "    experiment_name=\"tfkeras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlrun clean"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
