{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook handles ingestion of stocks data to feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to align client/server mlrun version\n",
    "# !/User/align_mlrun.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-06 11:26:06,823 [info] loaded project stocks from None or context\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "project = mlrun.get_or_create_project(name='stocks',user_project=True, context=\"src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b> Steps </b>\n",
    "> * [Creating mlrun function that reads stocks from yahoo_fin and returning record oriented json](#Creating-mlrun-function-that-reads-stocks-from-yahoo_fin-and-returning-record-oriented-json)\n",
    "> * [Creating a feature set and declaring the graph](#Creating-a-feature-set-and-declaring-the-graph)\n",
    "> * [Dummy ingestion, Deploying ingestion service and getting ingestion endpoint](#Dummy-ingestion,-Deploying-ingestion-service-and-getting-ingestion-endpoint)\n",
    "> * [Testing ingestion service](#Testing-ingestion-service)\n",
    "> * [Creating scheduled mlrun job to invoke our function every time delta](#Creating-scheduled-mlrun-job-to-invoke-our-function-every-time-delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yahoo_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# getting the sentiment analysis pretrained model (433M might take a while)\n",
    "if not os.path.exists('src/model.pt'): \n",
    "    os.makedirs('src',exist_ok=True)\n",
    "    print('getting model')\n",
    "    !wget -O src/model.pt https://iguazio-sample-data.s3.amazonaws.com/models/model.pt \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying sentiment analysis serving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-06 11:26:22,484 [info] Starting remote function deploy\n",
      "2022-07-06 11:26:22  (info) Deploying function\n",
      "2022-07-06 11:26:22  (info) Building\n",
      "2022-07-06 11:26:22  (info) Staging files and preparing base images\n",
      "2022-07-06 11:26:22  (info) Building processor image\n",
      "2022-07-06 11:28:08  (info) Build complete\n",
      "2022-07-06 11:28:38  (info) Function deploy complete\n",
      "> 2022-07-06 11:28:39,680 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-stocks-dani-sentiment-analysis-serving.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['stocks-dani-sentiment-analysis-serving-stocks-dani.default-tenant.app.vmdev94.lab.iguazeng.com/']}\n"
     ]
    }
   ],
   "source": [
    "model_location = os.path.abspath('src/model.pt')\n",
    "sentiment_analysis_serving = mlrun.import_function('hub://sentiment_analysis_serving').apply(mlrun.auto_mount())\n",
    "sentiment_analysis_serving.add_model('sentiment_analysis_model', model_path=model_location,\n",
    "                                      class_name='SentimentClassifierServing')\n",
    "\n",
    "# sentiment_analysis_serving.with_http() # needed to provide http-endpoint to our serving graph\n",
    "\n",
    "address = sentiment_analysis_serving.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating mlrun function that reads stocks from yahoo_fin and returning record oriented json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlrun: start-code\n",
    "\n",
    "import yahoo_fin.stock_info as si\n",
    "import yahoo_fin.news as ynews\n",
    "from dateutil import parser\n",
    "import pandas as pd \n",
    "import json\n",
    "import requests\n",
    "from storey import MapClass, Event\n",
    "import string\n",
    "import mlrun\n",
    "\n",
    "def print_event(event):    \n",
    "    sentiment = event.body['outputs']['predictions'][0]/2\n",
    "    return_event = Event(body={'sentiment': sentiment}, key=event.body['outputs']['meta_data']['ticker'], time=event.body['outputs']['meta_data']['Datetime'])\n",
    "    return return_event\n",
    "\n",
    "def wrap_event(event):\n",
    "    wrapped_event = {'meta_data': {'ticker': event['ticker'], 'Datetime': event['Datetime']}, 'inputs': [event['summary']]}\n",
    "    return wrapped_event\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "def get_news(event):\n",
    "    '''\n",
    "    event: dict with the following keys:\n",
    "    n_stocks - how many stocks to collect\n",
    "    '''\n",
    "    tickers = si.tickers_sp500()[:event['n_stocks']]\n",
    "    tickers_news = []\n",
    "    for ticker in tickers:\n",
    "        news = ynews.get_yf_rss(ticker=ticker)\n",
    "        news_df = pd.DataFrame(news)\n",
    "        df_copy = news_df[['title','summary','link','published']].copy()\n",
    "        df_copy['ticker'] = ticker\n",
    "        df_copy['Datetime'] = df_copy['published'].apply(lambda x: parser.parse(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        df_copy['summary'] = df_copy['summary'].apply(lambda x:remove_punctuation(x))\n",
    "        df_copy['title'] = df_copy['title'].apply(lambda x:remove_punctuation(x))\n",
    "        tickers_news.append(df_copy)\n",
    "    df = pd.concat(tickers_news).reset_index(drop=True)\n",
    "    return json.loads(df.to_json(orient='records'))\n",
    "\n",
    "class sentiment_analysis():\n",
    "    def __init__(self,address):\n",
    "        self.address= address    \n",
    "        \n",
    "    def do(self,event):\n",
    "        response = json.loads(requests.put(self.address + \"v2/models/sentiment_analysis_model/predict\",\n",
    "                                                     json=json.dumps(event.body)).text)\n",
    "        sentiment_event = response['outputs']['meta_data']\n",
    "        sentiment_event['sentiment'] = response['outputs']['predictions'][0]/2 # so it'll be 0 for neg, 0.5 for neutral and 1 for pos\n",
    "        \n",
    "        return Event(sentiment_event,key=sentiment_event['ticker'], time=sentiment_event['Datetime'])\n",
    "    \n",
    "#mlrun: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a feature set and declaring the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"827pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 826.86 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-94 822.8551,-94 822.8551,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"38.5476,-27.0493 40.698,-27.1479 42.8263,-27.2953 44.9236,-27.4913 46.9815,-27.7353 48.9917,-28.0266 50.9463,-28.3645 52.8377,-28.7479 54.6587,-29.1759 56.4025,-29.6472 58.0628,-30.1606 59.634,-30.7147 61.1107,-31.308 62.4882,-31.9388 63.7625,-32.6054 64.9302,-33.3059 65.9882,-34.0385 66.9343,-34.8012 67.7669,-35.5918 68.4849,-36.4082 69.0878,-37.2481 69.5758,-38.1093 69.9496,-38.9894 70.2102,-39.886 70.3595,-40.7965 70.3997,-41.7186 70.3334,-42.6497 70.1636,-43.5873 69.8937,-44.5287 69.5276,-45.4713 69.0691,-46.4127 68.5225,-47.3503 67.8923,-48.2814 67.1831,-49.2035 66.3996,-50.114 65.5464,-51.0106 64.6285,-51.8907 63.6504,-52.7519 62.617,-53.5918 61.5329,-54.4082 60.4024,-55.1988 59.2299,-55.9615 58.0197,-56.6941 56.7755,-57.3946 55.5012,-58.0612 54.2002,-58.692 52.8757,-59.2853 51.5309,-59.8394 50.1684,-60.3528 48.7908,-60.8241 47.4003,-61.2521 45.9989,-61.6355 44.5886,-61.9734 43.1708,-62.2647 41.7472,-62.5087 40.3189,-62.7047 38.8872,-62.8521 37.4531,-62.9507 36.0175,-63 34.5815,-63 33.146,-62.9507 31.7119,-62.8521 30.2801,-62.7047 28.8519,-62.5087 27.4282,-62.2647 26.0105,-61.9734 24.6001,-61.6355 23.1988,-61.2521 21.8083,-60.8241 20.4306,-60.3528 19.0681,-59.8394 17.7233,-59.2853 16.3989,-58.692 15.0979,-58.0612 13.8236,-57.3946 12.5794,-56.6941 11.3691,-55.9615 10.1967,-55.1988 9.0662,-54.4082 7.982,-53.5918 6.9486,-52.7519 5.9706,-51.8907 5.0526,-51.0106 4.1995,-50.114 3.4159,-49.2035 2.7067,-48.2814 2.0765,-47.3503 1.53,-46.4127 1.0715,-45.4713 .7053,-44.5287 .4355,-43.5873 .2657,-42.6497 .1993,-41.7186 .2395,-40.7965 .3888,-39.886 .6495,-38.9894 1.0232,-38.1093 1.5112,-37.2481 2.1141,-36.4082 2.8321,-35.5918 3.6647,-34.8012 4.6109,-34.0385 5.6689,-33.3059 6.8365,-32.6054 8.1108,-31.9388 9.4884,-31.308 10.9651,-30.7147 12.5362,-30.1606 14.1966,-29.6472 15.9404,-29.1759 17.7614,-28.7479 19.6528,-28.3645 21.6074,-28.0266 23.6176,-27.7353 25.6755,-27.4913 27.7728,-27.2953 29.901,-27.1479 32.0515,-27.0493 34.2154,-27 36.3837,-27 38.5476,-27.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.2995\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<!-- get_news -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>get_news</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"161.1942\" cy=\"-45\" rx=\"54.6905\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"161.1942\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">get_news</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;get_news -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;get_news</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M70.0341,-45C78.1776,-45 87.1155,-45 96.1116,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.254,-48.5001 106.254,-45 96.2539,-41.5001 96.254,-48.5001\"/>\n",
       "</g>\n",
       "<!-- flatten_news -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>flatten_news</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"321.9831\" cy=\"-45\" rx=\"70.3881\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"321.9831\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flatten_news</text>\n",
       "</g>\n",
       "<!-- get_news&#45;&gt;flatten_news -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>get_news&#45;&gt;flatten_news</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M216.0789,-45C224.3179,-45 232.9556,-45 241.5932,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"241.7092,-48.5001 251.7091,-45 241.7091,-41.5001 241.7092,-48.5001\"/>\n",
       "</g>\n",
       "<!-- wrap_event -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>wrap_event</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"493.1711\" cy=\"-45\" rx=\"64.9885\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"493.1711\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">wrap_event</text>\n",
       "</g>\n",
       "<!-- flatten_news&#45;&gt;wrap_event -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>flatten_news&#45;&gt;wrap_event</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M392.6002,-45C400.9159,-45 409.4263,-45 417.804,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"417.9353,-48.5001 427.9353,-45 417.9353,-41.5001 417.9353,-48.5001\"/>\n",
       "</g>\n",
       "<!-- sentiment -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>sentiment</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"652.0102\" cy=\"-45\" rx=\"57.6901\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"652.0102\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sentiment</text>\n",
       "</g>\n",
       "<!-- wrap_event&#45;&gt;sentiment -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>wrap_event&#45;&gt;sentiment</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M558.2354,-45C566.6409,-45 575.2683,-45 583.724,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"583.9264,-48.5001 593.9264,-45 583.9264,-41.5001 583.9264,-48.5001\"/>\n",
       "</g>\n",
       "<!-- parquet -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>parquet</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M818.8551,-86.7273C818.8551,-88.5331 802.4952,-90 782.3551,-90 762.215,-90 745.8551,-88.5331 745.8551,-86.7273 745.8551,-86.7273 745.8551,-57.2727 745.8551,-57.2727 745.8551,-55.4669 762.215,-54 782.3551,-54 802.4952,-54 818.8551,-55.4669 818.8551,-57.2727 818.8551,-57.2727 818.8551,-86.7273 818.8551,-86.7273\"/>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M818.8551,-86.7273C818.8551,-84.9214 802.4952,-83.4545 782.3551,-83.4545 762.215,-83.4545 745.8551,-84.9214 745.8551,-86.7273\"/>\n",
       "<text text-anchor=\"middle\" x=\"782.3551\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">parquet</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;&gt;parquet -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>sentiment&#45;&gt;parquet</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M700.1755,-54.9771C711.8422,-57.3938 724.2907,-59.9724 735.8779,-62.3726\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"735.2955,-65.8262 745.7976,-64.4274 736.7154,-58.9717 735.2955,-65.8262\"/>\n",
       "</g>\n",
       "<!-- nosql -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>nosql</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M809.8551,-32.7273C809.8551,-34.5331 797.5292,-36 782.3551,-36 767.181,-36 754.8551,-34.5331 754.8551,-32.7273 754.8551,-32.7273 754.8551,-3.2727 754.8551,-3.2727 754.8551,-1.4669 767.181,0 782.3551,0 797.5292,0 809.8551,-1.4669 809.8551,-3.2727 809.8551,-3.2727 809.8551,-32.7273 809.8551,-32.7273\"/>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M809.8551,-32.7273C809.8551,-30.9214 797.5292,-29.4545 782.3551,-29.4545 767.181,-29.4545 754.8551,-30.9214 754.8551,-32.7273\"/>\n",
       "<text text-anchor=\"middle\" x=\"782.3551\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nosql</text>\n",
       "</g>\n",
       "<!-- sentiment&#45;&gt;nosql -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>sentiment&#45;&gt;nosql</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M700.1755,-35.0229C714.8541,-31.9823 730.7702,-28.6854 744.6514,-25.81\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"745.7335,-29.1603 754.8156,-23.7046 744.3135,-22.3058 745.7335,-29.1603\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f32dd1c7790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlrun.feature_store as fstore\n",
    "from mlrun.feature_store.steps import DateExtractor, MapValues\n",
    "import yahoo_fin.stock_info as si\n",
    "\n",
    "# creating feature set\n",
    "news_set = fstore.FeatureSet(\"stocks_news\", \n",
    "                                 entities=[fstore.Entity(\"ticker\")],\n",
    "                                 timestamp_key='Datetime', \n",
    "                                 description=\"stocks news feature set\")\n",
    "\n",
    "# how many tickers data we ingest (make sure same number used for ingesting news)\n",
    "# n_tickers = 4\n",
    "\n",
    "news_set.graph \\\n",
    "    .to(name='get_news', handler='get_news') \\\n",
    "    .to(\"storey.steps.Flatten\", name=\"flatten_news\") \\\n",
    "    .to(name='wrap_event', handler='wrap_event') \\\n",
    "    .to(\"sentiment_analysis\", \"sentiment\", full_event=True, address=address) \n",
    "\n",
    "news_set.set_targets(with_defaults=True) \n",
    "news_set.plot(rankdir=\"LR\", with_targets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy ingestion, Deploying ingestion service and getting ingestion endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2022-07-05 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2022-07-04 16:01:50</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2022-07-01 21:28:09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2022-06-30 13:30:01</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2022-06-23 15:30:03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2022-07-05 17:16:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2022-07-05 16:42:15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2022-07-05 16:25:00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2022-07-05 16:08:26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2022-07-05 15:52:12</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Datetime  sentiment\n",
       "ticker                               \n",
       "A      2022-07-05 12:00:00        0.0\n",
       "A      2022-07-04 16:01:50        0.5\n",
       "A      2022-07-01 21:28:09        1.0\n",
       "A      2022-06-30 13:30:01        0.5\n",
       "A      2022-06-23 15:30:03        1.0\n",
       "...                    ...        ...\n",
       "AAPL   2022-07-05 17:16:00        0.0\n",
       "AAPL   2022-07-05 16:42:15        0.0\n",
       "AAPL   2022-07-05 16:25:00        0.5\n",
       "AAPL   2022-07-05 16:08:26        0.0\n",
       "AAPL   2022-07-05 15:52:12        0.5\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingesting dummy (A MUST) \n",
    "import os\n",
    "import datetime\n",
    "\n",
    "name = os.environ['V3IO_USERNAME']\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "fstore.ingest(news_set,\n",
    "              pd.DataFrame.from_dict({'ticker':[name],\n",
    "                                      'Datetime': now,\n",
    "                                      'n_stocks':4}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the graph and providing http-endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HTTP Source to_dictable the HTTP trigger on our function and expose the endpoint.\n",
    "# There is an option to declare key and timestamp inside the http source (here we dont send data through the http hence not needed)\n",
    "http_source = mlrun.datastore.sources.HttpSource()\n",
    "news_set.spec.source = http_source\n",
    "\n",
    "# code_to_function our mlrun wrapped function to deploy the ingestion pipeline on.\n",
    "# the serving runtimes enables the deployment of our feature set's computational graph\n",
    "function = mlrun.code_to_function(name='get_news',kind='serving',image='mlrun/mlrun', requirements=['yahoo_fin','graphviz'])\n",
    "\n",
    "run_config = fstore.RunConfig(function=function, local=False).apply(mlrun.mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-06 11:30:37,802 [info] Starting remote function deploy\n",
      "2022-07-06 11:30:37  (info) Deploying function\n",
      "2022-07-06 11:30:37  (info) Building\n",
      "2022-07-06 11:30:38  (info) Staging files and preparing base images\n",
      "2022-07-06 11:30:38  (info) Building processor image\n",
      "2022-07-06 11:31:23  (info) Build complete\n",
      "2022-07-06 11:32:25  (info) Function deploy complete\n",
      "> 2022-07-06 11:32:25,914 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-stocks-dani-get-news.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['stocks-dani-get-news-stocks-dani.default-tenant.app.vmdev94.lab.iguazeng.com/']}\n"
     ]
    }
   ],
   "source": [
    "# Deploying\n",
    "news_set_endpoint = fstore.deploy_ingestion_service(featureset=news_set, run_config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://stocks-dani-get-news-stocks-dani.default-tenant.app.vmdev94.lab.iguazeng.com/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_set_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ingestion service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": \"ae95e581-979f-4833-8173-391368126bda\"}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "t = requests.post(news_set_endpoint,json={'ticker':['news'],\n",
    "                                                 'Datetime': now,\n",
    "                                                 'n_stocks':4})\n",
    "t.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating scheduled mlrun job to invoke our function every time delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/invoker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/invoker.py\n",
    "\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "def ingestion_service_invoker(endpoint): \n",
    "    now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    t = requests.post(endpoint,json={'ticker':['news'],\n",
    "                                     'Datetime': now,\n",
    "                                     'n_stocks':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-07-06 11:32:26,190 [info] starting run ingestion-service-news-ingestion_service_invoker uid=8442a7d80b254a0e9d2d4f839e919b7e DB=http://mlrun-api:8080\n",
      "> 2022-07-06 11:32:26,493 [info] task scheduled, {'schedule': '0 */1 * * *', 'project': 'stocks-dani', 'name': 'ingestion-service-news-ingestion_service_invoker'}\n"
     ]
    }
   ],
   "source": [
    "# specifying '0 8 * * *' as schedule will trigger the function every day at 08:00 AM\n",
    "fn = mlrun.code_to_function(name='ingestion_service_news',kind='job',image='mlrun/mlrun',handler='ingestion_service_invoker', filename='src/invoker.py')\n",
    "fn.run(params={'endpoint':news_set_endpoint}, schedule='0 */1 * * *')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
